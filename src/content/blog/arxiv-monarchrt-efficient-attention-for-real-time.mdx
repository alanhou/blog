---
title:
  en: "MonarchRT: Efficient Attention for Real-Time Video Generation"
  zh: "MonarchRT: 实时视频生成的高效注意力机制"
description:
  en: "A structured attention parameterization using Monarch matrices that achieves 95% sparsity and enables true real-time video generation at 16 FPS on consumer GPUs."
  zh: "基于Monarch矩阵的结构化注意力参数化方法,实现95%稀疏度并在消费级GPU上达到16 FPS的真实时视频生成。"
date: 2026-02-13
tags: ["arxiv", "ai", "cs.cv", "cs.lg"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.12271](https://arxiv.org/abs/2602.12271)
**Authors**: Krish Agarwal, Zhuoming Chen, Cheng Luo, Yongqi Chen, Haizhong Zheng, Xun Huang, Atri Rudra, Beidi Chen
**Categories**: cs.CV, cs.LG

## Abstract

Real-time video generation using Diffusion Transformers faces a critical bottleneck: the quadratic computational cost of 3D self-attention. This challenge becomes particularly acute in autoregressive, few-step generation regimes where errors accumulate over time and each denoising step must encode significantly more information. The authors discover that video attention patterns are fundamentally different from static images—they exhibit complex periodic spatiotemporal structures combined with dynamic semantic correspondences that exceed the capacity of traditional sparse attention methods. MonarchRT addresses this through a novel structured attention parameterization based on Monarch matrices, achieving up to 95% attention sparsity without quality loss and enabling true real-time generation at 16 FPS on a single RTX 5090 GPU.

## Key Contributions

- **Empirical Analysis of Video Attention**: Demonstrates that video attention is not reliably sparse but combines periodic spatiotemporal structure with dynamic semantic correspondences, challenging assumptions behind existing sparse attention methods
- **Monarch Matrix Parameterization**: Introduces a structured attention factorization using extended tiled Monarch matrices with appropriately aligned block structures for high expressivity and computational efficiency
- **Custom Kernel Implementation**: Develops optimized Triton kernels that outperform FlashAttention-2/3/4 by 1.4-11.8× across RTX 5090, H100, and B200 GPUs
- **Real-Time Performance**: First demonstration of true real-time video generation with state-of-the-art Self-Forcing model at 16 FPS on consumer hardware
- **Scalable Sparsity**: Achieves 95% attention sparsity on Self-Forcing without quality degradation, validated against both sparse baselines and oracle top-k attention

## The Real-Time Video Generation Challenge

The computational demands of video generation with Diffusion Transformers scale as $O(n^2d)$ for sequence length $n$ and dimension $d$, making 3D spatiotemporal attention prohibitively expensive. Unlike bidirectional many-step diffusion where each step contributes incrementally, autoregressive few-step generation requires each denoising operation to carry substantially more information—errors compound temporally, and the model cannot "look ahead" to future frames for context.

Previous sparse attention approaches like local windows, strided patterns, and learned top-k selection work well for bidirectional image generation but fail in this regime. The authors' analysis reveals why: video attention patterns exhibit three simultaneous characteristics that exceed the representational capacity of simple sparsity patterns:

1. **Periodic Structure**: Strong spatiotemporal position-driven patterns that repeat across frames
2. **Dynamic Semantics**: Sparse but critical semantic correspondences that vary by content
3. **Dense Mixing**: Regions requiring dense attention that cannot be captured by fixed sparsity budgets

Even oracle top-k attention (which knows the optimal sparse pattern) struggles to capture this complexity within reasonable sparsity budgets.

## Monarch Matrix Methodology

MonarchRT's core innovation is parameterizing attention weights using Monarch matrices—a class of structured matrices that can be expressed as products of block-diagonal matrices. For an $n \times n$ attention matrix, the Monarch parameterization factorizes it as:

$$A = L \cdot R$$

where $L$ and $R$ are block-diagonal matrices with block size $b$. This reduces parameters from $O(n^2)$ to $O(nb)$ while maintaining expressivity through the interaction of block structures.

The authors extend this with a tiled Monarch parameterization that applies the factorization hierarchically across spatial and temporal dimensions. Key design choices include:

- **Aligned Block Structure**: Block boundaries align with natural video structure (spatial patches, temporal segments) to capture periodic patterns
- **Extended Tiling**: Multiple Monarch factors at different scales to handle both local and global dependencies
- **Learnable Parameterization**: Fine-tuning the Monarch factors on video data to adapt to dynamic semantic patterns

The computational cost reduces to $O(nb \log n)$ for the forward pass, with the block structure enabling efficient parallel computation.

## Implementation and Performance

The authors implement MonarchRT with custom Triton kernels optimized for the block-diagonal structure of Monarch matrices. Key optimizations include:

- **Fused Operations**: Combining matrix multiplications and attention computations to reduce memory bandwidth
- **Block-Aware Scheduling**: Exploiting block structure for better cache utilization and parallelism
- **Mixed Precision**: Strategic use of FP16/BF16 for throughput while maintaining numerical stability

Performance results demonstrate significant speedups over state-of-the-art attention implementations:

| GPU | vs FlashAttention-2 | vs FlashAttention-3 | vs FlashAttention-4 |
|-----|---------------------|---------------------|---------------------|
| RTX 5090 | 1.4-3.2× | - | - |
| H100 | 2.1-5.7× | 1.8-4.3× | - |
| B200 | 3.8-11.8× | 2.9-8.4× | 2.2-6.1× |

When integrated with the Self-Forcing model, MonarchRT enables 16 FPS generation on a single RTX 5090—the first demonstration of true real-time performance for high-quality video generation.

## Experimental Validation

The authors validate MonarchRT across multiple dimensions:

**Sparsity vs Quality**: MonarchRT maintains visual quality up to 95% sparsity on Self-Forcing, significantly outperforming sparse baselines (local attention, strided patterns, top-k) which degrade rapidly beyond 80% sparsity. Metrics include FVD (Fréchet Video Distance), temporal consistency, and human evaluation.

**Comparison to Oracle**: Even oracle top-k attention (with perfect knowledge of important positions) shows quality degradation at high sparsity, demonstrating that video attention requires structured expressivity beyond simple sparse selection.

**Ablation Studies**: 
- Block size: Optimal at 16-32 for balancing expressivity and efficiency
- Tiling depth: 2-3 levels capture multi-scale dependencies effectively
- Fine-tuning: Essential for adapting Monarch structure to video-specific patterns

**Generalization**: MonarchRT transfers effectively across different video domains (natural scenes, synthetic content, human actions) and resolution scales.

## Takeaways

1. Video attention in autoregressive few-step diffusion exhibits fundamentally different patterns than bidirectional image generation, combining periodic structure, dynamic semantics, and dense mixing that challenge simple sparse approximations.

2. Monarch matrix parameterization provides a structured middle ground between dense attention and naive sparsity, achieving 95% parameter reduction while maintaining the expressivity needed for high-quality video generation.

3. Custom kernel optimization is critical for realizing theoretical efficiency gains—MonarchRT's Triton implementation achieves 1.4-11.8× speedups over FlashAttention variants across modern GPU architectures.

4. Real-time video generation (16 FPS) is now achievable on consumer hardware (RTX 5090) through the combination of efficient attention parameterization and optimized implementation.

5. The structured approach of MonarchRT opens new directions for efficient transformer architectures in other domains requiring complex attention patterns, particularly in autoregressive and real-time settings.
:::

:::zh
**论文**: [2602.12271](https://arxiv.org/abs/2602.12271)
**作者**: Krish Agarwal, Zhuoming Chen, Cheng Luo, Yongqi Chen, Haizhong Zheng, Xun Huang, Atri Rudra, Beidi Chen
**分类**: cs.CV, cs.LG

## 摘要

使用扩散Transformer进行实时视频生成面临关键瓶颈:3D自注意力的二次计算成本。这一挑战在自回归、少步生成场景中尤为突出,因为误差会随时间累积,每个去噪步骤必须编码更多信息。作者发现视频注意力模式与静态图像根本不同——它们展现出复杂的周期性时空结构,结合动态语义对应关系,超出了传统稀疏注意力方法的能力范围。MonarchRT通过基于Monarch矩阵的新型结构化注意力参数化解决这一问题,实现高达95%的注意力稀疏度且无质量损失,在单块RTX 5090 GPU上实现16 FPS的真实时生成。

## 主要贡献

- **视频注意力的实证分析**: 证明视频注意力并非可靠稀疏,而是结合周期性时空结构与动态语义对应关系,挑战现有稀疏注意力方法的假设
- **Monarch矩阵参数化**: 引入使用扩展平铺Monarch矩阵的结构化注意力分解,通过适当对齐的块结构实现高表达能力和计算效率
- **定制核心实现**: 开发优化的Triton核心,在RTX 5090、H100和B200 GPU上比FlashAttention-2/3/4快1.4-11.8倍
- **实时性能**: 首次在消费级硬件上以16 FPS实现最先进Self-Forcing模型的真实时视频生成
- **可扩展稀疏性**: 在Self-Forcing上实现95%注意力稀疏度且无质量下降,经过稀疏基线和oracle top-k注意力验证

## 实时视频生成的挑战

扩散Transformer视频生成的计算需求按$O(n^2d)$缩放(序列长度$n$和维度$d$),使3D时空注意力的计算成本极高。与双向多步扩散(每步增量贡献)不同,自回归少步生成要求每个去噪操作承载更多信息——误差在时间上复合,模型无法"前瞻"未来帧获取上下文。

先前的稀疏注意力方法如局部窗口、跨步模式和学习的top-k选择在双向图像生成中表现良好,但在此场景下失效。作者的分析揭示了原因:视频注意力模式同时展现三个超出简单稀疏模式表示能力的特征:

1. **周期性结构**: 由时空位置驱动的强周期性模式,在帧间重复
2. **动态语义**: 稀疏但关键的语义对应关系,随内容变化
3. **密集混合**: 需要密集注意力的区域,无法被固定稀疏预算捕获

即使oracle top-k注意力(知道最优稀疏模式)在合理稀疏预算内也难以捕获这种复杂性。

## Monarch矩阵方法论

MonarchRT的核心创新是使用Monarch矩阵参数化注意力权重——一类可表示为块对角矩阵乘积的结构化矩阵。对于$n \times n$注意力矩阵,Monarch参数化将其分解为:

$$A = L \cdot R$$

其中$L$和$R$是块大小为$b$的块对角矩阵。这将参数从$O(n^2)$减少到$O(nb)$,同时通过块结构的交互保持表达能力。

作者通过平铺Monarch参数化扩展此方法,在空间和时间维度上分层应用分解。关键设计选择包括:

- **对齐块结构**: 块边界与视频的自然结构(空间块、时间段)对齐以捕获周期性模式
- **扩展平铺**: 不同尺度的多个Monarch因子以处理局部和全局依赖
- **可学习参数化**: 在视频数据上微调Monarch因子以适应动态语义模式

前向传播的计算成本降至$O(nb \log n)$,块结构支持高效并行计算。

## 实现与性能

作者使用针对Monarch矩阵块对角结构优化的定制Triton核心实现MonarchRT。关键优化包括:

- **融合操作**: 结合矩阵乘法和注意力计算以减少内存带宽
- **块感知调度**: 利用块结构实现更好的缓存利用和并行性
- **混合精度**: 战略性使用FP16/BF16提高吞吐量同时保持数值稳定性

性能结果显示相比最先进注意力实现的显著加速:

| GPU | vs FlashAttention-2 | vs FlashAttention-3 | vs FlashAttention-4 |
|-----|---------------------|---------------------|---------------------|
| RTX 5090 | 1.4-3.2× | - | - |
| H100 | 2.1-5.7× | 1.8-4.3× | - |
| B200 | 3.8-11.8× | 2.9-8.4× | 2.2-6.1× |

与Self-Forcing模型集成后,MonarchRT在单块RTX 5090上实现16 FPS生成——首次展示高质量视频生成的真实时性能。

## 实验验证

作者从多个维度验证MonarchRT:

**稀疏度与质量**: MonarchRT在Self-Forcing上保持高达95%稀疏度的视觉质量,显著优于稀疏基线(局部注意力、跨步模式、top-k),后者在超过80%稀疏度时快速退化。评估指标包括FVD(Fréchet视频距离)、时间一致性和人工评估。

**与Oracle对比**: 即使oracle top-k注意力(完美知道重要位置)在高稀疏度下也显示质量下降,证明视频注意力需要超越简单稀疏选择的结构化表达能力。

**消融研究**: 
- 块大小: 16-32时在表达能力和效率间达到最优平衡
- 平铺深度: 2-3层有效捕获多尺度依赖
- 微调: 对于将Monarch结构适应视频特定模式至关重要

**泛化能力**: MonarchRT在不同视频领域(自然场景、合成内容、人类动作)和分辨率尺度间有效迁移。

## 要点总结

1. 自回归少步扩散中的视频注意力展现出与双向图像生成根本不同的模式,结合周期性结构、动态语义和密集混合,挑战简单稀疏近似方法。

2. Monarch矩阵参数化在密集注意力和朴素稀疏性之间提供结构化中间方案,实现95%参数减少同时保持高质量视频生成所需的表达能力。

3. 定制核心优化对于实现理论效率增益至关重要——MonarchRT的Triton实现在现代GPU架构上实现比FlashAttention变体快1.4-11.8倍。

4. 通过高效注意力参数化和优化实现的结合,在消费级硬件(RTX 5090)上实现实时视频生成(16 FPS)现已可行。

5. MonarchRT的结构化方法为其他需要复杂注意力模式的领域中的高效transformer架构开辟新方向,特别是在自回归和实时设置中。
:::
