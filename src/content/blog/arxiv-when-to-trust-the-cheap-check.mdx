---
title:
  en: "When to Trust the Cheap Check: Weak and Strong Verification for Reasoning"
  zh: "何时信任廉价检查:推理中的弱验证与强验证"
description:
  en: "A formal framework for balancing fast but noisy weak verification with costly but reliable strong verification in LLM reasoning systems, introducing optimal two-threshold policies and online error control algorithms."
  zh: "针对大语言模型推理系统中快速但有噪声的弱验证与昂贵但可靠的强验证之间的平衡问题,提出了最优双阈值策略框架和在线误差控制算法。"
date: 2026-02-20
tags: ["arxiv", "ai", "cs.lg", "cs.ai", "stat.ml"]
image: "/arxiv-visuals/arxiv-when-to-trust-the-cheap-check.png"
---

:::en
**Paper**: [2602.17633](https://arxiv.org/abs/2602.17633)
**Authors**: Shayan Kiyani, Sima Noorani, George Pappas, Hamed Hassani
**Categories**: cs.LG, cs.AI, stat.ML

## Abstract

This paper addresses a fundamental challenge in LLM-based reasoning systems: how to balance cheap but imperfect verification methods with expensive but reliable ones. The authors formalize the distinction between weak verification (internal checks like self-consistency) and strong verification (external human feedback or rigorous testing). They introduce weak-strong verification policies that optimally decide when to trust weak signals and when to escalate to strong verification. The work proves that optimal policies follow a two-threshold structure and develops an online algorithm that provably controls both false acceptance and false rejection rates without requiring assumptions about the query distribution, model behavior, or verifier characteristics.

## Key Contributions

- **Formal framework for verification policies**: Introduces a mathematical model distinguishing weak verification (fast, scalable, noisy) from strong verification (costly, reliable) with explicit cost-reliability tradeoffs
- **Two-threshold optimality**: Proves that optimal policies admit a simple two-threshold structure where decisions depend on weak verifier confidence scores
- **Calibration and sharpness analysis**: Shows that the value of weak verifiers is governed by two key properties—calibration (accuracy of confidence estimates) and sharpness (ability to discriminate between correct and incorrect outputs)
- **Online error control algorithm**: Develops a provably correct algorithm that maintains user-specified bounds on incorrect acceptance and rejection rates without distributional assumptions

## Methodology and Theoretical Framework

The paper models the verification problem as a sequential decision process. For each query, a language model produces an output, and a weak verifier assigns a confidence score. The policy must decide whether to accept, reject, or defer to strong verification based on this score.

The authors define three key metrics:
- **Incorrect acceptance rate** $\alpha$: frequency of accepting wrong outputs
- **Incorrect rejection rate** $\beta$: frequency of rejecting correct outputs  
- **Strong verification frequency** $\gamma$: proportion of queries requiring expensive verification

The optimal policy minimizes $\gamma$ subject to constraints $\alpha \leq \alpha_{\text{max}}$ and $\beta \leq \beta_{\text{max}}$. The paper proves this optimal policy takes the form:

$$
\pi^*(s) = \begin{cases}
\text{accept} & \text{if } s > \tau_{\text{accept}} \\
\text{strong verify} & \text{if } \tau_{\text{reject}} \leq s \leq \tau_{\text{accept}} \\
\text{reject} & \text{if } s < \tau_{\text{reject}}
\end{cases}
$$

where $s$ is the weak verifier's confidence score and $\tau_{\text{accept}}, \tau_{\text{reject}}$ are learned thresholds.

The theoretical analysis reveals that weak verifier quality depends on:
- **Calibration**: whether $P(\text{correct} \mid s) \approx s$
- **Sharpness**: the variance of the score distribution, with sharper (more concentrated) distributions enabling better discrimination

## Online Algorithm with Provable Guarantees

A key practical contribution is an online algorithm that adapts thresholds dynamically without knowing the query distribution or verifier properties in advance. The algorithm:

1. Maintains running estimates of acceptance and rejection error rates
2. Adjusts thresholds using a multiplicative update rule when error rates exceed targets
3. Provides theoretical guarantees on long-run error control

The algorithm is distribution-free and model-agnostic, making it applicable across different LLMs, tasks, and weak verification methods. The authors prove that with probability $1-\delta$, the algorithm maintains:

$$
\limsup_{T \to \infty} \frac{1}{T} \sum_{t=1}^T \mathbb{1}[\text{incorrect acceptance at } t] \leq \alpha_{\text{max}} + \epsilon
$$

with similar guarantees for rejection errors, where $\epsilon$ depends on $\delta$ and vanishes as more queries are processed.

## Implications for LLM Systems

This work has significant implications for deploying LLM reasoning systems in practice:

**Cost-quality tradeoffs**: The framework provides a principled way to navigate the tension between system cost (strong verification frequency) and output quality (error rates). Organizations can specify acceptable error tolerances and minimize verification costs accordingly.

**Verifier design insights**: The calibration-sharpness decomposition offers concrete guidance for improving weak verifiers. Self-consistency methods, for instance, may be well-calibrated but lack sharpness, while learned reward models might be sharp but poorly calibrated.

**Adaptive deployment**: The online algorithm enables systems to adapt to shifting query distributions and model updates without retraining, crucial for production environments where conditions change continuously.

**Human-in-the-loop optimization**: By formalizing when to request human feedback, the framework helps optimize the use of expensive human verification resources, potentially reducing annotation costs while maintaining quality guarantees.

## Takeaways

1. Optimal verification policies follow a simple two-threshold structure, making them practical to implement and interpret in real systems
2. Weak verifier quality decomposes into calibration (accuracy of confidence) and sharpness (discrimination ability), providing actionable targets for improvement
3. Online algorithms can provably control error rates without assumptions about queries, models, or verifiers, enabling robust deployment
4. The framework applies broadly across reasoning tasks, from mathematical problem-solving to code generation to factual question answering
5. Balancing weak and strong verification is essential for scaling LLM systems—pure reliance on either is suboptimal in cost-quality space
:::

:::zh
**论文**: [2602.17633](https://arxiv.org/abs/2602.17633)
**作者**: Shayan Kiyani, Sima Noorani, George Pappas, Hamed Hassani
**分类**: cs.LG, cs.AI, stat.ML

## 摘要

本文解决了基于大语言模型的推理系统中的一个基本挑战:如何平衡廉价但不完美的验证方法与昂贵但可靠的验证方法。作者形式化了弱验证(如自洽性等内部检查)和强验证(外部人工反馈或严格测试)之间的区别。他们提出了弱-强验证策略,可以最优地决定何时信任弱信号、何时升级到强验证。研究证明最优策略遵循双阈值结构,并开发了一种在线算法,该算法可证明地控制错误接受率和错误拒绝率,且无需对查询分布、模型行为或验证器特性做任何假设。

## 主要贡献

- **验证策略的形式化框架**:引入数学模型区分弱验证(快速、可扩展、有噪声)和强验证(昂贵、可靠),明确成本-可靠性权衡
- **双阈值最优性**:证明最优策略具有简单的双阈值结构,决策依赖于弱验证器的置信度分数
- **校准度与锐度分析**:表明弱验证器的价值由两个关键属性决定——校准度(置信度估计的准确性)和锐度(区分正确与错误输出的能力)
- **在线误差控制算法**:开发了可证明正确的算法,在无分布假设的情况下维持用户指定的错误接受率和拒绝率界限

## 方法论与理论框架

本文将验证问题建模为序列决策过程。对于每个查询,语言模型产生输出,弱验证器分配置信度分数。策略必须基于该分数决定是接受、拒绝还是推迟到强验证。

作者定义了三个关键指标:
- **错误接受率** $\alpha$:接受错误输出的频率
- **错误拒绝率** $\beta$:拒绝正确输出的频率
- **强验证频率** $\gamma$:需要昂贵验证的查询比例

最优策略在约束 $\alpha \leq \alpha_{\text{max}}$ 和 $\beta \leq \beta_{\text{max}}$ 下最小化 $\gamma$。论文证明该最优策略采用如下形式:

$$
\pi^*(s) = \begin{cases}
\text{接受} & \text{若 } s > \tau_{\text{accept}} \\
\text{强验证} & \text{若 } \tau_{\text{reject}} \leq s \leq \tau_{\text{accept}} \\
\text{拒绝} & \text{若 } s < \tau_{\text{reject}}
\end{cases}
$$

其中 $s$ 是弱验证器的置信度分数,$\tau_{\text{accept}}, \tau_{\text{reject}}$ 是学习得到的阈值。

理论分析揭示弱验证器质量取决于:
- **校准度**:是否满足 $P(\text{正确} \mid s) \approx s$
- **锐度**:分数分布的方差,更锐利(更集中)的分布能实现更好的区分能力

## 具有可证明保证的在线算法

一个关键的实践贡献是在线算法,它在不预先知道查询分布或验证器属性的情况下动态调整阈值。该算法:

1. 维护接受和拒绝错误率的运行估计
2. 当错误率超过目标时使用乘法更新规则调整阈值
3. 提供长期误差控制的理论保证

该算法是分布无关和模型无关的,适用于不同的大语言模型、任务和弱验证方法。作者证明以 $1-\delta$ 的概率,算法维持:

$$
\limsup_{T \to \infty} \frac{1}{T} \sum_{t=1}^T \mathbb{1}[\text{时刻 } t \text{ 错误接受}] \leq \alpha_{\text{max}} + \epsilon
$$

对拒绝错误有类似保证,其中 $\epsilon$ 依赖于 $\delta$ 并随着处理更多查询而消失。

## 对大语言模型系统的影响

这项工作对实际部署大语言模型推理系统具有重要意义:

**成本-质量权衡**:该框架提供了一种原则性方法来处理系统成本(强验证频率)和输出质量(错误率)之间的张力。组织可以指定可接受的错误容忍度并相应地最小化验证成本。

**验证器设计洞察**:校准度-锐度分解为改进弱验证器提供了具体指导。例如,自洽性方法可能校准良好但缺乏锐度,而学习的奖励模型可能锐利但校准不佳。

**自适应部署**:在线算法使系统能够适
