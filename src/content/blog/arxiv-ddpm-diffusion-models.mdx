---
title: 'Denoising Diffusion Probabilistic Models (DDPM)'
description: '将扩散模型与降噪得分匹配联系起来，训练高质量图像生成模型'
pubDate: 2020-06-19
heroImage: '../../assets/images/arxiv-ddpm.jpg'
heroImageAlt: 'Diffusion process forward and reverse'
category: 'AI Research'
tags: ['Diffusion Models', 'DDPM', 'Generative Models', 'Image Generation', 'arXiv']
---

## 论文信息 / Paper Information

- **标题**: Denoising Diffusion Probabilistic Models
- **作者**: Jonathan Ho, Ajay Jain, Pieter Abbeel
- **机构**: UC Berkeley
- **发表年份**: 2020
- **论文链接**: [arXiv:2006.11239](https://arxiv.org/abs/2006.11239)

---

## 核心贡献 / Core Contributions

DDPM重新定义了扩散模型的训练方法，使其成为强大的生成模型：

1. **简化训练目标**: 将复杂的变分下界简化为简单的降噪目标
2. **高质量生成**: 在CIFAR-10上达到3.17 FID，超越当时的GAN
3. **理论联系**: 建立了扩散模型与降噪得分匹配、Langevin动力学的联系

---

## 技术细节 / Technical Details

### 前向扩散过程

逐步向数据添加高斯噪声：

$$q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)$$

经过T步后，$x_T$近似为标准高斯分布。

### 反向去噪过程

学习逆向过程，从噪声恢复数据：

$$p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$$

### 简化训练目标

$$L_{simple} = \mathbb{E}_{t,x_0,\epsilon}\left[\|\epsilon - \epsilon_\theta(x_t, t)\|^2\right]$$

模型学习预测添加的噪声，而非直接预测均值。

### 采样过程

从$x_T \sim \mathcal{N}(0, I)$开始，迭代应用去噪网络：

$$x_{t-1} = \frac{1}{\sqrt{\alpha_t}}\left(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t, t)\right) + \sigma_t z$$

---

## 影响与后续发展 / Impact and Follow-up

DDPM开启了扩散模型的黄金时代：

- **DDIM (2020)**: 加速采样，减少步数
- **Guided Diffusion (2021)**: 分类器引导，提升质量
- **Latent Diffusion (2021)**: 潜空间扩散，Stable Diffusion基础
- **DiT (2022)**: Transformer架构的扩散模型
- **Sora (2024)**: 视频生成的扩散模型

---

## 总结 / Summary

DDPM通过简化训练目标和建立理论联系，使扩散模型从理论走向实践。它是Stable Diffusion、DALL-E、Midjourney等现代图像生成系统的理论基础，彻底改变了生成式AI的格局。
