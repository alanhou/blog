---
title:
  en: "CORAL: Correctness-Optimized Residual Activation Lens for Inference-Time Steering"
  zh: "CORAL：面向正确性优化的残差激活透镜用于推理时引导"
description:
  en: "A transferrable and calibration-aware method for steering LLM behavior at inference time through residual stream interventions"
  zh: "一种可迁移且具有校准感知能力的方法，通过残差流干预在推理时引导LLM行为"
date: 2026-02-05
tags: ["arxiv", "ai", "interpretability", "inference-steering", "llm", "mechanistic-interpretability", "cs.CL", "cs.LG"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.06022](https://arxiv.org/abs/2602.06022)
**Title**: Correctness-Optimized Residual Activation Lens (CORAL): Transferrable and Calibration-Aware Inference-Time Steering
**Categories**: cs.CL, cs.LG

## Abstract

Inference-time steering has emerged as a promising approach for controlling Large Language Model (LLM) behavior without expensive fine-tuning. CORAL (Correctness-Optimized Residual Activation Lens) introduces a novel framework that learns transferrable steering vectors optimized for correctness rather than mere activation matching, while maintaining calibration awareness to prevent overconfident or miscalibrated outputs.

## Key Contributions

- **Correctness-Optimized Training**: Unlike traditional activation steering that matches target activations, CORAL directly optimizes for downstream task correctness
- **Residual Activation Lens**: A learned projection that identifies the most influential directions in the residual stream for steering
- **Transferability**: Steering vectors learned on one task transfer effectively to related tasks and even different model scales
- **Calibration Awareness**: Built-in mechanisms to maintain well-calibrated confidence estimates during steering

## Background: Activation Steering

Traditional activation steering methods work by:
1. Collecting activations from contrastive prompts (e.g., helpful vs. harmful)
2. Computing a steering vector as the difference in mean activations
3. Adding this vector to the residual stream during inference

The steering intervention at layer $l$ can be written as:

$$h_l' = h_l + \alpha \cdot v$$

where $h_l$ is the original hidden state, $v$ is the steering vector, and $\alpha$ controls the steering strength.

## The Problem with Existing Methods

**Activation Matching vs. Correctness**: Traditional methods optimize for activation similarity, not task performance. A steering vector that perfectly matches target activations may not improve actual model behavior.

**Calibration Degradation**: Aggressive steering can push the model into overconfident predictions, degrading calibration even when accuracy improves.

**Limited Transferability**: Steering vectors are often task-specific and fail to generalize across different prompts or model configurations.

## CORAL Framework

### Residual Activation Lens

CORAL learns a projection matrix $W$ that identifies the most influential subspace for steering:

$$v_{coral} = W \cdot (a_{target} - a_{base})$$

where $a_{target}$ and $a_{base}$ are activations from target and base behaviors. The lens $W$ is learned to maximize downstream correctness.

### Correctness-Optimized Training

The training objective combines task performance with calibration:

$$\mathcal{L} = \mathcal{L}_{task} + \lambda \cdot \mathcal{L}_{calibration}$$

The task loss $\mathcal{L}_{task}$ measures performance on the target behavior, while $\mathcal{L}_{calibration}$ penalizes miscalibrated confidence estimates using Expected Calibration Error (ECE).

### Calibration-Aware Steering

CORAL introduces adaptive steering strength based on model uncertainty:

$$\alpha_{adaptive} = \alpha_0 \cdot \sigma(u)$$

where $u$ is a learned uncertainty estimate and $\sigma$ is a sigmoid function. This prevents oversteering on inputs where the model is already confident.

## Methodology

### Training Pipeline

1. **Data Collection**: Gather contrastive examples representing target and base behaviors
2. **Activation Extraction**: Extract residual stream activations at multiple layers
3. **Lens Learning**: Train the projection matrix $W$ to maximize correctness
4. **Calibration Tuning**: Fine-tune steering strength for calibration preservation

### Inference-Time Application

At inference, CORAL applies the learned steering:

$$h_l' = h_l + \alpha_{adaptive} \cdot W \cdot \Delta a$$

The intervention is applied at selected layers identified during training as most effective for the target behavior.

## Results

CORAL demonstrates improvements across multiple steering tasks:

| Task | Baseline | Activation Steering | CORAL |
|------|----------|---------------------|-------|
| Truthfulness | 62.3% | 71.5% | 78.2% |
| Helpfulness | 74.1% | 79.8% | 84.6% |
| Safety | 81.2% | 86.4% | 91.3% |

### Calibration Preservation

| Method | Accuracy | ECE (lower is better) |
|--------|----------|----------------------|
| Base Model | 65.4% | 0.082 |
| Activation Steering | 73.2% | 0.156 |
| CORAL | 78.2% | 0.091 |

CORAL maintains calibration while improving accuracy, unlike traditional steering which degrades calibration.

### Transferability

Steering vectors learned on one task show strong transfer:
- **Cross-prompt**: 89% effectiveness on unseen prompt formats
- **Cross-task**: 72% effectiveness on related but distinct tasks
- **Cross-scale**: 81% effectiveness when transferred to larger models

## Why This Matters

**Efficient Alignment**: CORAL enables behavior modification without fine-tuning, reducing computational costs by orders of magnitude.

**Interpretable Control**: The learned lens provides insights into which activation directions matter for specific behaviors.

**Safe Deployment**: Calibration awareness ensures that steered models maintain reliable uncertainty estimates, crucial for high-stakes applications.

## Takeaways

1. **Optimize for correctness, not activation matching**: Direct optimization for task performance yields better steering vectors than activation similarity
2. **Calibration matters**: Steering methods must preserve calibration to be useful in practice
3. **Transferability is achievable**: Well-designed steering vectors can generalize across tasks and model scales
4. **Residual stream is key**: The residual stream provides a natural intervention point for behavior modification
5. **Adaptive steering**: Uncertainty-aware steering strength prevents overconfident predictions
:::

:::zh
**论文**: [2602.06022](https://arxiv.org/abs/2602.06022)
**标题**: 面向正确性优化的残差激活透镜（CORAL）：可迁移且具有校准感知能力的推理时引导
**分类**: cs.CL, cs.LG

## 摘要

推理时引导已成为一种有前景的方法，可以在不进行昂贵微调的情况下控制大语言模型（LLM）的行为。CORAL（面向正确性优化的残差激活透镜）引入了一个新颖的框架，学习针对正确性而非仅仅激活匹配进行优化的可迁移引导向量，同时保持校准感知能力以防止过度自信或校准不良的输出。

## 主要贡献

- **面向正确性的训练**：与匹配目标激活的传统激活引导不同，CORAL直接针对下游任务正确性进行优化
- **残差激活透镜**：一种学习的投影，识别残差流中对引导最有影响力的方向
- **可迁移性**：在一个任务上学习的引导向量可以有效迁移到相关任务甚至不同规模的模型
- **校准感知**：内置机制在引导过程中保持良好校准的置信度估计

## 背景：激活引导

传统激活引导方法的工作原理：
1. 从对比提示（如有帮助vs有害）收集激活
2. 计算引导向量作为平均激活的差异
3. 在推理时将此向量添加到残差流中

在第 $l$ 层的引导干预可以写为：

$$h_l' = h_l + \alpha \cdot v$$

其中 $h_l$ 是原始隐藏状态，$v$ 是引导向量，$\alpha$ 控制引导强度。

## 现有方法的问题

**激活匹配vs正确性**：传统方法针对激活相似性而非任务性能进行优化。完美匹配目标激活的引导向量可能不会改善实际模型行为。

**校准退化**：激进的引导可能将模型推向过度自信的预测，即使准确率提高也会降低校准质量。

**有限的可迁移性**：引导向量通常是任务特定的，无法在不同提示或模型配置之间泛化。

## CORAL框架

### 残差激活透镜

CORAL学习一个投影矩阵 $W$，识别对引导最有影响力的子空间：

$$v_{coral} = W \cdot (a_{target} - a_{base})$$

其中 $a_{target}$ 和 $a_{base}$ 是来自目标和基础行为的激活。透镜 $W$ 被学习以最大化下游正确性。

### 面向正确性的训练

训练目标结合了任务性能和校准：

$$\mathcal{L} = \mathcal{L}_{task} + \lambda \cdot \mathcal{L}_{calibration}$$

任务损失 $\mathcal{L}_{task}$ 衡量目标行为的性能，而 $\mathcal{L}_{calibration}$ 使用期望校准误差（ECE）惩罚校准不良的置信度估计。

### 校准感知引导

CORAL引入基于模型不确定性的自适应引导强度：

$$\alpha_{adaptive} = \alpha_0 \cdot \sigma(u)$$

其中 $u$ 是学习的不确定性估计，$\sigma$ 是sigmoid函数。这防止了在模型已经自信的输入上过度引导。

## 方法论

### 训练流程

1. **数据收集**：收集代表目标和基础行为的对比示例
2. **激活提取**：在多个层提取残差流激活
3. **透镜学习**：训练投影矩阵 $W$ 以最大化正确性
4. **校准调优**：微调引导强度以保持校准

### 推理时应用

在推理时，CORAL应用学习的引导：

$$h_l' = h_l + \alpha_{adaptive} \cdot W \cdot \Delta a$$

干预应用于训练期间识别为对目标行为最有效的选定层。

## 实验结果

CORAL在多个引导任务中展示了改进：

| 任务 | 基线 | 激活引导 | CORAL |
|------|------|----------|-------|
| 真实性 | 62.3% | 71.5% | 78.2% |
| 有帮助性 | 74.1% | 79.8% | 84.6% |
| 安全性 | 81.2% | 86.4% | 91.3% |

### 校准保持

| 方法 | 准确率 | ECE（越低越好） |
|------|--------|----------------|
| 基础模型 | 65.4% | 0.082 |
| 激活引导 | 73.2% | 0.156 |
| CORAL | 78.2% | 0.091 |

CORAL在提高准确率的同时保持校准，而传统引导会降低校准质量。

### 可迁移性

在一个任务上学习的引导向量显示出强大的迁移能力：
- **跨提示**：在未见过的提示格式上89%的有效性
- **跨任务**：在相关但不同的任务上72%的有效性
- **跨规模**：迁移到更大模型时81%的有效性

## 重要意义

**高效对齐**：CORAL实现了无需微调的行为修改，将计算成本降低了数个数量级。

**可解释的控制**：学习的透镜提供了关于哪些激活方向对特定行为重要的洞察。

**安全部署**：校准感知确保引导后的模型保持可靠的不确定性估计，这对高风险应用至关重要。

## 要点总结

1. **针对正确性优化，而非激活匹配**：直接针对任务性能优化比激活相似性产生更好的引导向量
2. **校准很重要**：引导方法必须保持校准才能在实践中有用
3. **可迁移性是可实现的**：设计良好的引导向量可以在任务和模型规模之间泛化
4. **残差流是关键**：残差流为行为修改提供了自然的干预点
5. **自适应引导**：不确定性感知的引导强度防止过度自信的预测
:::
