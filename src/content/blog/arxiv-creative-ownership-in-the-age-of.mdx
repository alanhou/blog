---
title:
  en: "Creative Ownership in the Age of AI: Rethinking Copyright Infringement"
  zh: "AI时代的创作所有权:重新思考版权侵权"
description:
  en: "A theoretical framework proposing that AI-generated content infringes copyright only if it could not exist without specific training data, revealing how the distribution of creative works determines regulatory constraints."
  zh: "提出AI生成内容仅在无法脱离特定训练数据而存在时才构成侵权的理论框架,揭示创作作品的分布如何决定监管约束。"
date: 2026-02-14
tags: ["arxiv", "ai", "econ.th", "cs.ai", "cs.gt"]
image: "/arxiv-visuals/arxiv-creative-ownership-in-the-age-of.png"
---

:::en
**Paper**: [2602.12270](https://arxiv.org/abs/2602.12270)
**Authors**: Annie Liang, Jay Lu
**Categories**: econ.TH, cs.AI, cs.GT

## Abstract

This paper addresses a fundamental challenge in copyright law posed by generative AI: the ability to imitate creative style without copying specific content. The authors propose a novel infringement criterion based on counterfactual dependence—an AI output infringes if it could not have been generated without a particular work in the training corpus. Using closure operators to model generative systems, they characterize permissible AI generation and discover a striking dichotomy: in light-tailed creative distributions, individual works become asymptotically irrelevant to AI generation, rendering regulation ineffective; in heavy-tailed distributions, regulation remains persistently constraining.

## Key Contributions

- Introduces a counterfactual dependence criterion for AI copyright infringement that moves beyond "substantial similarity"
- Models generative AI systems as closure operators mapping training corpora to generated outputs
- Proves a sharp asymptotic dichotomy based on the tail behavior of creative work distributions
- Demonstrates that light-tailed creativity leads to vanishing dependence on individual works
- Shows that heavy-tailed creativity maintains persistent regulatory constraints on AI generation
- Provides formal characterization of permissible generation under the proposed framework

## Theoretical Framework

The paper models a generative system as a closure operator $\mathcal{G}: 2^W \to 2^W$, where $W$ is the space of all possible works. For a corpus $C \subseteq W$, $\mathcal{G}(C)$ represents all works the AI can generate from $C$. A work $w$ is permissible if there exists a corpus $C$ not containing any work that $w$ depends on, yet $w \in \mathcal{G}(C)$.

The counterfactual dependence criterion states that an AI-generated work $w'$ infringes on work $w$ if $w' \in \mathcal{G}(C)$ but $w' 
otin \mathcal{G}(C \setminus \{w\})$ for some corpus $C$ containing $w$. This captures the intuition that $w$ was essential to generating $w'$.

The closure operator framework satisfies three natural properties: extensivity ($C \subseteq \mathcal{G}(C)$), monotonicity (larger corpora enable more generation), and idempotence (applying generation twice yields the same result as once).

## The Asymptotic Dichotomy

The paper's central result reveals how the statistical properties of organic creative production determine long-run regulatory effectiveness. Consider a sequence of creative works $w_1, w_2, \ldots$ generated organically over time, and let $C_n = \{w_1, \ldots, w_n\}$.

**Light-tailed case**: When the influence of individual works decays sufficiently fast (light-tailed distribution), for any work $w_i$, the probability that a randomly generated work depends on $w_i$ approaches zero as $n \to \infty$. Formally, $\mathbb{P}(w \text{ depends on } w_i \mid w \in \mathcal{G}(C_n)) \to 0$. This implies that copyright regulation becomes asymptotically irrelevant—AI systems can generate virtually any permissible work without depending on any specific copyrighted work.

**Heavy-tailed case**: When creative influence follows a heavy-tailed distribution (e.g., power law), certain works maintain persistent influence. The probability that generated works depend on highly influential works remains bounded away from zero even as $n \to \infty$. This means regulation continues to constrain AI generation indefinitely, as removing influential works from training data meaningfully restricts the output space.

This dichotomy has profound implications: in domains where creativity is relatively uniform (light-tailed), copyright law may be unable to effectively regulate AI; in domains with "superstar" works (heavy-tailed), regulation remains potent.

## Implications for Policy and Practice

The framework suggests that copyright policy for AI should be domain-specific, reflecting the underlying distribution of creative influence. In fields like stock photography or background music, where individual works have limited influence, attempting to enforce copyright through training data restrictions may be futile. The AI can approximate any style or content using alternative works.

Conversely, in domains with iconic works—think of distinctive artistic styles, landmark literary voices, or signature musical compositions—copyright holders retain meaningful leverage. Removing these works from training data substantially limits what AI can generate.

The paper also highlights a tension in AI development: companies may prefer training on diverse, light-tailed corpora to minimize legal risk, while the most valuable AI capabilities may require learning from heavy-tailed distributions containing highly influential works.

From a legal perspective, the counterfactual dependence criterion offers a more principled basis for infringement claims than substantial similarity. It asks: "Was this specific work necessary for the AI to generate this output?" rather than "Does the output look similar to this work?" This shift could resolve current litigation ambiguities around style imitation.

## Takeaways

1. Traditional copyright concepts like "substantial similarity" are inadequate for generative AI, which can imitate style without copying content
2. A work-specific counterfactual dependence test—asking whether AI output could exist without a particular training work—provides a more suitable infringement criterion
3. The effectiveness of copyright regulation on AI depends critically on whether creative influence follows light-tailed or heavy-tailed distributions
4. In light-tailed creative domains, individual works become asymptotically irrelevant, making copyright regulation ineffective against AI generation
5. In heavy-tailed domains with "superstar" works, copyright regulation maintains persistent constraining power over AI systems
6. Policy should be domain-specific, recognizing that one-size-fits-all AI copyright rules will be either too restrictive or too permissive depending on the creative field
7. The mathematical framework using closure operators provides a rigorous foundation for analyzing permissible AI generation under various regulatory regimes
:::

:::zh
**论文**: [2602.12270](https://arxiv.org/abs/2602.12270)
**作者**: Annie Liang, Jay Lu
**分类**: econ.TH, cs.AI, cs.GT

## 摘要

本文针对生成式AI给版权法带来的根本性挑战:能够模仿创作风格而不复制具体内容。作者提出了一个基于反事实依赖的新侵权标准——如果AI输出在训练语料库中缺少某个特定作品就无法生成,则构成侵权。通过使用闭包算子对生成系统建模,他们刻画了可允许的AI生成特性,并发现了一个显著的二分法:在轻尾创作分布中,单个作品的影响最终消失,监管对AI生成无法施加限制;在重尾分布中,监管能够持续约束AI生成。

## 主要贡献

- 引入基于反事实依赖的AI版权侵权标准,超越了"实质性相似"的传统概念
- 将生成式AI系统建模为将训练语料库映射到生成输出的闭包算子
- 证明了基于创作作品分布尾部行为的尖锐渐近二分法
- 论证了轻尾创作导致对单个作品的依赖逐渐消失
- 展示了重尾创作维持对AI生成的持续监管约束
- 在提出的框架下对可允许生成进行了形式化刻画

## 理论框架

论文将生成系统建模为闭包算子 $\mathcal{G}: 2^W \to 2^W$,其中 $W$ 是所有可能作品的空间。对于语料库 $C \subseteq W$,$\mathcal{G}(C)$ 表示AI可以从 $C$ 生成的所有作品。如果存在不包含 $w$ 所依赖的任何作品的语料库 $C$,但 $w \in \mathcal{G}(C)$,则作品 $w$ 是可允许的。

反事实依赖标准规定:如果对于包含作品 $w$ 的某个语料库 $C$,有 $w' \in \mathcal{G}(C)$ 但 $w' 
otin \mathcal{G}(C \setminus \{w\})$,则AI生成的作品 $w'$ 侵犯了作品 $w$ 的版权。这捕捉了 $w$ 对生成 $w'$ 至关重要的直觉。

闭包算子框架满足三个自然属性:扩展性($C \subseteq \mathcal{G}(C)$)、单调性(更大的语料库支持更多生成)和幂等性(应用两次生成与一次结果相同)。

## 渐近二分法

论文的核心结果揭示了有机创作生产的统计特性如何决定长期监管有效性。考虑随时间有机生成的创作作品序列 $w_1, w_2, \ldots$,令 $C_n = \{w_1, \ldots, w_n\}$。

**轻尾情况**:当单个作品的影响衰减足够快(轻尾分布)时,对于任何作品 $w_i$,随机生成的作品依赖于 $w_i$ 的概率在 $n \to \infty$ 时趋近于零。形式化表示为 $\mathbb{P}(w \text{ 依赖于 } w_i \mid w \in \mathcal{G}(C_n)) \to 0$。这意味着版权监管变得渐近无关——AI系统可以生成几乎任何可允许的作品而不依赖任何特定的受版权保护作品。

**重尾情况**:当创作影响遵循重尾分布(如幂律)时,某些作品保持持续影响力。生成作品依赖于高影响力作品的概率即使在 $n \to \infty$ 时也保持远离零的下界。这意味着监管继续无限期地约束AI生成,因为从训练数据中移除有影响力的作品会显著限制输出空间。

这种二分法具有深远影响:在创作相对均匀的领域(轻尾),版权法可能无法有效监管AI;在具有"超级明星"作品的领域(重尾),监管保持强大效力。

## 政策与实践启示

该框架表明AI版权政策应该是特定领域的,反映创作影响力的底层分布。在库存摄影或背景音乐等领域,单个作品的影响有限,试图通过训练数据限制来执行版权可能是徒劳的。AI可以使用替代作品近似任何风格或内容。

相反,在具有标志性作品的领域——如独特的艺术风格、里程碑式的文学声音或标志性音乐作品——版权持有者保留有意义的影响力。从训练数据中移除这些作品会实质性限制AI能够生成的内容。

论文还强调了AI开发中的一个张力:公司可能更倾向于在多样化的轻尾语料库上训练以最小化法律风险,而最有价值的AI能力可能需要从包含高影响力作品的重尾分布中学习。

从法律角度看,反事实依赖标准为侵权主张提供了比实质性相似更有原则的基础。它询问:"这个特定作品对于AI生成此输出是否必要?"而不是"输出看起来是否与这个作品相似?"这种转变可以解决当前围绕风格模仿的诉讼模糊性。

## 要点总结

1. 传统版权概念如"实质性相似"不适用于生成式AI,后者可以模仿风格而不复制内容
2. 针对特定作品的反事实依赖测试——询问AI输出是否能在没有特定训练作品的情况下存在——提供了更合适的侵权标准
3. 版权监管对AI的有效性关键取决于创作影响力是遵循轻尾还是重尾分布
4. 在轻尾创作领域,单个作品变得渐近无关,使得版权监管对AI生成无效
5. 在具有"超级明星"作品的重尾领域,版权监管对AI系统保持持续约束力
6. 政策应该是特定领域的,认识到一刀切的AI版权规则在不同创作领域会过于限制或过于宽松
7. 使用闭包算子的数学框架为分析各种监管制度下的可允许AI生成提供了严格基础
:::
