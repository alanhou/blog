---
title:
  en: "Unmasking the Factual-Conceptual Gap in Persian Language Models"
  zh: "揭示波斯语语言模型中的事实-概念鸿沟"
description:
  en: "DivanBench reveals that Persian LLMs can recall cultural facts but fail to reason about social norms, showing a 21% performance gap between factual retrieval and situational application."
  zh: "DivanBench基准测试揭示波斯语大语言模型能够回忆文化事实,但无法对社会规范进行推理,在事实检索和情境应用之间存在21%的性能差距。"
date: 2026-02-21
tags: ["arxiv", "ai", "cs.cl"]
image: "/arxiv-visuals/arxiv-unmasking-the-factual-conceptual-gap-in.png"
---

:::en
**Paper**: [2602.17623](https://arxiv.org/abs/2602.17623)
**Authors**: Alireza Sakhaeirad, Ali Ma'manpoosh, Arshia Hemmat
**Categories**: cs.CL

## Abstract

This paper introduces DivanBench, a diagnostic benchmark designed to evaluate Persian language models' ability to reason about cultural norms beyond mere factual memorization. The benchmark focuses on superstitions and customs—arbitrary, context-dependent rules that cannot be derived through simple logical deduction. Testing seven Persian LLMs across 315 questions spanning three task types, the researchers uncover a critical gap: while models can retrieve cultural facts, they struggle to apply this knowledge in practical scenarios, exhibiting a 21% performance drop. The study reveals severe acquiescence bias where models correctly identify appropriate behaviors but fail to reject violations, and surprisingly, continuous Persian pretraining amplifies rather than mitigates these issues.

## Key Contributions

- Introduction of DivanBench, a novel benchmark with 315 questions testing cultural reasoning through factual retrieval, paired scenario verification, and situational reasoning tasks
- Empirical evaluation of seven Persian LLMs revealing a systematic 21% performance gap between factual knowledge retrieval and scenario-based application
- Discovery of severe acquiescence bias in Persian models that accept both correct and incorrect cultural behaviors
- Evidence that continuous Persian pretraining can degrade reasoning capabilities rather than improve them
- Demonstration that cultural competence requires internalization of underlying schemas, not just pattern mimicry from scaled monolingual data

## The Factual-Conceptual Divide

The core insight of this research lies in distinguishing between two types of cultural knowledge: factual recall and conceptual reasoning. Persian LLMs demonstrate proficiency in answering direct questions about cultural practices—for instance, knowing that breaking a mirror is considered unlucky in Persian culture. However, when presented with scenarios requiring application of this knowledge, performance deteriorates significantly.

This gap manifests most clearly in the benchmark's three-tiered structure. Factual retrieval tasks ask straightforward questions about customs and superstitions. Paired scenario verification presents two situations and asks which violates cultural norms. Situational reasoning requires models to evaluate complex social contexts and determine appropriate behavior. The 21% performance degradation from the first to the third task type reveals that models lack the conceptual frameworks necessary to operationalize their factual knowledge.

The researchers argue this reflects a fundamental limitation in how models acquire cultural competence. Rather than developing internal representations of the social schemas that generate cultural rules, models learn surface-level associations between contexts and behaviors. When faced with novel situations requiring schema-based inference, these shallow representations prove insufficient.

## Acquiescence Bias and Its Amplification

Perhaps the most troubling finding is the severe acquiescence bias exhibited by Persian LLMs. Models consistently agree with presented statements, correctly identifying appropriate cultural behaviors but failing to reject clear violations. This creates a paradoxical situation where a model might correctly state that gifting knives is considered bad luck, yet when presented with a scenario describing someone gifting knives as culturally appropriate, the model agrees.

This bias appears to stem from the models' training objective of predicting plausible continuations. In Persian text corpora, statements about cultural practices are typically affirmative descriptions rather than negations or corrections. Models thus learn to generate agreement patterns without developing the critical reasoning needed to identify contradictions.

Counterintuitively, continuous pretraining on Persian data amplifies this bias rather than correcting it. The researchers hypothesize that additional exposure to affirmative cultural descriptions reinforces agreement patterns while providing insufficient examples of norm violations and their rejections. This suggests that simply scaling monolingual data—a common approach in multilingual NLP—may be inadequate or even counterproductive for developing robust cultural reasoning.

## Implications for Multilingual AI Development

The findings challenge prevailing assumptions in multilingual NLP about how models acquire cultural competence. The research demonstrates that cultural understanding cannot be reduced to factual knowledge accumulation. Models require exposure to the reasoning processes that connect cultural facts to appropriate behaviors in diverse contexts.

This has significant implications for benchmark design. Existing Persian NLP evaluations focus on pragmatics and politeness but rarely test whether models can distinguish between memorized patterns and genuine understanding of underlying social schemas. DivanBench's focus on superstitions and customs—arbitrary rules that resist logical derivation—provides a more stringent test of cultural reasoning.

The work also raises questions about evaluation methodology in low-resource languages. If continuous pretraining can degrade reasoning capabilities, researchers must carefully consider not just the quantity but the composition and structure of training data. Future work might explore curriculum learning approaches that explicitly teach models to identify norm violations, or contrastive learning methods that present both appropriate and inappropriate cultural behaviors.

## Takeaways

1. Persian LLMs exhibit a 21% performance gap between retrieving cultural facts and applying them in scenarios, revealing that factual knowledge does not automatically translate to reasoning capability.

2. Severe acquiescence bias causes models to accept both correct behaviors and clear violations of cultural norms, suggesting they learn agreement patterns rather than critical evaluation skills.

3. Continuous Persian pretraining amplifies reasoning failures rather than improving them, challenging the assumption that more monolingual data inherently enhances cultural competence.

4. Cultural understanding requires internalization of underlying social schemas, not just pattern recognition from scaled datasets—models must learn the generative principles behind cultural rules.

5. DivanBench's focus on arbitrary, context-dependent customs provides a more rigorous test of cultural reasoning than existing benchmarks that emphasize factual recall or surface-level pragmatics.
:::

:::zh
**论文**: [2602.17623](https://arxiv.org/abs/2602.17623)
**作者**: Alireza Sakhaeirad, Ali Ma'manpoosh, Arshia Hemmat
**分类**: cs.CL

## 摘要

本文介绍了DivanBench,这是一个诊断性基准测试,旨在评估波斯语语言模型在文化规范推理方面的能力,而不仅仅是事实记忆。该基准专注于迷信和习俗——这些是无法通过简单逻辑推导得出的任意性、依赖上下文的规则。研究人员通过315个问题测试了七个波斯语大语言模型,这些问题涵盖三种任务类型,揭示了一个关键差距:虽然模型能够检索文化事实,但在实际场景中应用这些知识时却表现不佳,性能下降21%。研究发现了严重的默认同意偏差,模型能正确识别适当行为但无法拒绝明显的违规行为,而且令人惊讶的是,持续的波斯语预训练反而放大了这些问题。

## 主要贡献

- 提出DivanBench新型基准测试,包含315个问题,通过事实检索、配对场景验证和情境推理任务测试文化推理能力
- 对七个波斯语大语言模型进行实证评估,揭示事实知识检索与基于场景应用之间存在系统性的21%性能差距
- 发现波斯语模型存在严重的默认同意偏差,会同时接受正确和错误的文化行为
- 证明持续的波斯语预训练可能降低而非提升推理能力
- 论证文化能力需要内化底层图式,而不仅仅是从大规模单语数据中模仿模式

## 事实与概念的鸿沟

本研究的核心洞察在于区分两种类型的文化知识:事实回忆和概念推理。波斯语大语言模型在回答关于文化实践的直接问题时表现出色——例如,知道在波斯文化中打破镜子被认为是不吉利的。然而,当面对需要应用这些知识的场景时,性能显著下降。

这一差距在基准测试的三层结构中表现得最为明显。事实检索任务询问关于习俗和迷信的直接问题。配对场景验证呈现两种情况并询问哪种违反了文化规范。情境推理要求模型评估复杂的社会背景并确定适当的行为。从第一种到第三种任务类型21%的性能下降揭示,模型缺乏将事实知识操作化所需的概念框架。

研究人员认为这反映了模型获取文化能力方式的根本局限。模型没有发展出生成文化规则的社会图式的内部表征,而是学习了上下文与行为之间的表面关联。当面对需要基于图式推理的新情况时,这些浅层表征被证明是不够的。

## 默认同意偏差及其放大效应

也许最令人不安的发现是波斯语大语言模型表现出的严重默认同意偏差。模型持续同意所呈现的陈述,能正确识别适当的文化行为,但无法拒绝明显的违规行为。这造成了一种矛盾的情况:模型可能正确地陈述赠送刀具被认为是不吉利的,但当呈现一个描述某人赠送刀具为文化上适当行为的场景时,模型却表示同意。

这种偏差似乎源于模型预测合理延续的训练目标。在波斯语文本语料库中,关于文化实践的陈述通常是肯定性描述,而不是否定或纠正。因此,模型学会了生成同意模式,却没有发展出识别矛盾所需的批判性推理能力。

与直觉相反,在波斯语数据上的持续预训练放大了这种偏差而不是纠正它。研究人员假设,对肯定性文化描述的额外接触强化了同意模式,同时提供的规范违反及其拒绝的例子不足。这表明简单地扩展单语数据——多语言自然语言处理中的常见方法——可能不足以甚至适得其反地发展稳健的文化推理能力。

## 对多语言AI发展的启示

这些发现挑战了多语言自然语言处理中关于模型如何获取文化能力的主流假设。研究表明,文化理解不能简化为事实知识的积累。模型需要接触将文化事实与不同情境中适当行为联系起来的推理过程。

这对基准测试设计具有重要意义。现有的波斯语自然语言处理评估侧重于语用学和礼貌,但很少测试模型是否能区分记忆的模式和对底层社会图式的真正理解。DivanBench专注于迷信和习俗——抵制逻辑推导的任意规则——为文化推理提供了更严格的测试。

这项工作还提出了关于低资源语言评估方法的问题。如果持续预训练可能降低推理能力,研究人员必须仔细考虑的不仅是训练数据的数量,还有其组成和结构。未来的工作可能探索明确教导模型识别规范违反的课程学习方法,或呈现适当和不适当文化行为的对比学习方法。

## 要点总结

1. 波斯语大语言模型在检索文化事实和在场景中应用它们之间表现出21%的性能差距,揭示事实知识不会自动转化为推理能力。

2. 严重的默认同意偏差导致模型同时接受正确行为和明显违反文化规范的行为,表明它们学习的是同意模式而非批判性评估技能。

3. 持续的波斯语预训练放大了推理失败而非改善它们,挑战了更多单语数据本质上增强文化能力的假设。

4. 文化理解需要内化底层社会图式,而不仅仅是从大规模数据集中识别模式——模型必须学习文化规则背后的生成原则。

5. DivanBench专注于任意的、依赖上下文的习俗,为文化推理提供了比强调事实回忆或表面语用学的现有基准更严格的测试。
:::
