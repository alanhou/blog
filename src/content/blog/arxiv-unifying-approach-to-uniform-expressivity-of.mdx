---
title:
  en: "Unifying Approach to Uniform Expressivity of Graph Neural Networks"
  zh: "图神经网络统一表达能力的统一方法"
description:
  en: "A theoretical framework introducing Template GNNs (T-GNNs) that unifies the analysis of GNN expressivity through template-based aggregation and establishes equivalence with graded template modal logic."
  zh: "提出模板图神经网络(T-GNNs)理论框架,通过基于模板的聚合统一分析GNN表达能力,并建立与分级模板模态逻辑的等价性。"
date: 2026-02-23
tags: ["arxiv", "ai", "cs.lg", "cs.ai", "cs.lo"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.18409](https://arxiv.org/abs/2602.18409)
**Authors**: Huan Luo, Jonni Virtema
**Categories**: cs.LG, cs.AI, cs.LO

## Abstract

This paper addresses a fundamental question in graph neural network theory: how to systematically understand and compare the expressive power of different GNN architectures. The authors introduce Template GNNs (T-GNNs), a generalized framework that formalizes the recent architectural trend of incorporating substructural information into GNNs. In T-GNNs, node features are updated by aggregating over valid template embeddings from a specified set of graph templates. The paper establishes a formal correspondence between T-GNNs and a newly proposed logic called Graded Template Modal Logic (GML(T)), along with generalized notions of template-based bisimulation and Weisfeiler-Leman algorithm. This unifying framework demonstrates that standard AC-GNNs and their recent variants can be interpreted as specific instantiations of T-GNNs, providing a principled approach to analyzing GNN expressivity.

## Key Contributions

- Introduction of Template GNNs (T-GNNs), a generalized architectural framework that captures GNNs performing aggregation over arbitrary graph templates
- Proposal of Graded Template Modal Logic (GML(T)) as the logical counterpart to T-GNNs
- Establishment of formal equivalence between the expressive power of T-GNNs and GML(T)
- Generalization of template-based bisimulation and Weisfeiler-Leman algorithm to the template setting
- Demonstration that standard AC-GNNs and recent variants (subgraph GNNs, cycle-counting GNNs) are instantiations of the T-GNN framework

## Theoretical Framework

The T-GNN framework operates on a simple yet powerful principle: instead of aggregating only over immediate neighbors or global structures, nodes aggregate information over all valid embeddings of predefined graph templates. Given a set of templates $\mathcal{T}$, a T-GNN updates node features by:

$$h_v^{(k+1)} = \text{COMBINE}\left(h_v^{(k)}, \text{AGGREGATE}\left(\{h_{\phi}^{(k)} : \phi \in \text{Emb}(G, \mathcal{T}, v)\}\right)\right)$$

where $\text{Emb}(G, \mathcal{T}, v)$ denotes all valid template embeddings that include node $v$. This formulation naturally generalizes standard message-passing GNNs (where templates are single edges) and recent substructure-aware architectures.

The corresponding logic GML(T) extends modal logic with graded modalities indexed by templates. A formula $\langle T \rangle_{\geq k} \phi$ expresses that there exist at least $k$ embeddings of template $T$ satisfying property $\phi$. This grading mechanism captures the counting capabilities inherent in GNN aggregation functions.

## Expressivity Analysis and Equivalence Results

The paper's central theoretical result establishes a tight correspondence between T-GNNs and GML(T). Specifically, two graphs are indistinguishable by T-GNNs if and only if they satisfy the same GML(T) formulas. This equivalence is proven through:

1. **Template-based bisimulation**: A generalization of standard bisimulation that respects template embeddings, providing a game-theoretic characterization of GML(T) equivalence
2. **Template Weisfeiler-Leman algorithm**: An extension of the classical WL test that refines node colors based on template embedding patterns
3. **Three-way equivalence**: Demonstrating that T-GNN indistinguishability, GML(T) equivalence, and template-WL equivalence all coincide

This result provides a powerful tool for analyzing GNN expressivity: to understand what a particular GNN architecture can distinguish, one can equivalently study the corresponding logic or algorithmic test. The framework also reveals fundamental limitations—T-GNNs with finite template sets cannot distinguish graphs that differ only in properties requiring unbounded template sizes.

## Unifying Existing Architectures

A key insight of the paper is showing how diverse GNN architectures fit within the T-GNN framework:

- **Standard MPNNs**: Instantiated with single-edge templates
- **Subgraph GNNs**: Use templates corresponding to specific subgraph patterns (triangles, cliques, etc.)
- **Cycle-counting GNNs**: Employ cycle templates of various lengths
- **Higher-order GNNs**: Captured by templates representing k-tuples of nodes

This unification reveals that many seemingly different architectural innovations are actually exploring different regions of the same design space—the choice of template set $\mathcal{T}$. The framework thus provides a systematic way to compare architectures and understand their relative expressivity based on their template sets.

## Takeaways

1. Template GNNs provide a unifying mathematical framework for understanding modern GNN architectures that incorporate substructural information
2. The equivalence between T-GNNs, GML(T), and template-WL algorithms offers multiple perspectives for analyzing expressivity
3. Many recent GNN variants can be understood as instantiations of T-GNNs with different template choices
4. The framework reveals fundamental trade-offs: richer template sets increase expressivity but also computational complexity
5. This theoretical foundation enables principled design of new GNN architectures by selecting appropriate template sets for specific tasks
:::

:::zh
**论文**: [2602.18409](https://arxiv.org/abs/2602.18409)
**作者**: Huan Luo, Jonni Virtema
**分类**: cs.LG, cs.AI, cs.LO

## 摘要

本文探讨图神经网络理论中的一个基本问题:如何系统地理解和比较不同GNN架构的表达能力。作者提出了模板图神经网络(T-GNNs)这一广义框架,形式化了近期将子结构信息融入GNN的架构趋势。在T-GNNs中,节点特征通过聚合来自指定图模板集合的有效模板嵌入来更新。论文建立了T-GNNs与新提出的分级模板模态逻辑(GML(T))之间的形式对应关系,并提出了基于模板的互模拟和Weisfeiler-Leman算法的广义概念。这一统一框架证明了标准AC-GNNs及其近期变体可以被解释为T-GNNs的特定实例化,为分析GNN表达能力提供了原则性方法。

## 主要贡献

- 引入模板图神经网络(T-GNNs),这是一个广义架构框架,能够捕获在任意图模板上执行聚合的GNN
- 提出分级模板模态逻辑(GML(T))作为T-GNNs的逻辑对应物
- 建立T-GNNs表达能力与GML(T)之间的形式等价性
- 将基于模板的互模拟和Weisfeiler-Leman算法推广到模板设置
- 证明标准AC-GNNs和近期变体(子图GNN、循环计数GNN)都是T-GNN框架的实例化

## 理论框架

T-GNN框架基于一个简单而强大的原理:节点不仅聚合直接邻居或全局结构的信息,而是聚合所有预定义图模板的有效嵌入信息。给定模板集合$\mathcal{T}$,T-GNN通过以下方式更新节点特征:

$$h_v^{(k+1)} = \text{COMBINE}\left(h_v^{(k)}, \text{AGGREGATE}\left(\{h_{\phi}^{(k)} : \phi \in \text{Emb}(G, \mathcal{T}, v)\}\right)\right)$$

其中$\text{Emb}(G, \mathcal{T}, v)$表示包含节点$v$的所有有效模板嵌入。这一表述自然地推广了标准消息传递GNN(其中模板是单条边)和近期的子结构感知架构。

相应的逻辑GML(T)通过模板索引的分级模态扩展了模态逻辑。公式$\langle T \rangle_{\geq k} \phi$表示存在至少$k$个满足性质$\phi$的模板$T$嵌入。这种分级机制捕获了GNN聚合函数固有的计数能力。

## 表达能力分析与等价性结果

论文的核心理论结果建立了T-GNNs与GML(T)之间的紧密对应关系。具体而言,两个图在T-GNNs下不可区分当且仅当它们满足相同的GML(T)公式。这一等价性通过以下方式证明:

1. **基于模板的互模拟**:标准互模拟的推广,尊重模板嵌入,提供GML(T)等价性的博弈论刻画
2. **模板Weisfeiler-Leman算法**:经典WL测试的扩展,基于模板嵌入模式细化节点颜色
3. **三向等价性**:证明T-GNN不可区分性、GML(T)等价性和模板WL等价性完全一致

这一结果为分析GNN表达能力提供了强大工具:要理解特定GNN架构能够区分什么,可以等价地研究相应的逻辑或算法测试。该框架还揭示了基本限制——具有有限模板集的T-GNNs无法区分仅在需要无界模板大小的性质上不同的图。

## 统一现有架构

论文的一个关键洞察是展示了多样化的GNN架构如何融入T-GNN框架:

- **标准MPNN**:用单边模板实例化
- **子图GNN**:使用对应特定子图模式(三角形、团等)的模板
- **循环计数GNN**:采用各种长度的循环模板
- **高阶GNN**:由表示节点k元组的模板捕获

这种统一揭示了许多看似不同的架构创新实际上是在探索同一设计空间的不同区域——模板集$\mathcal{T}$的选择。因此,该框架提供了一种系统方法来比较架构并基于其模板集理解它们的相对表达能力。

## 要点总结

1. 模板GNN为理解融合子结构信息的现代GNN架构提供了统一的数学框架
2. T-GNNs、GML(T)和模板WL算法之间的等价性为分析表达能力提供了多重视角
3. 许多近期GNN变体可以理解为具有不同模板选择的T-GNNs实例化
4. 该框架揭示了基本权衡:更丰富的模板集增加表达能力但也增加计算复杂度
5. 这一理论基础通过为特定任务选择适当的模板集,使新GNN架构的原则性设计成为可能
:::
