---
title:
  en: "In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach"
  zh: "上下文自主网络事件响应:端到端大语言模型智能体方法"
description:
  en: "A lightweight LLM agent that autonomously responds to cyberattacks through in-context learning, achieving 23% faster recovery than frontier models without requiring handcrafted simulators."
  zh: "一个轻量级大语言模型智能体,通过上下文学习自主响应网络攻击,无需手工建模即可实现比前沿模型快23%的恢复速度。"
date: 2026-02-16
tags: ["arxiv", "ai", "cs.cr", "cs.ai"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.13156](https://arxiv.org/abs/2602.13156)
**Authors**: Yiran Gao, Kim Hammar, Tao Li
**Categories**: cs.CR, cs.AI

## Abstract

This paper introduces an end-to-end LLM-based agent for autonomous network incident response that eliminates the need for handcrafted simulators required by traditional reinforcement learning approaches. The agent integrates four core functionalities—perception, reasoning, planning, and action—into a single 14B parameter model. Through fine-tuning and chain-of-thought reasoning, the agent processes raw system logs to infer network states, updates attack model conjectures, simulates response outcomes, and generates effective countermeasures. The system demonstrates in-context adaptation by iteratively refining its understanding through comparison of simulated and actual observations, achieving up to 23% faster recovery times compared to frontier LLMs on real-world incident logs.

## Key Contributions

- **End-to-end agentic architecture** that unifies perception, reasoning, planning, and action in a single lightweight LLM without requiring separate simulators or handcrafted models
- **In-context learning mechanism** that enables the agent to autonomously adapt its attack conjectures and response strategies by comparing simulated outcomes with actual observations
- **Direct log processing capability** that preserves semantic information from raw system logs and alerts, avoiding information loss inherent in abstracted state representations
- **Practical deployment feasibility** with a 14B parameter model that runs on commodity hardware while outperforming larger frontier models by 23% in recovery speed

## Methodology and Architecture

The proposed agent architecture integrates four interconnected modules within a single LLM framework. The **perception module** processes raw system logs and security alerts to construct an understanding of the current network state, leveraging the model's pre-trained knowledge of system behaviors and attack patterns. Unlike traditional approaches that map logs to discrete state spaces, this module maintains rich semantic information from the original data.

The **reasoning module** employs chain-of-thought prompting to formulate and update hypotheses about ongoing attacks. By analyzing observed system behaviors and comparing them against known attack patterns, the agent builds a dynamic model of adversary tactics, techniques, and procedures (TTPs). This conjecture is continuously refined as new evidence emerges.

The **planning module** simulates potential response strategies by projecting their consequences on the inferred network state. Rather than relying on pre-built simulators, the LLM uses its understanding of system dynamics to mentally model how different interventions would affect the attack progression and system recovery.

Finally, the **action module** generates concrete response commands based on the optimal strategy identified through planning. The agent then observes the actual outcomes of its actions and feeds this information back into the perception-reasoning loop, enabling iterative refinement of its attack model and response strategy.

## Experimental Results and Performance

The evaluation uses real-world incident logs documented in cybersecurity literature, providing authentic test cases with known attack patterns and optimal response strategies. The agent demonstrates significant performance advantages over baseline approaches:

**Recovery Speed**: The proposed agent achieves system recovery up to 23% faster than frontier LLMs when measured from initial detection to full remediation. This improvement stems from more accurate attack model inference and more effective response planning.

**Adaptation Capability**: Through in-context learning, the agent successfully refines its attack conjectures across multiple iterations. Initial hypotheses based on limited observations are progressively corrected as more evidence accumulates, demonstrating genuine adaptive behavior without requiring retraining.

**Resource Efficiency**: Operating with only 14B parameters, the agent runs on commodity hardware while maintaining competitive or superior performance compared to much larger models. This efficiency makes the approach practical for deployment in resource-constrained environments.

**Semantic Preservation**: By processing raw logs directly rather than abstracted state representations, the agent leverages subtle indicators and contextual information that would be lost in traditional state-based approaches, leading to more accurate threat assessment.

## Implications and Future Directions

This work represents a paradigm shift in autonomous incident response, moving from simulation-based reinforcement learning to knowledge-driven in-context adaptation. The elimination of handcrafted simulators significantly reduces the engineering effort required for deployment while improving adaptability to novel attack patterns not seen during training.

The success of this approach suggests several promising research directions. First, incorporating multi-modal data sources beyond text logs—such as network traffic patterns, system call traces, and threat intelligence feeds—could further enhance perception accuracy. Second, extending the framework to collaborative multi-agent scenarios where multiple LLM agents coordinate responses across distributed systems presents interesting challenges in communication and consensus.

The demonstrated ability to run effectively on commodity hardware opens possibilities for edge deployment in resource-constrained environments. However, questions remain about the agent's performance against sophisticated adversarial attacks specifically designed to mislead LLM-based defenders, an area requiring further investigation.

From a broader perspective, this work exemplifies how large language models' pre-trained knowledge can be leveraged for complex decision-making tasks beyond natural language processing, potentially inspiring similar approaches in other domains requiring autonomous adaptation to dynamic environments.

## Takeaways

1. LLM agents can autonomously respond to cyberattacks through in-context learning without requiring handcrafted simulators, achieving 23% faster recovery than frontier models
2. Integrating perception, reasoning, planning, and action into a single 14B parameter model enables practical deployment on commodity hardware
3. Processing raw system logs directly preserves semantic information that improves threat detection compared to abstracted state representations
4. Iterative refinement of attack conjectures through comparison of simulated and actual outcomes demonstrates genuine adaptive capability
5. This approach represents a shift from simulation-based RL to knowledge-driven adaptation, reducing engineering overhead while improving flexibility against novel threats
:::

:::zh
**论文**: [2602.13156](https://arxiv.org/abs/2602.13156)
**作者**: Yiran Gao, Kim Hammar, Tao Li
**分类**: cs.CR, cs.AI

## 摘要

本文提出了一种基于大语言模型的端到端自主网络事件响应智能体,无需传统强化学习方法所需的手工构建模拟器。该智能体将感知、推理、规划和行动四个核心功能集成到单个140亿参数模型中。通过微调和链式思维推理,智能体能够处理原始系统日志以推断网络状态,更新攻击模型假设,模拟响应结果,并生成有效的对抗措施。系统通过比较模拟结果与实际观察来迭代优化其理解,展现出上下文适应能力,在真实事件日志上实现了比前沿大语言模型快23%的恢复速度。

## 主要贡献

- **端到端智能体架构**,在单个轻量级大语言模型中统一感知、推理、规划和行动功能,无需独立模拟器或手工建模
- **上下文学习机制**,使智能体能够通过比较模拟结果与实际观察自主调整攻击假设和响应策略
- **直接日志处理能力**,保留原始系统日志和告警的语义信息,避免抽象状态表示固有的信息损失
- **实际部署可行性**,140亿参数模型可在普通硬件上运行,同时在恢复速度上超越更大规模前沿模型23%

## 方法论与架构设计

所提出的智能体架构在单一大语言模型框架内集成了四个相互关联的模块。**感知模块**处理原始系统日志和安全告警以构建对当前网络状态的理解,利用模型预训练的系统行为和攻击模式知识。与将日志映射到离散状态空间的传统方法不同,该模块保留了原始数据的丰富语义信息。

**推理模块**采用链式思维提示来构建和更新关于正在进行的攻击的假设。通过分析观察到的系统行为并与已知攻击模式对比,智能体建立了对手战术、技术和程序(TTP)的动态模型。这一假设随着新证据的出现而持续优化。

**规划模块**通过预测潜在响应策略对推断网络状态的影响来模拟其后果。该模块不依赖预构建的模拟器,而是利用大语言模型对系统动态的理解来心智建模不同干预措施如何影响攻击进展和系统恢复。

最后,**行动模块**根据规划识别的最优策略生成具体响应命令。智能体随后观察其行动的实际结果,并将此信息反馈到感知-推理循环中,实现攻击模型和响应策略的迭代优化。

## 实验结果与性能表现

评估使用网络安全文献中记录的真实事件日志,提供具有已知攻击模式和最优响应策略的真实测试案例。智能体相比基线方法展现出显著的性能优势:

**恢复速度**:从初始检测到完全修复的测量中,所提出的智能体实现系统恢复的速度比前沿大语言模型快23%。这一改进源于更准确的攻击模型推断和更有效的响应规划。

**适应能力**:通过上下文学习,智能体成功地在多次迭代中优化其攻击假设。基于有限观察的初始假设随着更多证据的积累而逐步修正,展现出真正的自适应行为而无需重新训练。

**资源效率**:仅使用140亿参数运行,智能体可在普通硬件上运行,同时保持与更大规模模型相当或更优的性能。这种效率使该方法在资源受限环境中的部署成为可能。

**语义保留**:通过直接处理原始日志而非抽象状态表示,智能体利用了传统基于状态方法中会丢失的细微指标和上下文信息,从而实现更准确的威胁评估。

## 影响与未来方向

这项工作代表了自主事件响应的范式转变,从基于模拟的强化学习转向知识驱动的上下文适应。消除手工构建模拟器显著减少了部署所需的工程工作量,同时提高了对训练期间未见过的新型攻击模式的适应性。

该方法的成功指向了几个有前景的研究方向。首先,整合文本日志之外的多模态数据源——如网络流量模式、系统调用跟踪和威胁情报源——可以进一步提升感知准确性。其次,将框架扩展到协作多智能体场景,让多个大语言模型智能体在分布式系统中协调响应,在通信和共识方面提出了有趣的挑战。

在普通硬件上有效运行的能力为资源受限环境中的边缘部署开辟了可能性。然而,智能体对专门设计来误导基于大语言模型防御者的复杂对抗性攻击的性能表现仍存在疑问,这是一个需要进一步研究的领域。

从更广泛的视角来看,这项工作展示了如何将大语言模型的预训练知识用于自然语言处理之外的复杂决策任务,可能为其他需要对动态环境进行自主适应的领域带来类似方法的启发。

## 要点总结

1. 大语言模型智能体可通过上下文学习自主响应网络攻击,无需手工构建模拟器,实现比前沿模型快23%的恢复速度
2. 将感知、推理、规划和行动集成到单个140亿参数模型中,使得在普通硬件上实际部署成为可能
3. 直接处理原始系统日志保留了语义信息,相比抽象状态表示提升了威胁检测能力
4. 通过比较模拟结果与实际结果迭代优化攻击假设,展现出真正的自适应能力
5. 该方法代表了从基于模拟的强化学习向知识驱动适应的转变,减少了工程开销同时提高了对新型威胁的灵活性
:::
