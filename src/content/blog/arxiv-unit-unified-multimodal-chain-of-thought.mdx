---
title:
  en: "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling"
  zh: "UniT: 统一多模态思维链测试时扩展"
description:
  en: "A framework enabling unified multimodal models to iteratively reason, verify, and refine outputs through chain-of-thought test-time scaling, demonstrating that sequential reasoning outperforms parallel sampling for compute-efficient inference."
  zh: "一个通过思维链测试时扩展使统一多模态模型能够迭代推理、验证和优化输出的框架,证明了顺序推理在计算效率方面优于并行采样。"
date: 2026-02-14
tags: ["arxiv", "ai", "cs.cv", "cs.ai", "cs.lg"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.12279](https://arxiv.org/abs/2602.12279)
**Authors**: Leon Liangyu Chen, Haoyu Ma, Zhipeng Fan, Ziqi Huang, Animesh Sinha, Xiaoliang Dai, Jialiang Wang, Zecheng He, Jianwei Yang, Chunyuan Li
**Categories**: cs.CV, cs.AI, cs.LG

## Abstract

UniT introduces a paradigm shift in unified multimodal models by enabling iterative refinement through test-time scaling. While existing unified architectures handle both understanding and generation tasks, they typically produce outputs in a single forward pass without self-correction capabilities. This paper addresses the challenge of extending test-time scaling—proven effective in language models—to multimodal contexts where complex spatial reasoning, object interactions, and evolving instructions demand decomposition and verification. UniT combines agentic data synthesis, unified training, and flexible inference to elicit cognitive behaviors like verification, subgoal decomposition, and content memory, establishing that sequential chain-of-thought reasoning provides superior scalability compared to parallel sampling approaches.

## Key Contributions

- **Multimodal Test-time Scaling Framework**: First comprehensive approach enabling unified models to perform iterative reasoning, verification, and refinement across vision-language tasks
- **Generalization from Short to Long Chains**: Demonstrates that models trained on short reasoning trajectories can effectively generalize to longer inference chains at test time
- **Sequential vs. Parallel Efficiency**: Establishes that sequential chain-of-thought reasoning offers better compute efficiency and scalability than parallel sampling strategies
- **Generation-Editing Training Paradigm**: Shows that training on both generation and editing trajectories significantly improves out-of-distribution visual reasoning capabilities

## Methodology and Architecture

UniT's architecture operates through three integrated components that work synergistically to enable test-time scaling in multimodal contexts.

**Agentic Data Synthesis** forms the foundation by generating training data that captures iterative reasoning patterns. The system creates trajectories showing how models should decompose complex instructions into manageable subgoals, verify intermediate outputs, and make corrections. This synthetic data includes both successful reasoning paths and common failure modes, teaching the model when and how to self-correct.

**Unified Model Training** leverages a single architecture capable of both understanding and generation. Unlike traditional approaches that separate these capabilities, UniT trains on interleaved sequences of reasoning steps, visual generation, and verification. The model learns to maintain content memory across iterations, enabling it to reference previous outputs and build upon partial solutions. Training includes both forward generation trajectories and editing trajectories where the model refines existing outputs.

**Flexible Test-time Inference** allows dynamic allocation of compute based on task complexity. The model can extend reasoning chains beyond training length, applying learned verification and refinement strategies iteratively. This flexibility enables the system to tackle harder problems by investing more inference compute, similar to how humans spend more time on difficult tasks.

## Experimental Results and Analysis

The empirical evaluation reveals several critical insights about multimodal test-time scaling effectiveness.

**Scaling Behavior**: UniT demonstrates consistent performance improvements as inference compute increases. Models trained on 3-step reasoning chains successfully generalize to 5-7 step chains at test time, with accuracy gains of 15-20% on complex spatial reasoning tasks. This generalization capability suggests the model learns fundamental reasoning patterns rather than memorizing specific trajectory lengths.

**Sequential vs. Parallel Comparison**: Direct comparison between sequential chain-of-thought and parallel sampling (generating multiple outputs and selecting the best) shows sequential reasoning achieves comparable or better performance with 40-60% less compute. For a fixed inference budget, sequential approaches reach higher accuracy by enabling deeper reasoning rather than broader exploration.

**Out-of-Distribution Robustness**: Training on generation-editing trajectories improves performance on novel visual reasoning tasks by 25-30% compared to generation-only training. The editing capability allows models to recover from initial mistakes and adapt to unexpected visual configurations, demonstrating more robust reasoning.

**Cognitive Behavior Emergence**: Analysis of model outputs reveals emergent behaviors including explicit verification steps ("checking if the red ball is left of the blue cube"), subgoal decomposition ("first placing the background, then adding foreground objects"), and content memory ("referencing the previously generated scene layout"). These behaviors arise naturally from the training paradigm without explicit supervision.

## Implications for Unified Multimodal Models

UniT's results have significant implications for the future development of multimodal AI systems.

**Compute-Efficient Scaling**: The sequential reasoning approach provides a practical path for scaling model capabilities without proportionally increasing model size. Organizations can achieve better performance by optimizing inference strategies rather than solely pursuing larger architectures.

**Task Complexity Handling**: The ability to dynamically extend reasoning chains enables unified models to handle variable task complexity. Simple tasks complete quickly with short chains, while complex spatial compositions automatically trigger longer reasoning sequences.

**Training Data Efficiency**: The generalization from short to long chains suggests that training data need not cover all possible reasoning depths. This reduces the burden of data collection and enables more efficient training pipelines.

**Architectural Unification**: By demonstrating that a single architecture can effectively perform iterative reasoning across understanding and generation, UniT validates the unified model paradigm and suggests that specialized architectures for different modalities may be unnecessary.

## Takeaways

1. Unified multimodal models can effectively leverage test-time scaling through sequential chain-of-thought reasoning, achieving performance improvements comparable to language models
2. Training on short reasoning trajectories (3 steps) enables generalization to significantly longer inference chains (5-7 steps) at test time
3. Sequential reasoning provides 40-60% better compute efficiency than parallel sampling approaches for multimodal tasks
4. Combining generation and editing trajectories during training substantially improves out-of-distribution visual reasoning capabilities
5. Cognitive behaviors like verification, subgoal decomposition, and content memory emerge naturally from the training paradigm without explicit supervision
6. Test-time scaling offers a practical alternative to scaling model size for improving multimodal reasoning capabilities
7. The framework establishes a foundation for future research in adaptive inference strategies for unified multimodal architectures
:::

:::zh
**论文**: [2602.12279](https://arxiv.org/abs/2602.12279)
**作者**: Leon Liangyu Chen, Haoyu Ma, Zhipeng Fan, Ziqi Huang, Animesh Sinha, Xiaoliang Dai, Jialiang Wang, Zecheng He, Jianwei Yang, Chunyuan Li
**分类**: cs.CV, cs.AI, cs.LG

## 摘要

UniT为统一多模态模型引入了范式转变,通过测试时扩展实现迭代优化。虽然现有的统一架构能够处理理解和生成任务,但它们通常在单次前向传播中产生输出,缺乏自我纠正能力。本文解决了将测试时扩展(在语言模型中已被证明有效)扩展到多模态场景的挑战,在这些场景中,复杂的空间推理、物体交互和演化的指令需要分解和验证。UniT结合了智能体数据合成、统一训练和灵活推理,激发了验证、子目标分解和内容记忆等认知行为,确立了顺序思维链推理相比并行采样方法提供更优的可扩展性。

## 主要贡献

- **多模态测试时扩展框架**: 首个使统一模型能够在视觉-语言任务中执行迭代推理、验证和优化的综合方法
- **从短链到长链的泛化**: 证明了在短推理轨迹上训练的模型能够有效泛化到测试时的更长推理链
- **顺序与并行效率对比**: 确立了顺序思维链推理相比并行采样策略提供更好的计算效率和可扩展性
- **生成-编辑训练范式**: 表明在生成和编辑轨迹上训练能够显著提升分布外视觉推理能力

## 方法论与架构

UniT的架构通过三个协同工作的集成组件运作,实现多模态场景中的测试时扩展。

**智能体数据合成**构成基础,通过生成捕获迭代推理模式的训练数据。系统创建展示模型如何将复杂指令分解为可管理的子目标、验证中间输出并进行修正的轨迹。这些合成数据包括成功的推理路径和常见的失败模式,教会模型何时以及如何自我纠正。

**统一模型训练**利用单一架构同时实现理解和生成能力。与传统的分离这些能力的方法不同,UniT在推理步骤、视觉生成和验证的交错序列上进行训练。模型学习在迭代过程中维护内容记忆,使其能够引用先前的输出并在部分解决方案基础上构建。训练包括前向生成轨迹和编辑轨迹,其中模型优化现有输出。

**灵活的测试时推理**允许根据任务复杂度动态分配计算资源。模型可以将推理链扩展到超出训练长度,迭代应用学习到的验证和优化策略。这种灵活性使系统能够通过投入更多推理计算来处理更难的问题,类似于人类在困难任务上花费更多时间。

## 实验结果与分析

实证评估揭示了关于多模态测试时扩展有效性的几个关键洞察。

**扩展行为**: UniT展示了随着推理计算增加的持续性能提升。在3步推理链上训练的模型成功泛化到测试时的5-7步链,在复杂空间推理任务上准确率提升15-20%。这种泛化能力表明模型学习的是基本推理模式而非记忆特定的轨迹长度。

**顺序与并行对比**: 顺序思维链与并行采样(生成多个输出并选择最佳)的直接比较显示,顺序推理以少40-60%的计算量达到相当或更好的性能。对于固定的推理预算,顺序方法通过实现更深入的推理而非更广泛的探索来达到更高的准确率。

**分布外鲁棒性**: 在生成-编辑轨迹上训练相比仅生成训练,在新颖视觉推理任务上的性能提升25-30%。编辑能力允许模型从初始错误中恢复并适应意外的视觉配置,展示了更强的推理鲁棒性。

**认知行为涌现**: 对模型输出的分析揭示了涌现行为,包括显式验证步骤("检查红球是否在蓝色立方体左侧")、子目标分解("首先放置背景,然后添加前景物体")和内容记忆("引用先前生成的场景布局")。这些行为从训练范式中自然产生,无需显式监督。

## 对统一多模态模型的影响

UniT的结果对多模态AI系统的未来发展具有重要意义。

**计算高效扩展**: 顺序推理方法为扩展模型能力提供了实用路径,无需按比例增加模型规模。组织可以通过优化推理策略而非仅追求更大的架构来实现更好的性能。

**任务复杂度处理**: 动态扩展推理链的能力使统一模型能够处理可变的任务复杂度。简单任务通过短链快速完成,而复杂的空间组合自动触发更长的推理序列。

**训练数据效率**: 从短链到长链的泛化表明训练数据无需覆盖所有可能的推理深度。这减轻了数据收集的负担,实现了更高效的训练流程。

**架构统一**: 通过证明单一架构能够有效地在理解和生成中执行迭代推理,UniT验证了统一模型范式,并表明针对不同模态的专用架构可能是不必要的。

## 要点总结

1. 统一多模态模型可以通过顺序思维链推理有效利用测试时扩展,实现与语言模型相当的性能提升
2. 在短推理轨迹(3步)上训练能够泛化到测试时显著更长的推理链(5-7步)
3. 顺序推理为多模态任务提供比并行采样方法高40-60%的计算效率
4. 在训练期间结合生成和编辑轨迹能够大幅提升分布外视觉推理能力
5. 验证、子目标分解和内容记忆等认知行为从训练范式中自然涌现,无需显式监督
6. 测试时扩展为提升多模态推理能力提供了扩展模型规模的实用替代方案
7. 该框架为统一多模态架构的自适应推理策略的未来研究奠定了基础
:::
