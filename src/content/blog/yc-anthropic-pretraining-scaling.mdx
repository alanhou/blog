---
title:
  en: "Anthropic Head of Pretraining on Scaling Laws, Compute, and the Future of AI"
  zh: "Anthropic预训练负责人谈扩展定律、算力与AI的未来"
description:
  en: "Nick Joseph, Head of Pretraining at Anthropic, discusses scaling laws, distributed training, infrastructure optimization, and how the pre-training team has evolved"
  zh: "Anthropic预训练负责人Nick Joseph讨论扩展定律、分布式训练、基础设施优化以及预训练团队的演变"
date: 2025-09-30
tags: ["ycombinator", "ai", "anthropic", "pretraining", "scaling-laws", "compute"]
image: "https://i2.ytimg.com/vi/YFeb3yAxtjE/hqdefault.jpg"
---

import YouTube from '../../components/YouTube.astro';

<YouTube id="YFeb3yAxtjE" title="Anthropic Head of Pretraining on Scaling Laws, Compute, and the Future of AI" />

:::en
Nick Joseph, Head of Pretraining at Anthropic, shares insights on how AI models are trained at scale, the infrastructure challenges involved, and how the pre-training team has evolved over time.

## Background and Journey to Anthropic

### Career Path
- Started at Vicarious, originally an AGI lab that shifted to robotics products
- Worked on training computer vision models for robotics - first job in ML
- Learned ML infrastructure fundamentals at Vicarious
- Joined OpenAI on one of the safety teams, worked on code models
- Saw GPT-3 fine-tuned to write code and realized AI could self-improve
- Left OpenAI with the safety team leads to join Anthropic at founding

### Early Interest in AI Safety
- Internship at GiveWell (nonprofit evaluating charities) introduced AI safety concepts
- Initially skeptical - AI safety discussions were mostly theoretical at the time
- Models weren't good enough to pose real dangers yet
- Decided to work on AI: either safety would matter, or he'd build useful AI tools

## What is Pre-training?

### The Core Concept
- Scale is a key ingredient to making AI models better
- Need an objective with massive amounts of data
- The internet is the biggest single source of data humanity has created
- No manual labels needed - predict the next word from existing text

### How It Works
- Take text and predict the next word
- "The cat" -> predict what comes next
- Every word becomes a new training example
- Dense signal from massive data

### Scaling Laws
- As you add more compute, data, and parameters, models get predictably better
- Lower loss = better prediction of next word
- Original scaling laws paper showed 11 orders of magnitude of consistent trends
- This creates a positive feedback loop: train model -> make useful product -> get money -> buy more compute -> train better model

## Early Days at Anthropic

### Starting Small
- Team of about 10-12 people initially
- Much less funding than competitors like OpenAI
- GPT-3 cost about $5 million to train - significant but achievable
- Used cloud provider for compute

### Efficiency as Competitive Advantage
- "We have way less funding than everyone else, we have to be really efficient"
- Most people weren't very efficient with compute at the time
- Focused on getting the most out of available hardware

### Infrastructure Challenges
- Had to understand literal physical layout of chips
- Ran clustering algorithms to identify which rooms chips were in
- Network latency between different physical locations caused issues
- Constantly pushing limits of hardware

## Distributed Training Approaches

### Key Techniques
- **Data Parallelism**: Split data across multiple chips
- **Pipelining**: Chain operations across chips
- **Op-sharding**: Distribute operations across hardware

### Building Custom Infrastructure
- No great open-source packages existed at the time
- Wrote their own all-reduce implementation
- Needed to modify everything as they scaled beyond what Facebook had done
- Couldn't rely on external packages they'd constantly need to modify

### Why Build In-House?
- Going to bigger scale than existing solutions supported
- Need full control to optimize at every level
- Can make architecture changes that simplify efficiency problems

## Scaling Laws and Conviction

### The Physicist's Perspective
- Original scaling laws paper showed remarkably consistent trends
- Debate about whether trends would continue seemed "nonsensical"
- 11 orders of magnitude of data, arguing about one more point seemed unlikely to fail
- "What are these people doing? They're all missing the big picture"

### Different Lab Cultures
- FAIR (Facebook AI Research) had PhD-style independent research culture
- People fighting for their own compute, pursuing individual ideas
- Training large language models requires collaboration on infrastructure
- Not publishable work - "I got 5% more efficiency" isn't a paper
- Anthropic's culture focused on collaborative scaling

## Team Evolution Over Time

### Early Days
- First 3-6 months: tried to read every PR in the codebase
- Knew all the pieces, could make cross-cutting changes easily
- Could spot efficiency improvements by changing architecture

### Growing Specialization
- As team grew, people became deep experts on individual components
- Some focus on exactly how attention should work
- Others dial in parallelism strategy
- Benefits: can go really deep on specific problems

### The Trade-off
- Specialists may miss cross-component optimizations
- Manager's role: ensure bigger picture makes sense
- Need people who understand the whole system
- Avoid single points of failure

### Balancing Generalists and Specialists
- People have genuine preferences for generalist vs specialist roles
- Early hires tend to be generalist-shaped (startup mentality)
- Risk: everyone doing everything, no one deeply understanding anything
- Too many specialists: manager has to connect everything
- Goal: balance of both types

## What Hasn't Changed

### The Core Metric
- Still pushing down the same loss function from day one
- "Loss go down" remains the one OKR that matters
- Could plot progress on same metric from first model to today
- Answer is always "as low as possible"

### The Feedback Loop
- Train model -> deploy -> get revenue -> buy more compute -> repeat
- This cycle has run continuously for ~5 years
- Scaling laws give conviction that progress will continue

## Key Takeaways

1. **Scale matters**: More compute, data, and parameters predictably improve models
2. **Efficiency is competitive advantage**: Especially when resource-constrained
3. **Build what you need to control**: Custom infrastructure enables optimization
4. **Balance team composition**: Mix of generalists and specialists
5. **Stay focused on core metric**: Loss reduction drives everything
:::

:::zh
Nick Joseph，Anthropic预训练负责人，分享了关于大规模AI模型训练、基础设施挑战以及预训练团队演变的见解。

## 背景与加入Anthropic的历程

### 职业路径
- 从Vicarious起步，最初是AGI实验室，后转向机器人产品
- 为机器人训练计算机视觉模型 - ML领域的第一份工作
- 在Vicarious学习了ML基础设施基础知识
- 加入OpenAI的安全团队，从事代码模型工作
- 看到GPT-3微调后能写代码，意识到AI可以自我改进
- 与安全团队负责人一起离开OpenAI，在Anthropic创立时加入

### 对AI安全的早期兴趣
- 在GiveWell（评估慈善机构的非营利组织）实习时接触到AI安全概念
- 最初持怀疑态度 - 当时AI安全讨论大多是理论性的
- 模型还不够好，无法构成真正的危险
- 决定从事AI工作：要么安全问题会变得重要，要么就构建有用的AI工具

## 什么是预训练？

### 核心概念
- 规模是让AI模型变得更好的关键因素
- 需要一个有海量数据的目标
- 互联网是人类创造的最大单一数据源
- 不需要人工标签 - 从现有文本预测下一个词

### 工作原理
- 获取文本并预测下一个词
- "The cat" -> 预测接下来是什么
- 每个词都成为新的训练样本
- 从海量数据中获得密集信号

### 扩展定律
- 随着计算、数据和参数的增加，模型可预测地变得更好
- 更低的损失 = 更好的下一词预测
- 原始扩展定律论文显示了11个数量级的一致趋势
- 这创造了正反馈循环：训练模型 -> 制作有用产品 -> 获得收入 -> 购买更多算力 -> 训练更好的模型

## Anthropic早期

### 小规模起步
- 最初团队约10-12人
- 资金比OpenAI等竞争对手少得多
- GPT-3训练成本约500万美元 - 很多但可以实现
- 使用云服务商的算力

### 效率作为竞争优势
- "我们的资金比其他人少得多，必须非常高效"
- 当时大多数人使用算力效率不高
- 专注于从可用硬件中获得最大收益

### 基础设施挑战
- 必须了解芯片的实际物理布局
- 运行聚类算法来识别芯片在哪些机房
- 不同物理位置之间的网络延迟导致问题
- 不断挑战硬件极限

## 分布式训练方法

### 关键技术
- **数据并行**：将数据分布到多个芯片
- **流水线**：跨芯片链接操作
- **操作分片**：将操作分布到硬件上

### 构建自定义基础设施
- 当时没有很好的开源包
- 自己编写all-reduce实现
- 需要修改一切，因为规模超过了Facebook曾达到的
- 不能依赖需要不断修改的外部包

### 为什么要自建？
- 要达到比现有解决方案支持的更大规模
- 需要完全控制以在每个层面优化
- 可以进行架构更改来简化效率问题

## 扩展定律与信念

### 物理学家的视角
- 原始扩展定律论文显示了非常一致的趋势
- 关于趋势是否会继续的争论似乎"毫无意义"
- 11个数量级的数据，争论再多一个点似乎不太可能失败
- "这些人在做什么？他们都错过了大局"

### 不同实验室的文化
- FAIR（Facebook AI Research）有PhD风格的独立研究文化
- 人们为自己的算力而战，追求个人想法
- 训练大型语言模型需要在基础设施上协作
- 不是可发表的工作 - "我提高了5%的效率"不是论文
- Anthropic的文化专注于协作扩展

## 团队随时间的演变

### 早期
- 前3-6个月：试图阅读代码库中的每个PR
- 了解所有部分，可以轻松进行跨领域更改
- 可以通过更改架构发现效率改进

### 日益专业化
- 随着团队增长，人们成为各个组件的深度专家
- 有些人专注于注意力机制应该如何工作
- 其他人专注于并行策略
- 好处：可以在特定问题上深入研究

### 权衡
- 专家可能会错过跨组件的优化
- 管理者的角色：确保大局合理
- 需要理解整个系统的人
- 避免单点故障

### 平衡通才和专家
- 人们对通才vs专家角色有真正的偏好
- 早期员工往往是通才型（创业心态）
- 风险：每个人都做所有事，没有人深入理解任何事
- 专家太多：管理者必须连接一切
- 目标：两种类型的平衡

## 没有改变的是什么

### 核心指标
- 仍在推动从第一天起就相同的损失函数
- "损失下降"仍然是唯一重要的OKR
- 可以用相同的指标绘制从第一个模型到今天的进展
- 答案永远是"尽可能低"

### 反馈循环
- 训练模型 -> 部署 -> 获得收入 -> 购买更多算力 -> 重复
- 这个循环已经持续运行了约5年
- 扩展定律给予信心，进步将继续

## 关键要点

1. **规模很重要**：更多的计算、数据和参数可预测地改进模型
2. **效率是竞争优势**：特别是在资源受限时
3. **构建你需要控制的东西**：自定义基础设施实现优化
4. **平衡团队组成**：通才和专家的混合
5. **专注于核心指标**：损失降低驱动一切
:::
