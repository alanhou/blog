---
title:
  en: "DeepSight: An All-in-One LM Safety Toolkit"
  zh: "DeepSight: 大模型安全一体化工具包"
description:
  en: "DeepSight introduces an integrated evaluation-diagnosis paradigm for large model safety, combining DeepSafe and DeepScan toolkits to transform black-box safety assessment into white-box mechanistic insights."
  zh: "DeepSight提出了大模型安全评估-诊断一体化范式,通过DeepSafe和DeepScan工具包将黑盒安全评估转化为白盒机制洞察。"
date: 2026-02-13
tags: ["arxiv", "ai", "cs.cl", "cs.ai", "cs.cr", "cs.cv"]
image: "/arxiv-visuals/arxiv-deepsight-an-all-in-one-lm.png"
---

:::en
**Paper**: [2602.12092](https://arxiv.org/abs/2602.12092)
**Authors**: Bo Zhang, Jiaxuan Guo, Lijun Li, Dongrui Liu, Sujin Chen, Guanxu Chen, Zhijie Zheng, Qihao Lin, Lewen Yan, Chen Qian
**Categories**: cs.CL, cs.AI, cs.CR, cs.CV

## Abstract

As large language models (LLMs) and multimodal large language models (MLLMs) become increasingly powerful, ensuring their safety has become a critical priority. Current safety workflows suffer from fragmentation—evaluation, diagnosis, and alignment are handled by separate tools that don't communicate effectively. Safety evaluation typically identifies external behavioral risks without uncovering internal root causes, while safety diagnosis often remains disconnected from concrete risk scenarios. This paper introduces DeepSight, an open-source project that unifies safety evaluation and diagnosis into a cohesive paradigm. DeepSight consists of two core components: DeepSafe for evaluation and DeepScan for diagnosis. By establishing unified task and data protocols, DeepSight transforms safety assessment from opaque black-box testing into transparent white-box mechanistic analysis, making it the first open-source toolkit to support both frontier AI risk evaluation and integrated safety evaluation-diagnosis workflows.

## Key Contributions

- **Integrated Paradigm**: Proposes a novel evaluation-diagnosis integrated approach that bridges the gap between external behavioral assessment and internal mechanistic understanding
- **Dual Toolkit Architecture**: Introduces DeepSafe for comprehensive safety evaluation and DeepScan for deep mechanistic diagnosis, with unified protocols enabling seamless integration
- **White-Box Transformation**: Converts traditional black-box safety evaluation into white-box insights by connecting evaluation results with internal model mechanisms
- **Frontier AI Support**: First open-source toolkit to support frontier AI risk evaluation, addressing emerging safety challenges in cutting-edge models
- **Scalability and Efficiency**: Designed as a low-cost, reproducible, and highly scalable solution for large-scale model safety assessment

## The Fragmentation Problem in Current Safety Workflows

Traditional large model safety pipelines operate in silos. Safety evaluation tools can identify when a model produces harmful outputs—detecting toxicity, bias, or dangerous content—but they cannot explain why these failures occur at a mechanistic level. Conversely, interpretability and diagnosis tools may analyze model internals but often lack grounding in concrete safety scenarios and real-world risk contexts.

This fragmentation creates several critical issues. First, safety alignment efforts proceed without clear understanding of which internal mechanisms need modification, potentially leading to over-correction that degrades general capabilities. Second, evaluation results cannot inform targeted interventions because the causal chain from internal representations to external behaviors remains obscured. Third, the lack of standardized protocols between evaluation and diagnosis stages prevents systematic iteration and improvement.

DeepSight addresses these challenges by establishing a unified framework where evaluation and diagnosis share common task definitions, data formats, and analytical protocols. This integration enables practitioners to trace safety failures from observable behaviors back to specific model components and forward from mechanistic insights to predicted behavioral outcomes.

## Architecture and Methodology

DeepSight's architecture consists of two complementary toolkits working in concert:

**DeepSafe (Evaluation Toolkit)** provides comprehensive safety assessment across multiple dimensions. It implements standardized evaluation protocols for both LLMs and MLLMs, covering traditional safety concerns (toxicity, bias, harmful content generation) as well as frontier AI risks (deception, power-seeking, situational awareness). DeepSafe generates structured evaluation reports that not only flag safety violations but also categorize them according to risk type, severity, and contextual factors.

**DeepScan (Diagnosis Toolkit)** performs deep mechanistic analysis to uncover the internal causes of safety failures. Rather than treating models as black boxes, DeepScan employs interpretability techniques to examine attention patterns, activation spaces, and information flow pathways. It identifies which model components (specific layers, attention heads, or neuron clusters) are responsible for generating unsafe outputs in particular contexts.

The key innovation lies in the unified protocol layer connecting these toolkits. When DeepSafe identifies a safety violation, it generates a structured report with standardized metadata. DeepScan can then automatically load this report, retrieve the relevant model states and inputs, and perform targeted analysis on the specific failure mode. This bidirectional flow—from evaluation to diagnosis and back—enables iterative refinement where diagnostic insights inform more precise evaluation strategies.

## Implications for AI Safety Research

DeepSight's integrated approach has significant implications for the broader AI safety research community. By open-sourcing both evaluation and diagnosis capabilities with unified protocols, it establishes a foundation for reproducible safety research. Researchers can now systematically investigate how specific architectural choices, training procedures, or alignment techniques affect both external safety behaviors and internal model mechanisms.

The toolkit's support for frontier AI risks is particularly timely. As models become more capable, new safety challenges emerge—models that can strategically deceive evaluators, exhibit goal-directed behavior beyond their training objectives, or demonstrate concerning levels of self-awareness. DeepSight provides the infrastructure to evaluate these advanced risks while simultaneously diagnosing their mechanistic origins.

Furthermore, the white-box transformation enabled by DeepSight's integrated paradigm opens new avenues for targeted safety interventions. Rather than applying broad alignment techniques that may inadvertently harm model capabilities, practitioners can use diagnostic insights to design surgical interventions that address specific safety mechanisms while preserving general functionality.

## Takeaways

1. DeepSight unifies safety evaluation and diagnosis into a single integrated framework, addressing the fragmentation problem in current large model safety workflows
2. The toolkit consists of DeepSafe for comprehensive evaluation and DeepScan for mechanistic diagnosis, connected through unified task and data protocols
3. By transforming black-box safety assessment into white-box mechanistic analysis, DeepSight enables more targeted and effective safety interventions
4. DeepSight is the first open-source toolkit to support both frontier AI risk evaluation and integrated evaluation-diagnosis workflows
5. The unified protocol architecture enables reproducible safety research and systematic iteration between behavioral assessment and mechanistic understanding
:::

:::zh
**论文**: [2602.12092](https://arxiv.org/abs/2602.12092)
**作者**: Bo Zhang, Jiaxuan Guo, Lijun Li, Dongrui Liu, Sujin Chen, Guanxu Chen, Zhijie Zheng, Qihao Lin, Lewen Yan, Chen Qian
**分类**: cs.CL, cs.AI, cs.CR, cs.CV

## 摘要

随着大语言模型(LLM)和多模态大语言模型(MLLM)能力的不断增强,确保其安全性已成为关键优先事项。当前的安全工作流程存在碎片化问题——评估、诊断和对齐由相互独立的工具处理,缺乏有效沟通。安全评估通常只能识别外部行为风险而无法揭示内部根本原因,而安全诊断往往脱离具体风险场景。本文介绍了DeepSight,一个将安全评估与诊断统一为一体的开源项目。DeepSight由两个核心组件构成:用于评估的DeepSafe和用于诊断的DeepScan。通过建立统一的任务和数据协议,DeepSight将安全评估从不透明的黑盒测试转变为透明的白盒机制分析,成为首个支持前沿AI风险评估和一体化安全评估-诊断工作流的开源工具包。

## 主要贡献

- **一体化范式**: 提出了新颖的评估-诊断一体化方法,弥合了外部行为评估与内部机制理解之间的鸿沟
- **双工具包架构**: 引入DeepSafe进行全面安全评估和DeepScan进行深度机制诊断,通过统一协议实现无缝集成
- **白盒化转型**: 通过连接评估结果与内部模型机制,将传统黑盒安全评估转化为白盒洞察
- **前沿AI支持**: 首个支持前沿AI风险评估的开源工具包,应对尖端模型中新兴的安全挑战
- **可扩展性与效率**: 设计为低成本、可复现且高度可扩展的大规模模型安全评估解决方案

## 当前安全工作流程的碎片化问题

传统的大模型安全流程各自为政。安全评估工具能够识别模型何时产生有害输出——检测毒性、偏见或危险内容——但无法从机制层面解释这些失败为何发生。相反,可解释性和诊断工具可能分析模型内部,但往往缺乏与具体安全场景和真实风险情境的关联。

这种碎片化造成了几个关键问题。首先,安全对齐工作在不清楚需要修改哪些内部机制的情况下进行,可能导致过度修正而损害通用能力。其次,评估结果无法指导针对性干预,因为从内部表征到外部行为的因果链条仍然模糊不清。第三,评估与诊断阶段之间缺乏标准化协议,阻碍了系统性的迭代改进。

DeepSight通过建立统一框架来应对这些挑战,在该框架中评估和诊断共享通用的任务定义、数据格式和分析协议。这种集成使实践者能够将安全失败从可观察行为追溯到特定模型组件,并从机制洞察前向预测行为结果。

## 架构与方法论

DeepSight的架构由两个互补的工具包协同工作:

**DeepSafe(评估工具包)** 提供跨多个维度的全面安全评估。它为LLM和MLLM实现标准化评估协议,涵盖传统安全关注点(毒性、偏见、有害内容生成)以及前沿AI风险(欺骗、权力追求、情境意识)。DeepSafe生成结构化评估报告,不仅标记安全违规,还根据风险类型、严重程度和情境因素进行分类。

**DeepScan(诊断工具包)** 执行深度机制分析以揭示安全失败的内部原因。DeepScan不将模型视为黑盒,而是采用可解释性技术检查注意力模式、激活空间和信息流路径。它识别哪些模型组件(特定层、注意力头或神经元簇)在特定情境下负责生成不安全输出。

关键创新在于连接这些工具包的统一协议层。当DeepSafe识别出安全违规时,它生成带有标准化元数据的结构化报告。DeepScan随后可以自动加载该报告,检索相关模型状态和输入,并对特定失败模式执行针对性分析。这种双向流动——从评估到诊断再返回——实现了迭代优化,其中诊断洞察为更精确的评估策略提供信息。

## 对AI安全研究的影响

DeepSight的一体化方法对更广泛的AI安全研究社区具有重要意义。通过开源具有统一协议的评估和诊断能力,它为可复现的安全研究奠定了基础。研究人员现在可以系统地调查特定架构选择、训练程序或对齐技术如何影响外部安全行为和内部模型机制。

该工具包对前沿AI风险的支持尤为及时。随着模型能力增强,新的安全挑战出现——能够策略性欺骗评估者的模型、表现出超越训练目标的目标导向行为,或展示令人担忧的自我意识水平。DeepSight提供了评估这些高级风险的基础设施,同时诊断其机制起源。

此外,DeepSight一体化范式实现的白盒化转型为针对性安全干预开辟了新途径。实践者可以利用诊断洞察设计精准干预,针对特定安全机制而不是应用可能无意中损害模型能力的广泛对齐技术,从而在解决安全问题的同时保留通用功能。

## 要点总结

1. DeepSight将安全评估与诊断统一为单一集成框架,解决了当前大模型安全工作流程的碎片化问题
2. 该工具包由用于全面评估的DeepSafe和用于机制诊断的DeepScan组成,通过统一的任务和数据协议连接
3. 通过将黑盒安全评估转化为白盒机制分析,DeepSight实现了更有针对性和有效的安全干预
4. DeepSight是首个支持前沿AI风险评估和一体化评估-诊断工作流的开源工具包
5. 统一协议架构支持可复现的安全研究,并在行为评估与机制理解之间实现系统性迭代
:::
