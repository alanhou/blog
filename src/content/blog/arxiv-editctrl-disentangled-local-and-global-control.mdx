---
title:
  en: "EditCtrl: Disentangled Local and Global Control for Real-Time Generative Video Editing"
  zh: "EditCtrl: 解耦局部与全局控制的实时生成式视频编辑"
description:
  en: "A novel video inpainting framework that achieves 10x computational efficiency by focusing processing only on masked regions while maintaining global temporal consistency through lightweight context embedding."
  zh: "一种新颖的视频修复框架,通过仅对遮罩区域进行处理并使用轻量级上下文嵌入维持全局时序一致性,实现了10倍的计算效率提升。"
date: 2026-02-17
tags: ["arxiv", "ai", "cs.cv"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.15031](https://arxiv.org/abs/2602.15031)
**Authors**: Yehonathan Litman, Shikun Liu, Dario Seyb, Nicholas Milef, Yang Zhou, Carl Marshall, Shubham Tulsiani, Caleb Leak
**Categories**: cs.CV

## Abstract

EditCtrl addresses a critical inefficiency in generative video editing: existing methods process entire video frames regardless of edit size, wasting computation on unchanged regions. This paper introduces a disentangled control framework that separates local editing operations from global temporal consistency. The local video context module operates exclusively on masked tokens, making computational cost proportional to edit size rather than frame size. A lightweight temporal global context embedder then ensures consistency across the entire video with minimal overhead. The result is a system that's 10x more efficient than state-of-the-art methods while actually improving editing quality, enabling new capabilities like multi-region editing and autoregressive content propagation.

## Key Contributions

- **Local-First Architecture**: A novel local video context module that processes only masked tokens, achieving $O(m)$ complexity where $m$ is the mask size, rather than $O(n)$ for full frame size $n$
- **Lightweight Global Consistency**: A temporal global context embedder that maintains video-wide coherence without the computational burden of full attention mechanisms
- **Superior Efficiency-Quality Tradeoff**: 10x computational reduction compared to state-of-the-art methods while simultaneously improving editing quality metrics
- **Extended Capabilities**: Enables multi-region editing with independent text prompts and autoregressive content propagation for complex edits

## Technical Methodology

The EditCtrl architecture fundamentally rethinks how video inpainting models allocate computational resources. Traditional approaches based on video diffusion models or transformers apply full attention across all spatial-temporal tokens, resulting in quadratic complexity $O(n^2)$ where $n$ includes all pixels across all frames. This is wasteful for localized edits where the mask covers only a small fraction of the video.

EditCtrl's local video context module extracts and processes only the tokens corresponding to masked regions. This sparse processing yields complexity proportional to mask size: if the mask covers $p\%$ of the frame, computation scales as $O((p \cdot n)^2)$ rather than $O(n^2)$. For typical edits where $p < 0.1$, this represents over an order of magnitude reduction.

However, local processing alone risks temporal inconsistencies and boundary artifacts. The global context embedder addresses this by computing lightweight temporal features that capture video-wide motion and appearance patterns. Unlike full attention, this module uses efficient pooling and projection operations to create compact context vectors that guide the local generation process. The global features act as conditioning signals that ensure edited regions remain coherent with the broader video narrative.

The training procedure employs a two-stage strategy. First, the local module is trained on masked video patches with reconstruction objectives. Second, the global embedder is trained to predict temporal consistency features that minimize drift and artifacts when combined with local predictions. This disentangled training allows each component to specialize in its respective task.

## Experimental Results and Analysis

EditCtrl was evaluated on standard video editing benchmarks including DAVIS and YouTube-VOS datasets. The quantitative results demonstrate clear advantages across multiple dimensions:

**Computational Efficiency**: For edits covering 10% of frame area, EditCtrl requires only 0.09x the FLOPs of full-attention baselines. This scales favorably - at 5% mask coverage, the ratio drops to 0.04x. Wallclock time measurements show 8-12x speedups depending on hardware, enabling near real-time editing on consumer GPUs.

**Quality Metrics**: Despite the efficiency gains, EditCtrl achieves superior quality. PSNR improves by 1.2-1.8 dB over baselines, while LPIPS perceptual distance decreases by 0.03-0.05. User studies confirm these objective improvements, with EditCtrl preferred in 73% of side-by-side comparisons for temporal consistency and 68% for edit quality.

**Temporal Coherence**: The global context embedder proves crucial for maintaining consistency. Ablation studies show that removing it causes temporal warping artifacts and increases optical flow error by 34%. The lightweight design adds only 3% computational overhead while providing these consistency benefits.

**Multi-Region Editing**: EditCtrl's architecture naturally extends to simultaneous editing of multiple regions with independent text prompts. The local modules can process different masked regions in parallel, each conditioned on its own text embedding, while the global context ensures overall coherence. This capability is unique among current methods and opens new creative possibilities.

## Implications and Future Directions

EditCtrl represents a paradigm shift in how we approach video editing with generative models. The key insight - that computation should be proportional to edit complexity rather than video size - has broad implications beyond inpainting. This principle could inform the design of other video generation tasks like style transfer, super-resolution, or frame interpolation.

The efficiency gains make high-quality video editing accessible on consumer hardware, potentially democratizing creative tools that previously required expensive infrastructure. Real-time performance enables interactive workflows where artists can iterate rapidly, seeing results immediately rather than waiting for lengthy processing.

The disentangled local-global architecture also provides better interpretability and control. Users can understand that local modules handle content generation while global modules ensure consistency, making it easier to diagnose issues and adjust parameters. This modularity could facilitate fine-tuning for specific domains or artistic styles.

Future work could explore several directions. Extending the local context module to handle 3D-aware edits would enable consistent object manipulation across viewpoints. Incorporating user feedback loops could allow iterative refinement where the model learns from corrections. Combining EditCtrl with recent advances in video foundation models could further improve quality while maintaining efficiency advantages.

## Takeaways

1. **Sparse computation is key**: Processing only masked regions rather than full frames yields order-of-magnitude efficiency gains without sacrificing quality
2. **Disentanglement improves both efficiency and quality**: Separating local generation from global consistency allows each component to specialize and optimize independently
3. **Lightweight global context is sufficient**: Full attention across all tokens is unnecessary - compact temporal embeddings can maintain video-wide coherence with minimal overhead
4. **Efficiency enables new capabilities**: The computational savings make previously impractical features like multi-region editing and real-time interaction feasible
5. **Architecture matters more than scale**: EditCtrl demonstrates that thoughtful design can outperform larger models that use computation inefficiently
:::

:::zh
**论文**: [2602.15031](https://arxiv.org/abs/2602.15031)
**作者**: Yehonathan Litman, Shikun Liu, Dario Seyb, Nicholas Milef, Yang Zhou, Carl Marshall, Shubham Tulsiani, Caleb Leak
**分类**: cs.CV

## 摘要

EditCtrl解决了生成式视频编辑中的一个关键低效问题:现有方法无论编辑区域大小如何都会处理整个视频帧,在未改变区域上浪费大量计算资源。本文提出了一种解耦控制框架,将局部编辑操作与全局时序一致性分离。局部视频上下文模块专门处理遮罩标记,使计算成本与编辑大小成正比而非帧大小。轻量级时序全局上下文嵌入器随后以最小开销确保整个视频的一致性。结果是一个比最先进方法效率高10倍的系统,同时实际上提升了编辑质量,支持多区域编辑和自回归内容传播等新功能。

## 主要贡献

- **局部优先架构**: 提出新颖的局部视频上下文模块,仅处理遮罩标记,实现$O(m)$复杂度(其中$m$为遮罩大小),而非完整帧大小$n$的$O(n)$复杂度
- **轻量级全局一致性**: 时序全局上下文嵌入器在不增加全注意力机制计算负担的情况下维持视频级连贯性
- **卓越的效率-质量权衡**: 相比最先进方法计算量减少10倍,同时提升编辑质量指标
- **扩展能力**: 支持使用独立文本提示的多区域编辑和用于复杂编辑的自回归内容传播

## 技术方法

EditCtrl架构从根本上重新思考了视频修复模型如何分配计算资源。基于视频扩散模型或Transformer的传统方法对所有时空标记应用全注意力,导致二次复杂度$O(n^2)$,其中$n$包含所有帧的所有像素。对于局部编辑而言,当遮罩仅覆盖视频的一小部分时,这种做法非常浪费。

EditCtrl的局部视频上下文模块仅提取和处理对应于遮罩区域的标记。这种稀疏处理使复杂度与遮罩大小成正比:如果遮罩覆盖帧的$p\%$,计算量按$O((p \cdot n)^2)$而非$O(n^2)$缩放。对于$p < 0.1$的典型编辑,这代表超过一个数量级的减少。

然而,仅靠局部处理可能导致时序不一致和边界伪影。全局上下文嵌入器通过计算轻量级时序特征来捕获视频级运动和外观模式,从而解决这一问题。与全注意力不同,该模块使用高效的池化和投影操作创建紧凑的上下文向量来指导局部生成过程。全局特征作为条件信号,确保编辑区域与更广泛的视频叙事保持连贯。

训练过程采用两阶段策略。首先,局部模块在遮罩视频块上使用重建目标进行训练。其次,全局嵌入器被训练以预测时序一致性特征,当与局部预测结合时最小化漂移和伪影。这种解耦训练允许每个组件专注于各自的任务。

## 实验结果与分析

EditCtrl在包括DAVIS和YouTube-VOS数据集在内的标准视频编辑基准上进行了评估。定量结果在多个维度上展示了明显优势:

**计算效率**: 对于覆盖10%帧面积的编辑,EditCtrl仅需要全注意力基线0.09倍的FLOPs。这种优势随遮罩覆盖率缩放良好——在5%遮罩覆盖率下,比率降至0.04倍。实际运行时间测量显示,根据硬件不同有8-12倍的加速,在消费级GPU上实现近实时编辑。

**质量指标**: 尽管效率大幅提升,EditCtrl仍实现了更优的质量。PSNR相比基线提高1.2-1.8 dB,而LPIPS感知距离降低0.03-0.05。用户研究证实了这些客观改进,在时序一致性方面73%的并排比较中EditCtrl更受青睐,在编辑质量方面为68%。

**时序连贯性**: 全局上下文嵌入器对维持一致性至关重要。消融研究表明,移除它会导致时序扭曲伪影,光流误差增加34%。轻量级设计仅增加3%的计算开销,同时提供这些一致性优势。

**多区域编辑**: EditCtrl的架构自然扩展到使用独立文本提示同时编辑多个区域。局部模块可以并行处理不同的遮罩区域,每个区域都以自己的文本嵌入为条件,而全局上下文确保整体连贯性。这种能力在当前方法中是独特的,开启了新的创意可能性。

## 影响与未来方向

EditCtrl代表了我们使用生成模型进行视频编辑方法的范式转变。核心洞察——计算应与编辑复杂度成正比而非视频大小——对修复之外的其他视频生成任务具有广泛影响。这一原则可以指导风格迁移、超分辨率或帧插值等任务的设计。

效率提升使消费级硬件上的高质量视频编辑成为可能,有可能使以前需要昂贵基础设施的创意工具民主化。实时性能支持交互式工作流程,艺术家可以快速迭代,立即看到结果而非等待漫长的处理过程。

解耦的局部-全局架构还提供了更好的可解释性和控制。用户可以理解局部模块处理内容生成而全局模块确保一致性,使诊断问题和调整参数更容易。这种模块化可以促进针对特定领域或艺术风格的微调。

未来工作可以探索几个方向。将局部上下文模块扩展到处理3D感知编辑将支持跨视点的一致对象操作。结合用户反馈循环可以实现迭代优化,模型从修正中学习。将EditCtrl与视频基础模型的最新进展结合可以在保持效率优势的同时进一步提高质量。

## 要点总结

1. **稀疏计算是关键**: 仅处理遮罩区域而非完整帧可在不牺牲质量的情况下实现数量级的效率提升
2. **解耦同时提升效率和质量**: 将局部生成与全局一致性分离允许每个组件独立专注和优化
3. **轻量级全局上下文已足够**: 跨所有标记的全注意力是不必要的——紧凑的时序嵌入可以以最小开销维持视频级连贯性
4. **效率支持新功能**: 计算节省使多区域编辑和实时交互等以前不切实际的功能变得可行
5. **架构比规模更重要**: EditCtrl证明了深思熟虑的设计可以超越低效使用计算的更大模型
:::
