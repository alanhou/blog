---
title:
  en: "Scaling and the Road to Human-Level AI | Anthropic Co-founder Jared Kaplan"
  zh: "扩展与通往人类级AI之路 | Anthropic联合创始人Jared Kaplan"
description:
  en: "Anthropic co-founder Jared Kaplan discusses scaling laws, AI training phases, and the path to human-level AI at Y Combinator"
  zh: "Anthropic联合创始人Jared Kaplan在Y Combinator讨论扩展定律、AI训练阶段以及通往人类级AI的道路"
date: 2025-07-29
tags: ["ycombinator", "ai", "anthropic", "jared-kaplan", "scaling-laws", "claude"]
image: "https://i2.ytimg.com/vi/p8Jx4qvDoSo/hqdefault.jpg"
---

import YouTube from '../../components/YouTube.astro';

<YouTube id="p8Jx4qvDoSo" title="Scaling and the Road to Human-Level AI | Anthropic Co-founder Jared Kaplan" />

:::en
Jared Kaplan, co-founder of Anthropic and one of the pioneers of scaling laws research, shares insights on how AI models are trained and why scaling is the fundamental driver of AI progress.

## From Physics to AI

### Background
- Spent most of his career as a theoretical physicist
- Mother was a science fiction writer - inspired interest in physics to explore faster-than-light travel
- Interested in fundamental questions: Is the universe deterministic? Do we have free will?
- Met many Anthropic co-founders during physics career
- Initially skeptical about AI ("SVMs aren't that exciting")
- Convinced to transition to AI about six years ago

## Two Phases of AI Training

### Phase 1: Pre-training
- Train AI models to imitate human-written text
- Learn correlations underlying the data
- Teach models what words are likely to follow other words
- Now includes multimodal data in contemporary models

### Phase 2: Reinforcement Learning
- Use human feedback to optimize model behavior
- Reinforce behaviors chosen to be helpful, honest, and harmless
- Discourage bad behaviors
- Early Claude versions used simple comparison interfaces

## Scaling Laws: The Key Discovery

### The Fundamental Insight
- Asked "dumb" physicist questions: How big should the data be? How much does it help?
- Discovered remarkably precise trends - as precise as anything in physics or astronomy
- Performance improves predictably as you scale up compute, data, and model size

### Why This Matters
- Trends observed across many orders of magnitude
- Gives conviction that AI will keep getting smarter predictably
- Not about researchers suddenly getting smart - found a systematic way to improve AI

### Scaling in Reinforcement Learning
- Andy Jones studied scaling laws for AlphaGo using the simpler game Hex
- Found similar straight-line trends in RL training
- Both pre-training and RL show scaling benefits

## AI Capabilities: Two Axes

### Flexibility (Y-axis)
- Ability of AI to meet us where we are
- Progress from narrow systems (AlphaGo only plays Go) to multimodal models
- Moving toward handling all modalities humans can deal with

### Task Horizon (X-axis) - More Interesting
- How long would it take a person to do tasks AI can do
- Doubling roughly every 7 months (per METR research)
- Currently at hours-scale tasks
- Projecting toward days, weeks, months, years

### Future Vision
- AI models or millions of models working together
- Able to do work of entire human organizations
- Could make 50 years of theoretical physics progress in days/weeks

## What's Left for Human-Level AI?

### Key Ingredients Needed

1. **Organizational Knowledge**
   - AI needs context like someone who's worked at a company for years
   - Not just blank slate interactions

2. **Memory**
   - Track progress on long tasks
   - Build and retrieve relevant memories
   - Being built into Claude 4

3. **Oversight/Supervision**
   - Understand fine-grained nuances
   - Solve hard, fuzzy tasks
   - Generate nuanced reward signals for RL
   - Beyond just "code passes tests" or "math answer is correct"

4. **Complexity Progression**
   - Text models to multimodal to robotics
   - Continued gains from scale expected

## Advice for Builders

### Build Things That Don't Quite Work Yet
- AI models are getting better very quickly
- If Claude 4 is "a little bit too dumb" for your product, Claude 5 will make it work
- Experiment on the boundaries of what AI can do

### Use AI to Integrate AI
- Main bottleneck: AI developing faster than we can integrate it
- Leverage AI for AI integration to speed adoption

### Find Fast Adoption Areas
- Software engineering exploding with AI integration
- Question: What's next beyond coding?
- Look for areas where 70-80% accuracy is good enough

## On Claude 4

### Improvements Over 3.7 Sonnet
- 3.7 was "a little bit too eager" - would do anything to make tests pass
- Claude 4 improves agentic capabilities for coding and other applications
- Better supervision and oversight
- Follows directions better, improves code quality
- Better memory storage and retrieval across context windows

### The Scaling Picture
- Scaling laws paint picture of incremental progress
- Smooth curve toward human-level AI/AGI
- Each release gets steadily better in many ways

## Human-AI Collaboration

### Current State
- AI makes brilliant moves but also basic errors
- Key difference from humans: judgment vs generative capability much closer in AI
- Humans can judge things they can't do; AI's judgment and generation are similar
- Major role for humans: managers who sanity-check AI work

### The Shift
- Moving from co-pilot (human approval needed) to end-to-end task completion
- Founders now selling direct workflow replacements
- Human-AI collaboration most interesting for advanced tasks

## AI's Unique Strength: Breadth

### Depth vs Breadth
- Math: work on one theorem for a decade (depth)
- Biology, psychology, history: putting together vast information across areas (breadth)
- AI during pre-training imbibes all of human civilization's knowledge
- Particular overhang in areas requiring breadth no single human expert has

### Green Field Opportunities
- Finance (Excel spreadsheet users)
- Law (though more regulated)
- Any skilled task involving sitting at a computer interacting with data
- Integrating AI into existing businesses

## Physics Background and AI Research

### The Physicist's Approach
- Ask the "dumbest possible questions"
- Look at the big picture
- Notice very simple trends
- Scaling laws discovery came from this mindset

### Predicting the Future
- Scaling laws give one way to predict: trends will continue
- Like GDP and economic trends - reliable indicators
- Details of implementation remain hard to predict
:::

:::zh
Jared Kaplan，Anthropic联合创始人和扩展定律研究的先驱之一，分享了关于AI模型如何训练以及为什么扩展是AI进步的根本驱动力的见解。

## 从物理学到AI

### 背景
- 职业生涯大部分时间是理论物理学家
- 母亲是科幻作家 - 激发了对物理学的兴趣，想探索超光速旅行
- 对基本问题感兴趣：宇宙是确定性的吗？我们有自由意志吗？
- 在物理学职业生涯中认识了许多Anthropic联合创始人
- 最初对AI持怀疑态度（"SVM没那么令人兴奋"）
- 大约六年前被说服转向AI

## AI训练的两个阶段

### 第一阶段：预训练
- 训练AI模型模仿人类书写的文本
- 学习数据中的相关性
- 教模型哪些词可能跟在其他词后面
- 现代模型现在包括多模态数据

### 第二阶段：强化学习
- 使用人类反馈优化模型行为
- 强化被选择为有帮助、诚实和无害的行为
- 抑制不良行为
- 早期Claude版本使用简单的比较界面

## 扩展定律：关键发现

### 基本洞察
- 问了"愚蠢"的物理学家问题：数据应该多大？它有多大帮助？
- 发现了非常精确的趋势 - 和物理学或天文学中的任何东西一样精确
- 随着计算、数据和模型规模的扩大，性能可预测地提高

### 为什么这很重要
- 在许多数量级上观察到的趋势
- 给予信心，AI将以可预测的方式变得越来越聪明
- 不是研究人员突然变聪明了 - 而是找到了系统性改进AI的方法

### 强化学习中的扩展
- Andy Jones使用更简单的Hex游戏研究了AlphaGo的扩展定律
- 在RL训练中发现了类似的直线趋势
- 预训练和RL都显示出扩展的好处

## AI能力：两个轴

### 灵活性（Y轴）
- AI满足我们需求的能力
- 从狭窄系统（AlphaGo只会下围棋）到多模态模型的进步
- 朝着处理人类能处理的所有模态发展

### 任务时间范围（X轴）- 更有趣
- 人类完成AI能做的任务需要多长时间
- 大约每7个月翻一番（根据METR研究）
- 目前处于小时级任务
- 预计将达到天、周、月、年级别

### 未来愿景
- AI模型或数百万个模型协同工作
- 能够完成整个人类组织的工作
- 可以在几天/几周内完成50年的理论物理进展

## 人类级AI还需要什么？

### 需要的关键要素

1. **组织知识**
   - AI需要像在公司工作多年的人一样的背景
   - 不仅仅是空白状态的交互

2. **记忆**
   - 跟踪长期任务的进度
   - 构建和检索相关记忆
   - 正在构建到Claude 4中

3. **监督/监管**
   - 理解细微差别
   - 解决困难、模糊的任务
   - 为RL生成细致的奖励信号
   - 超越"代码通过测试"或"数学答案正确"

4. **复杂性递进**
   - 从文本模型到多模态到机器人
   - 预计扩展将继续带来收益

## 给构建者的建议

### 构建还不太能工作的东西
- AI模型正在快速变好
- 如果Claude 4对你的产品"有点太笨"，Claude 5会让它工作
- 在AI能力的边界上实验

### 用AI来整合AI
- 主要瓶颈：AI发展速度超过我们整合它的速度
- 利用AI进行AI整合以加速采用

### 找到快速采用的领域
- 软件工程正在爆发式地整合AI
- 问题：编程之后是什么？
- 寻找70-80%准确率就足够好的领域

## 关于Claude 4

### 相比3.7 Sonnet的改进
- 3.7"有点太急切" - 会做任何事来让测试通过
- Claude 4改进了编程和其他应用的代理能力
- 更好的监督和监管
- 更好地遵循指示，提高代码质量
- 更好的跨上下文窗口的记忆存储和检索

### 扩展图景
- 扩展定律描绘了渐进式进步的图景
- 向人类级AI/AGI的平滑曲线
- 每次发布都在许多方面稳步改进

## 人机协作

### 当前状态
- AI做出精彩的动作但也会犯基本错误
- 与人类的关键区别：AI的判断与生成能力更接近
- 人类可以判断他们做不到的事情；AI的判断和生成相似
- 人类的主要角色：作为管理者检查AI的工作

### 转变
- 从副驾驶（需要人类批准）转向端到端任务完成
- 创始人现在直接销售工作流程替代方案
- 人机协作对高级任务最有趣

## AI的独特优势：广度

### 深度vs广度
- 数学：在一个定理上工作十年（深度）
- 生物学、心理学、历史：整合跨领域的大量信息（广度）
- AI在预训练期间吸收了人类文明的所有知识
- 在需要单个人类专家不具备的广度的领域有特别的优势

### 绿地机会
- 金融（Excel电子表格用户）
- 法律（虽然监管更严格）
- 任何涉及坐在电脑前与数据交互的技能任务
- 将AI整合到现有业务中

## 物理学背景与AI研究

### 物理学家的方法
- 问"最愚蠢的问题"
- 看大局
- 注意非常简单的趋势
- 扩展定律的发现来自这种思维方式

### 预测未来
- 扩展定律提供了一种预测方式：趋势将继续
- 像GDP和经济趋势一样 - 可靠的指标
- 实施细节仍然难以预测
:::
