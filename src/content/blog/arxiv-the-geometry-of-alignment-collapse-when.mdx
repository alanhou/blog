---
title:
  en: "The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety"
  zh: "对齐崩溃的几何学：微调如何破坏安全性"
description:
  en: "A geometric analysis revealing why fine-tuning aligned language models on benign tasks unpredictably degrades safety, establishing a quartic scaling law for alignment loss."
  zh: "通过几何分析揭示为何在良性任务上微调对齐语言模型会不可预测地降低安全性，并建立对齐损失的四次方缩放定律。"
date: 2026-02-18
tags: ["arxiv", "ai", "cs.lg", "cs.ai"]
image: "/arxiv-visuals/arxiv-the-geometry-of-alignment-collapse-when.png"
---

:::en
**Paper**: [2602.15799](https://arxiv.org/abs/2602.15799)
**Authors**: Max Springer, Chung Peng Lee, Blossom Metevier, Jane Castleman, Bohdan Turbal, Hayoung Jung, Zeyu Shen, Aleksandra Korolova
**Categories**: cs.LG, cs.AI

## Abstract

This paper investigates a critical vulnerability in aligned language models: fine-tuning on benign tasks can unpredictably degrade safety guardrails, even without harmful training data or adversarial intent. The authors challenge the prevailing assumption that fine-tuning updates orthogonal to safety-critical directions preserve alignment, demonstrating that this orthogonality is structurally unstable under gradient descent dynamics. Through novel geometric analysis, they prove that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure invisible to first-order methods. The paper establishes the Alignment Instability Condition and derives a quartic scaling law showing alignment loss grows with the fourth power of training time, fundamentally reframing alignment fragility as an intrinsic geometric property rather than a patchable bug.

## Key Contributions

- **Geometric characterization of alignment collapse**: Proves that safety alignment concentrates in low-dimensional subspaces with sharp curvature, making it structurally fragile to fine-tuning
- **Alignment Instability Condition**: Formalizes three geometric properties that jointly predict safety degradation during fine-tuning
- **Quartic scaling law**: Establishes that alignment loss scales as $\mathcal{O}(t^4)$ with training time $t$, governed by alignment sharpness and curvature coupling
- **Structural critique of current paradigm**: Demonstrates that dominant safe fine-tuning approaches address only initial conditions of a fundamentally dynamic problem
- **Second-order mechanism**: Shows how curvature in the fine-tuning loss generates acceleration that systematically steers trajectories into alignment-sensitive regions

## The Geometry of Alignment

The paper's central insight is that alignment safety is not uniformly distributed across parameter space but concentrates in low-dimensional subspaces. This geometric structure has profound implications:

**Sharp curvature manifolds**: The authors prove that safety-critical parameters lie on manifolds with high curvature. While first-order gradient methods (standard in deep learning) can initially avoid these regions, the curvature itself creates second-order effects that pull optimization trajectories back toward alignment-sensitive areas.

**Orthogonality illusion**: The prevailing wisdom suggests that if fine-tuning gradients are orthogonal to safety directions, alignment should be preserved. This paper shows this orthogonality is structurally unstable—small perturbations in parameter space can rapidly collapse this independence due to the curved geometry of the loss landscape.

**Low-dimensional concentration**: Rather than safety being a high-dimensional property robust to perturbation, it concentrates in surprisingly low-dimensional subspaces. This concentration makes alignment brittle: even benign fine-tuning can inadvertently intersect these critical regions.

## The Alignment Instability Condition

The paper formalizes when fine-tuning will degrade safety through three geometric properties:

1. **Alignment concentration**: Safety-critical parameters occupy a low-dimensional subspace $\mathcal{S}$ with dimension $d_{\mathcal{S}} \ll d$ where $d$ is the full parameter dimension
2. **Sharp curvature**: The alignment loss exhibits high curvature (large eigenvalues of the Hessian) within $\mathcal{S}$
3. **Curvature coupling**: The fine-tuning task loss has non-negligible curvature components that couple with the alignment subspace

When all three conditions hold, the paper proves that alignment degradation is inevitable, regardless of the initial orthogonality of gradients.

## The Quartic Scaling Law

The main theoretical result establishes:

$$\Delta L_{\text{align}}(t) \sim \kappa_{\text{align}} \cdot \kappa_{\text{couple}} \cdot t^4$$

where:
- $\Delta L_{\text{align}}(t)$ is the alignment loss at training time $t$
- $\kappa_{\text{align}}$ measures the sharpness of alignment geometry
- $\kappa_{\text{couple}}$ quantifies curvature coupling between fine-tuning and safety parameters

This quartic relationship reveals that alignment degradation accelerates dramatically over time—not linearly or quadratically, but with the fourth power. This explains why safety can appear stable initially but collapse suddenly during extended fine-tuning.

**Mechanistic explanation**: The quartic scaling emerges from second-order dynamics. Initial fine-tuning updates may avoid alignment subspaces (first-order effect), but the curvature of the loss landscape generates acceleration (second-order effect) that systematically steers trajectories into these regions. The fourth power arises from the compounding of curvature effects over time.

## Implications for AI Safety

This work exposes fundamental limitations in current safety practices:

**Reactive vs. predictive**: Current approaches rely on red-teaming and post-hoc evaluation. This paper argues for predictive diagnostics based on geometric properties that can be measured before deployment.

**First-order blindness**: Standard gradient-based safety interventions operate in a first-order regime, unable to detect or defend against the second-order curvature effects that drive alignment collapse.

**Open-weight deployment risks**: For open-weight models, users can fine-tune without oversight. Understanding the geometric conditions for alignment collapse enables better risk assessment and potentially curvature-aware fine-tuning methods.

**Beyond orthogonality**: The paper demonstrates that ensuring gradient orthogonality is insufficient. Safe fine-tuning requires curvature-aware methods that account for the dynamic, second-order nature of alignment degradation.

## Takeaways

1. Alignment safety is geometrically fragile, concentrating in low-dimensional subspaces with sharp curvature that first-order methods cannot protect
2. The quartic scaling law ($\mathcal{O}(t^4)$) explains why safety can appear stable initially but collapse suddenly during extended fine-tuning
3. Current safe fine-tuning approaches address only initial conditions of a fundamentally dynamic problem, missing second-order curvature effects
4. The Alignment Instability Condition provides a predictive framework for assessing when fine-tuning will degrade safety
5. Future safety methods must be curvature-aware, shifting from reactive red-teaming to predictive geometric diagnostics
:::

:::zh
**论文**: [2602.15799](https://arxiv.org/abs/2602.15799)
**作者**: Max Springer, Chung Peng Lee, Blossom Metevier, Jane Castleman, Bohdan Turbal, Hayoung Jung, Zeyu Shen, Aleksandra Korolova
**分类**: cs.LG, cs.AI

## 摘要

本文研究了对齐语言模型中的一个关键漏洞：即使在没有有害训练数据或对抗性意图的情况下,在良性任务上进行微调也会不可预测地降低安全防护。作者挑战了主流假设——即与安全关键方向正交的微调更新能够保持对齐,证明这种正交性在梯度下降动力学下结构不稳定。通过新颖的几何分析,他们证明对齐集中在具有尖锐曲率的低维子空间中,形成一种一阶方法无法检测或防御的脆弱结构。论文建立了对齐不稳定性条件,并推导出四次方缩放定律,表明对齐损失随训练时间的四次方增长,从根本上将对齐脆弱性重新定义为内在的几何属性而非可修补的缺陷。

## 主要贡献

- **对齐崩溃的几何刻画**: 证明安全对齐集中在具有尖锐曲率的低维子空间中,使其在微调时结构脆弱
- **对齐不稳定性条件**: 形式化了三个几何属性,它们共同预测微调期间的安全退化
- **四次方缩放定律**: 确立对齐损失随训练时间$t$按$\mathcal{O}(t^4)$缩放,由对齐尖锐度和曲率耦合控制
- **对当前范式的结构性批判**: 证明主流的安全微调方法仅解决了一个根本动态问题的初始条件
- **二阶机制**: 展示微调损失中的曲率如何产生加速度,系统性地将轨迹引导至对齐敏感区域

## 对齐的几何学

论文的核心洞察是安全对齐并非均匀分布在参数空间中,而是集中在低维子空间内。这种几何结构具有深远影响:

**尖锐曲率流形**: 作者证明安全关键参数位于高曲率流形上。虽然一阶梯度方法(深度学习中的标准方法)最初可以避开这些区域,但曲率本身会产生二阶效应,将优化轨迹拉回对齐敏感区域。

**正交性幻觉**: 主流观点认为,如果微调梯度与安全方向正交,对齐应该得以保持。本文表明这种正交性结构不稳定——由于损失景观的弯曲几何,参数空间中的小扰动可以迅速瓦解这种独立性。

**低维集中**: 安全性并非高维空间中对扰动鲁棒的属性,而是集中在令人惊讶的低维子空间中。这种集中使对齐变得脆弱:即使是良性微调也可能无意中与这些关键区域相交。

## 对齐不稳定性条件

论文通过三个几何属性形式化了微调何时会降低安全性:

1. **对齐集中性**: 安全关键参数占据低维子空间$\mathcal{S}$,其维度$d_{\mathcal{S}} \ll d$,其中$d$是完整参数维度
2. **尖锐曲率**: 对齐损失在$\mathcal{S}$内表现出高曲率(Hessian矩阵的大特征值)
3. **曲率耦合**: 微调任务损失具有与对齐子空间耦合的非可忽略曲率分量

当三个条件同时满足时,论文证明对齐退化不可避免,无论梯度的初始正交性如何。

## 四次方缩放定律

主要理论结果确立:

$$\Delta L_{\text{align}}(t) \sim \kappa_{\text{align}} \cdot \kappa_{\text{couple}} \cdot t^4$$

其中:
- $\Delta L_{\text{align}}(t)$是训练时间$t$时的对齐损失
- $\kappa_{\text{align}}$衡量对齐几何的尖锐度
- $\kappa_{\text{couple}}$量化微调与安全参数之间的曲率耦合

这种四次方关系揭示对齐退化随时间急剧加速——不是线性或二次,而是四次方。这解释了为什么安全性最初看起来稳定,但在长时间微调期间会突然崩溃。

**机制解释**: 四次方缩放源于二阶动力学。初始微调更新可能避开对齐子空间(一阶效应),但损失景观的曲率产生加速度(二阶效应),系统性地将轨迹引导至这些区域。四次方源于曲率效应随时间的复合。

## 对AI安全的影响

这项工作揭示了当前安全实践的根本局限:

**反应式vs预测式**: 当前方法依赖红队测试和事后评估。本文主张基于几何属性的预测性诊断,这些属性可以在部署前测量。

**一阶盲点**: 标准的基于梯度的安全干预在一阶范式中运作,无法检测或防御驱动对齐崩溃的二阶曲率效应。

**开放权重部署风险**: 对于开放权重模型,用户可以在无监督下进行微调。理解对齐崩溃的几何条件能够实现更好的风险评估,并可能产生曲率感知的微调方法。

**超越正交性**: 论文证明确保梯度正交性是不够的。安全微调需要曲率感知方法,考虑对齐退化的动态、二阶本质。

## 要点总结

1. 对齐安全在几何上是脆弱的,集中在具有尖锐曲率的低维子空间中,一阶方法无法保护
2. 四次方缩放定律($\mathcal{O}(t^4)$)解释了为什么安全性最初看起来稳定但在长时间微调期间会突然崩溃
3. 当前的安全微调方法仅解决了根本动态问题的初始条件,忽略了二阶曲率效应
4. 对齐不稳定性条件提供了一个预测框架,用于评估微调何时会降低安全性
5. 未来的安全方法必须具有曲率感知能力,从反应式红队测试转向预测性几何诊断
:::
