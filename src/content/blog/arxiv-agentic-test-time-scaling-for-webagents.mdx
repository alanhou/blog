---
title:
  en: "CATTS: Confidence-Aware Test-Time Scaling for Multi-Step Web Agents"
  zh: "CATTS: 面向多步骤网络智能体的置信度感知测试时扩展"
description:
  en: "A dynamic compute allocation technique that uses vote-derived uncertainty to improve web agent performance by up to 9.1% while reducing token usage by 2.3x compared to uniform scaling."
  zh: "一种动态计算分配技术,通过投票衍生的不确定性指标,在减少2.3倍token使用的同时将网络智能体性能提升最高9.1%。"
date: 2026-02-13
tags: ["arxiv", "ai", "cs.ai", "cs.cl"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.12276](https://arxiv.org/abs/2602.12276)
**Authors**: Nicholas Lee, Lutfi Eren Erdogan, Chris Joseph John, Surya Krishnapillai, Michael W. Mahoney, Kurt Keutzer, Amir Gholami
**Categories**: cs.AI, cs.CL

## Abstract

Test-time scaling has emerged as a powerful paradigm for enhancing neural network performance, but its application to agentic, multi-step tasks presents unique challenges. This paper introduces CATTS (Confidence-Aware Test-Time Scaling), a technique that dynamically allocates computational resources based on decision uncertainty in web agents. Through empirical analysis on WebArena-Lite and GoBrowse benchmarks, the authors demonstrate that naive uniform scaling strategies quickly saturate in long-horizon environments due to error compounding. CATTS addresses this by using vote distribution statistics—specifically entropy and top-1/top-2 margin—to identify contentious decisions requiring additional compute. The method achieves up to 9.1% performance improvement over baseline React agents while consuming 2.3x fewer tokens than uniform scaling approaches.

## Key Contributions

- Empirical characterization of test-time scaling behavior for multi-step web agents, revealing diminishing returns from uniform per-step compute increases
- Analysis of aggregation strategies including LLM-based Arbiters, showing they can outperform naive voting but may overrule high-consensus decisions
- Identification of vote-derived uncertainty metrics (entropy, top-1/top-2 margin) as reliable predictors of downstream task success
- Introduction of CATTS, a practical dynamic compute allocation policy that achieves superior efficiency-performance tradeoffs

## The Problem with Uniform Scaling

Traditional test-time scaling approaches apply uniform compute increases across all decision points. For single-step tasks, this strategy works well—more samples generally yield better results through improved coverage of the solution space. However, multi-step agentic tasks exhibit fundamentally different dynamics.

The authors identify two critical issues. First, errors compound over long horizons: a single misstep early in a task trajectory can render subsequent actions irrelevant, wasting computational resources on doomed paths. Second, not all decisions carry equal uncertainty—some steps have clear optimal actions while others involve genuine ambiguity requiring careful deliberation.

Through experiments on web navigation benchmarks, the paper demonstrates that uniformly increasing sampling from $k=1$ to $k=5$ per step yields diminishing returns. Performance improvements plateau while token consumption grows linearly, creating an unfavorable efficiency frontier. This motivates the need for smarter, adaptive allocation strategies.

## Methodology: Vote-Derived Uncertainty Signals

CATTS operates on a simple but powerful insight: the agent's own vote distribution reveals decision confidence. When multiple sampled trajectories converge on the same action, the decision is likely straightforward. When votes fragment across options, additional compute can help resolve genuine ambiguity.

The paper evaluates two uncertainty metrics derived from vote distributions:

**Entropy**: Measures the spread of votes across actions. For a distribution $p$ over actions, entropy is computed as:

$$H(p) = -\sum_{i} p_i \log p_i$$

High entropy indicates dispersed votes and high uncertainty.

**Top-1/Top-2 Margin**: Captures the gap between the most popular and second-most popular actions:

$$\text{margin} = p_{\text{top-1}} - p_{\text{top-2}}$$

Small margins suggest competitive alternatives requiring disambiguation.

Empirical analysis shows both metrics correlate with downstream success rates. Steps with high entropy or low margins benefit significantly from additional sampling, while confident decisions (low entropy, high margin) show minimal gains from extra compute.

## The CATTS Algorithm

CATTS implements a threshold-based policy for dynamic compute allocation. At each step:

1. Sample $k_{\text{base}}$ trajectories (typically $k_{\text{base}} = 3$)
2. Compute uncertainty metric (entropy or margin) from vote distribution
3. If uncertainty exceeds threshold $\tau$, allocate additional samples up to $k_{\text{max}}$
4. Aggregate votes and select action

The threshold $\tau$ controls the aggressiveness of compute allocation. Lower thresholds trigger more frequent scaling, trading tokens for performance. Higher thresholds prioritize efficiency, scaling only for highly contentious decisions.

This approach provides an interpretable decision rule: compute is allocated precisely when the agent exhibits genuine uncertainty, rather than uniformly across all steps. The policy adapts naturally to task difficulty—complex environments with more ambiguous decisions automatically receive more resources.

## Experimental Results

The authors evaluate CATTS on two web agent benchmarks:

**WebArena-Lite**: A simplified web navigation environment with 100 tasks spanning e-commerce, content management, and information retrieval scenarios.

**GoBrowse**: A more challenging benchmark requiring multi-step reasoning and interaction with real websites.

Key findings include:

- CATTS with entropy-based allocation achieves 9.1% relative improvement over React baseline on WebArena-Lite
- Token efficiency gains of 2.3x compared to uniform $k=5$ scaling while maintaining comparable performance
- Margin-based allocation shows similar trends with slightly different efficiency-performance tradeoffs
- Performance improvements are most pronounced on longer-horizon tasks where error compounding is severe

The paper also analyzes the distribution of compute allocation across task trajectories. CATTS concentrates resources on genuinely difficult decision points—typically 20-30% of steps—while using minimal compute for straightforward actions. This adaptive behavior explains the superior efficiency compared to uniform strategies.

## Aggregation Strategies and the Arbiter

Beyond uncertainty-based allocation, the paper investigates aggregation methods for combining multiple sampled trajectories. Naive majority voting serves as the baseline, but the authors explore more sophisticated approaches.

An LLM-based Arbiter receives all sampled actions and their reasoning traces, then selects the best option. This meta-reasoning can outperform voting by considering action quality beyond mere frequency. However, the Arbiter introduces a critical failure mode: it may overrule high-consensus decisions, injecting errors even when the agent exhibits strong agreement.

The paper finds that Arbiters provide modest gains on average but increase variance. For production systems prioritizing reliability, vote-based aggregation with uncertainty-aware scaling offers a better risk-reward profile. The Arbiter remains valuable for research settings exploring the limits of test-time scaling.

## Implications for Agentic Systems

CATTS demonstrates that test-time scaling for agents requires fundamentally different strategies than single-step tasks. The key insight—allocate compute based on decision uncertainty—generalizes beyond web navigation to any multi-step agentic system.

Several broader implications emerge:

**Efficiency-Performance Tradeoffs**: Dynamic allocation enables new operating points on the efficiency frontier, achieving strong performance with constrained budgets or maximizing performance with flexible resources.

**Interpretability**: Uncertainty metrics provide transparency into agent decision-making. High-uncertainty steps flag potential failure points for human review or intervention.

**Scalability**: As models and tasks grow more complex, intelligent compute allocation becomes increasingly critical. CATTS provides a practical framework that scales naturally with task difficulty.

**Future Directions**: The paper opens questions about optimal uncertainty metrics, learned allocation policies, and integration with other test-time techniques like self-consistency and chain-of-thought prompting.

## Takeaways

1. Uniform test-time scaling shows diminishing returns for multi-step agents due to error compounding and heterogeneous decision difficulty across trajectories.

2. Vote-derived uncertainty metrics (entropy and top-1/top-2 margin) reliably predict which decisions benefit from additional compute, enabling dynamic allocation.

3. CATTS achieves up to 9.1% performance improvement over baseline agents while using 2.3x fewer tokens than uniform scaling, demonstrating superior efficiency-performance tradeoffs.

4. LLM-based Arbiters can outperform naive voting but introduce variance by potentially overruling high-consensus decisions, making them less suitable for reliability-critical applications.

5. Adaptive compute allocation provides interpretability benefits by flagging uncertain decisions, enabling human oversight and debugging of agentic systems.

6. The principles of confidence-aware scaling generalize beyond web agents to any multi-step decision-making system, suggesting broad applicability across agentic AI domains.
:::

:::zh
**论文**: [2602.12276](https://arxiv.org/abs/2602.12276)
**作者**: Nicholas Lee, Lutfi Eren Erdogan, Chris Joseph John, Surya Krishnapillai, Michael W. Mahoney, Kurt Keutzer, Amir Gholami
**分类**: cs.AI, cs.CL

## 摘要

测试时扩展已成为增强神经网络性能的强大范式,但其在智能体多步骤任务中的应用面临独特挑战。本文介绍了CATTS(置信度感知测试时扩展),这是一种基于网络智能体决策不确定性动态分配计算资源的技术。通过在WebArena-Lite和GoBrowse基准上的实证分析,作者证明了朴素的均匀扩展策略由于误差累积在长时域环境中迅速饱和。CATTS通过使用投票分布统计量——特别是熵和top-1/top-2边际——来识别需要额外计算的争议性决策,从而解决这一问题。该方法相比基线React智能体实现了高达9.1%的性能提升,同时比均匀扩展方法减少了2.3倍的token消耗。

## 主要贡献

- 对多步骤网络智能体的测试时扩展行为进行实证刻画,揭示了均匀增加每步计算的收益递减现象
- 分析包括基于LLM的仲裁器在内的聚合策略,表明它们可以优于朴素投票但可能推翻高共识决策
- 识别投票衍生的不确定性指标(熵、top-1/top-2边际)作为下游任务成功的可靠预测因子
- 提出CATTS这一实用的动态计算分配策略,实现了卓越的效率-性能权衡

## 均匀扩展的问题

传统的测试时扩展方法在所有决策点应用均匀的计算增量。对于单步任务,这种策略效果良好——更多样本通过改善解空间覆盖通常产生更好的结果。然而,多步骤智能体任务表现出根本不同的动态特性。

作者识别出两个关键问题。首先,误差在长时域内累积:任务轨迹早期的单个失误可能使后续动作变得无关紧要,在注定失败的路径上浪费计算资源。其次,并非所有决策都具有相同的不确定性——某些步骤有明确的最优动作,而其他步骤涉及需要仔细考虑的真实歧义。

通过在网络导航基准上的实验,论文证明了将每步采样从$k=1$均匀增加到$k=5$会产生收益递减。性能改进趋于平稳,而token消耗线性增长,创造了不利的效率前沿。这激发了对更智能、自适应分配策略的需求。

## 方法论:投票衍生的不确定性信号

CATTS基于一个简单但强大的洞察:智能体自身的投票分布揭示了决策置信度。当多个采样轨迹收敛于相同动作时,决策可能是直接的。当投票在选项间分散时,额外的计算可以帮助解决真实的歧义。

论文评估了从投票分布衍生的两个不确定性指标:

**熵**:测量投票在动作间的分散程度。对于动作上的分布$p$,熵计算为:

$$H(p) = -\sum_{i} p_i \log p_i$$

高熵表示分散的投票和高不确定性。

**Top-1/Top-2边际**:捕获最受欢迎和第二受欢迎动作之间的差距:

$$\text{margin} = p_{\text{top-1}} - p_{\text{top-2}}$$

小边际表明需要消歧的竞争性替代方案。

实证分析显示两个指标都与下游成功率相关。具有高熵或低边际的步骤从额外采样中显著受益,而置信决策(低熵、高边际)从额外计算中显示出最小收益。

## CATTS算法

CATTS实现了基于阈值的动态计算分配策略。在每个步骤:

1. 采样$k_{\text{base}}$条轨迹(通常$k_{\text{base}} = 3$)
2. 从投票分布计算不确定性指标(熵或边际)
3. 如果不确定性超过阈值$\tau$,分配额外样本直到$k_{\text{max}}$
4. 聚合投票并选择动作

阈值$\tau$控制计算分配的激进程度。较低的阈值触发更频繁的扩展,用token换取性能。较高的阈值优先考虑效率,仅对高度争议的决策进行扩展。

这种方法提供了可解释的决策规则:计算精确地分配在智能体表现出真实不确定性时,而不是在所有步骤上均匀分配。该策略自然适应任务难度——具有更多模糊决策的复杂环境自动接收更多资源。

## 实验结果

作者在两个网络智能体基准上评估CATTS:

**WebArena-Lite**:一个简化的网络导航环境,包含100个跨越电子商务、内容管理和信息检索场景的任务。

**GoBrowse**:一个更具挑战性的基准,需要多步推理和与真实网站的交互。

关键发现包括:

- 基于熵分配的CATTS在WebArena-Lite上相比React基线实现9.1%的相对改进
- 相比均匀$k=5$扩展,在保持可比性能的同时实现2.3倍的token效率提升
- 基于边际的分配显示出类似趋势,具有略微不同的效率-性能权衡
- 性能改进在误差累积严重的长时域任务上最为显著

论文还分析了计算分配在任务轨迹上的分布。CATTS将资源集中在真正困难的决策点——通常是20-30%的步骤——同时对直接动作使用最少的计算。这种自适应行为解释了相比均匀策略的卓越效率。

## 聚合策略与仲裁器

除了基于不确定性的分配,论文还研究了组合多个采样轨迹的聚合方法。朴素多数投票作为基线,但作者探索了更复杂的方法。

基于LLM的仲裁器接收所有采样的动作及其推理轨迹,然后选择最佳选项。这种元推理可以通过考虑超越单纯频率的动作质量来优于投票。然而,仲裁器引入了一个关键的失败模式:它可能推翻高共识决策,即使在智能体表现出强烈一致性时也注入错误。

论文发现仲裁器平均提供适度收益但增加方差。对于优先考虑可靠性的生产系统,基于投票的聚合与不确定性感知扩展提供了更好的风险-回报特征。仲裁器对于探索测试时扩展极限的研究环境仍然有价值。

## 对智能体系统的启示

CATTS证明了智能体的测试时扩展需要与单步任务根本不同的策略。关键洞察——基于决策不确定性分配计算——泛化到超越网络导航的任何多步骤智能体系统。

出现了几个更广泛的启示:

**效率-性能权衡**:动态分配在效率前沿上实现新的操作点,在受限预算下实现强性能或在灵活资源下最大化性能。

**可解释性**:不确定性指标为智能体决策提供透明度。高不确定性步骤标记潜在失败点以供人工审查或干预。

**可扩展性**:随着模型和任务变得更加复杂,智能计算分配变得越来越关键。CATTS提供了一个随任务难度自然扩展的实用框架。

**未来方向**:论文开启了关于最优不确定性指标、学习分配策略以及与其他测试时技术(如自洽性和思维链提示)集成的问题。

## 要点总结

1. 由于误差累积和轨迹间决策难度的异质性,均匀测试时扩展对多步骤智能体显示出收益递减。

2. 投票衍生的不确定性指标(熵和top-1/top-2边际)可靠地预测哪些决策从额外计算中受益,实现动态分配。

3. CATTS相比基线智能体实现高达9.1%的性能提升,同时比均匀扩展使用少2.3倍的token,展示了卓越的效率-性能权衡。

4. 基于LLM的仲裁器可以优于朴素投票,但通过可能推翻高共识决策引入方差,使其不太适合可靠性关键应用。

5. 自适应计算分配通过标记不确定决策提供可解释性优势,实现对智能体系统的人工监督和调试。

6. 置信度感知扩展的原则泛化到超越网络智能体的任何多步骤决策系统,表明在智能体AI领域具有广泛适用性。
:::
