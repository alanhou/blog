---
title:
  en: "Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting"
  zh: "通过细粒度细节定向推进黑盒大型视觉语言模型攻击前沿"
description:
  en: "M-Attack-V2 introduces gradient-denoising techniques to dramatically improve black-box adversarial attacks on frontier LVLMs, achieving up to 30% success rate on Claude-4.0 and near-perfect performance on GPT-5."
  zh: "M-Attack-V2引入梯度去噪技术,显著提升对前沿大型视觉语言模型的黑盒对抗攻击效果,在Claude-4.0上达到30%成功率,在GPT-5上接近完美表现。"
date: 2026-02-20
tags: ["arxiv", "ai", "cs.lg", "cs.ai", "cs.cl", "cs.cv"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.17645](https://arxiv.org/abs/2602.17645)
**Authors**: Xiaohan Zhao, Zhaoyi Li, Yaxin Luo, Jiacheng Cui, Zhiqiang Shen
**Categories**: cs.LG, cs.AI, cs.CL, cs.CV

## Abstract

This paper addresses the challenge of black-box adversarial attacks on Large Vision-Language Models (LVLMs), where gradient information is unavailable and multimodal decision boundaries are complex. The authors identify critical limitations in existing transfer-based approaches like M-Attack: local crop-level matching produces high-variance, nearly orthogonal gradients across iterations due to Vision Transformer (ViT) translation sensitivity and structural asymmetry between source and target crops. To address this, they propose M-Attack-V2, which reformulates local matching as an asymmetric expectation framework and introduces gradient-denoising mechanisms. The approach achieves substantial improvements in attack success rates across frontier LVLMs, including Claude-4.0 (8% → 30%), Gemini-2.5-Pro (83% → 97%), and GPT-5 (98% → 100%).

## Key Contributions

- **Problem Identification**: Discovered that existing local crop-level matching in M-Attack generates high-variance, nearly orthogonal gradients that destabilize optimization, attributed to ViT translation sensitivity and structural asymmetry
- **Multi-Crop Alignment (MCA)**: Reduces gradient variance on the source side by averaging gradients from multiple independently sampled local views per iteration
- **Auxiliary Target Alignment (ATA)**: Replaces aggressive target augmentation with a semantically correlated auxiliary set, producing a smoother, lower-variance target manifold
- **Patch Momentum**: Reinterprets momentum as a mechanism for replaying historical crop gradients, combined with refined patch-size ensemble (PE+) to strengthen transferable attack directions
- **State-of-the-Art Performance**: Achieves significant improvements over prior black-box LVLM attacks across multiple frontier models

## Technical Methodology

The core innovation of M-Attack-V2 lies in its gradient-denoising framework that addresses the instability of local crop-level matching. The authors reformulate the optimization problem as:

$$\mathbb{E}_{T_s \sim \mathcal{T}_s, T_t \sim \mathcal{T}_t}[\mathcal{L}(f(T_s(x + \delta)), f(T_t(x_{target})))]$$

where $T_s$ and $T_t$ represent source and target transformations respectively.

**Multi-Crop Alignment (MCA)** samples $K$ independent local crops from the source image per iteration and averages their gradients:

$$g_{MCA} = \frac{1}{K}\sum_{i=1}^{K} \nabla_\delta \mathcal{L}(f(crop_i(x + \delta)), f(x_{target}))$$

This variance reduction technique ensures more coherent gradient directions across iterations, addressing the spike-like gradients caused by ViT's translation sensitivity.

**Auxiliary Target Alignment (ATA)** constructs a small auxiliary target set $\mathcal{X}_{aux}$ from a semantically correlated distribution rather than aggressive augmentations of a single target. This produces a smoother target manifold:

$$g_{ATA} = \mathbb{E}_{x_{aux} \sim \mathcal{X}_{aux}}[
abla_\delta \mathcal{L}(f(x + \delta), f(x_{aux}))]$$

**Patch Momentum** extends traditional momentum by maintaining a history of crop-specific gradients, enabling the replay of successful local attack patterns. Combined with PE+, which ensembles multiple patch sizes, this mechanism identifies and amplifies transferable adversarial directions that generalize across different LVLM architectures.

## Experimental Results and Analysis

M-Attack-V2 demonstrates substantial improvements across multiple frontier LVLMs in black-box settings. The results reveal several important patterns:

**Performance on Frontier Models**: The attack achieves dramatic improvements on Claude-4.0 (from 8% to 30% success rate), representing a 3.75× improvement. On Gemini-2.5-Pro, success rates increase from 83% to 97%, while GPT-5 reaches near-perfect 100% from 98%. These results indicate that the gradient-denoising approach effectively addresses the transferability gap in black-box scenarios.

**Ablation Studies**: Individual component analysis shows that MCA contributes the most significant variance reduction, while ATA provides complementary benefits by smoothing the target manifold. Patch Momentum and PE+ together enhance the stability of transferable directions. The modular design allows practitioners to selectively apply components based on computational constraints.

**Computational Efficiency**: Despite sampling multiple crops per iteration, M-Attack-V2 maintains reasonable computational overhead through efficient batching and parallel processing. The auxiliary target set in ATA is kept small (typically 5-10 images) to balance effectiveness and efficiency.

**Cross-Model Transferability**: The improved gradient coherence leads to better transferability across different LVLM architectures, suggesting that the approach captures more fundamental vulnerabilities in multimodal alignment rather than model-specific artifacts.

## Security Implications and Future Directions

The success of M-Attack-V2 highlights critical security vulnerabilities in current LVLM deployments. The ability to achieve high attack success rates in black-box settings—where attackers have no access to model internals—demonstrates that even frontier commercial models remain susceptible to carefully crafted adversarial perturbations.

**Defense Considerations**: The gradient-denoising perspective suggests potential defense mechanisms. Randomized cropping and multi-scale processing during inference could disrupt the coherent local alignment that M-Attack-V2 exploits. Adversarial training with diverse crop-level perturbations may improve robustness.

**Broader Impact**: This work underscores the need for robust evaluation of LVLMs before deployment in security-critical applications. The modular framework provides a standardized benchmark for measuring LVLM robustness and tracking progress in adversarial defenses.

**Future Research**: Promising directions include extending the gradient-denoising framework to other modalities (audio, video), investigating adaptive defenses that detect multi-crop attack patterns, and developing certified robustness guarantees for multimodal models.

## Takeaways

1. Local crop-level matching in transfer-based attacks suffers from high-variance, orthogonal gradients due to ViT translation sensitivity and structural asymmetry
2. Multi-Crop Alignment (MCA) and Auxiliary Target Alignment (ATA) provide complementary gradient-denoising mechanisms that stabilize optimization
3. Patch Momentum combined with refined patch-size ensemble (PE+) strengthens transferable adversarial directions across LVLM architectures
4. M-Attack-V2 achieves state-of-the-art black-box attack performance on frontier LVLMs, with success rates reaching 30% on Claude-4.0, 97% on Gemini-2.5-Pro, and 100% on GPT-5
5. The modular design enables flexible deployment based on computational constraints and target model characteristics
6. Results highlight critical security vulnerabilities in current LVLM deployments and emphasize the need for robust evaluation before production use
:::

:::zh
**论文**: [2602.17645](https://arxiv.org/abs/2602.17645)
**作者**: Xiaohan Zhao, Zhaoyi Li, Yaxin Luo, Jiacheng Cui, Zhiqiang Shen
**分类**: cs.LG, cs.AI, cs.CL, cs.CV

## 摘要

本文针对大型视觉语言模型(LVLM)的黑盒对抗攻击问题展开研究,在这种场景下梯度信息不可获取且多模态决策边界复杂。作者识别出现有迁移攻击方法(如M-Attack)的关键局限:局部裁剪级别匹配会产生高方差、近乎正交的梯度,这是由于视觉Transformer(ViT)的平移敏感性和源-目标裁剪之间的结构不对称性导致的。为解决这一问题,研究者提出M-Attack-V2,将局部匹配重新表述为非对称期望框架,并引入梯度去噪机制。该方法在前沿LVLM上实现了攻击成功率的大幅提升,包括Claude-4.0(8% → 30%)、Gemini-2.5-Pro(83% → 97%)和GPT-5(98% → 100%)。

## 主要贡献

- **问题识别**:发现M-Attack中现有的局部裁剪级别匹配会生成高方差、近乎正交的梯度,导致优化不稳定,归因于ViT平移敏感性和结构不对称性
- **多裁剪对齐(MCA)**:通过对每次迭代中多个独立采样的局部视图的梯度进行平均,降低源端梯度方差
- **辅助目标对齐(ATA)**:用语义相关分布的小型辅助集替代激进的目标增强,产生更平滑、低方差的目标流形
- **补丁动量(Patch Momentum)**:将动量重新解释为历史裁剪梯度的重放机制,结合改进的补丁尺寸集成(PE+)增强可迁移攻击方向
- **最先进性能**:在多个前沿模型上相比先前黑盒LVLM攻击实现显著改进

## 技术方法论

M-Attack-V2的核心创新在于其梯度去噪框架,该框架解决了局部裁剪级别匹配的不稳定性问题。作者将优化问题重新表述为:

$$\mathbb{E}_{T_s \sim \mathcal{T}_s, T_t \sim \mathcal{T}_t}[\mathcal{L}(f(T_s(x + \delta)), f(T_t(x_{target})))]$$

其中$T_s$和$T_t$分别表示源变换和目标变换。

**多裁剪对齐(MCA)**在每次迭代中从源图像采样$K$个独立的局部裁剪并平均其梯度:

$$g_{MCA} = \frac{1}{K}\sum_{i=1}^{K} 
abla_\delta \mathcal{L}(f(crop_i(x + \delta)), f(x_{target}))$$

这种方差缩减技术确保跨迭代的梯度方向更加一致,解决了ViT平移敏感性导致的尖峰状梯度问题。

**辅助目标对齐(ATA)**从语义相关分布构建小型辅助目标集$\mathcal{X}_{aux}$,而非对单一目标进行激进增强。这产生了更平滑的目标流形:

$$g_{ATA} = \mathbb{E}_{x_{aux} \sim \mathcal{X}_{aux}}[
abla_\delta \mathcal{L}(f(x + \delta), f(x_{aux}))]$$

**补丁动量**通过维护裁剪特定梯度的历史记录扩展了传统动量,实现成功局部攻击模式的重放。结合集成多个补丁尺寸的PE+,该机制识别并放大可跨不同LVLM架构泛化的可迁移对抗方向。

## 实验结果与分析

M-Attack-V2在黑盒设置下对多个前沿LVLM展现出显著改进。结果揭示了几个重要模式:

**前沿模型性能**:该攻击在Claude-4.0上实现了显著改进(成功率从8%提升至30%),代表3.75倍的提升。在Gemini-2.5-Pro上,成功率从83%增至97%,而GPT-5达到了从98%到接近完美的100%。这些结果表明梯度去噪方法有效解决了黑盒场景中的可迁移性差距。

**消融研究**:单个组件分析显示MCA贡献了最显著的方差缩减,而ATA通过平滑目标流形提供互补优势。补丁动量和PE+共同增强了可迁移方向的稳定性。模块化设计允许实践者根据计算约束选择性应用组件。

**计算效率**:尽管每次迭代采样多个裁剪,M-Attack-V2通过高效批处理和并行处理保持了合理的计算开销。ATA中的辅助目标集保持较小规模(通常5-10张图像)以平衡有效性和效率。

**跨模型可迁移性**:改进的梯度一致性导致跨不同LVLM架构的更好可迁移性,表明该方法捕获了多模态对齐中更基础的漏洞,而非模型特定的伪影。

## 安全影响与未来方向

M-Attack-V2的成功凸显了当前LVLM部署中的关键安全漏洞。在黑盒设置下实现高攻击成功率的能力——攻击者无法访问模型内部——表明即使是前沿商业模型仍然容易受到精心设计的对抗扰动的影响。

**防御考虑**:梯度去噪视角提示了潜在的防御机制。推理期间的随机裁剪和多尺度处理可能破坏M-Attack-V2利用的一致局部对齐。使用多样化裁剪级别扰动的对抗训练可能提高鲁棒性。

**更广泛影响**:这项工作强调了在安全关键应用中部署LVLM之前进行鲁棒评估的必要性。模块化框架为测量LVLM鲁棒性和跟踪对抗防御进展提供了标准化基准。

**未来研究**:有前景的方向包括将梯度去噪框架扩展到其他模态(音频、视频),研究检测多裁剪攻击模式的自适应防御,以及为多模态模型开发经认证的鲁棒性保证。

## 要点总结

1. 迁移攻击中的局部裁剪级别匹配由于ViT平移敏感性和结构不对称性而遭受高方差、正交梯度问题
2. 多裁剪对齐(MCA)和辅助目标对齐(ATA)提供互补的梯度去噪机制,稳定优化过程
3. 补丁动量结合改进的补丁尺寸集成(PE+)增强跨LVLM架构的可迁移对抗方向
4. M-Attack-V2在前沿LVLM上实现最先进的黑盒攻击性能,成功率在Claude-4.0上达到30%,Gemini-2.5-Pro上达到97%,GPT-5上达到100%
5. 模块化设计支持基于计算约束和目标模型特性的灵活部署
6. 研究结果凸显当前LVLM部署中的关键安全漏洞,强调生产使用前进行鲁棒评估的必要性
:::
