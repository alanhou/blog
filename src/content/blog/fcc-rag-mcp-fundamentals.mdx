---
title:
  en: "RAG & MCP Fundamentals – A Hands-On Crash Course"
  zh: "RAG与MCP基础 - 实战速成课程"
description:
  en: "Learn to build integrated AI systems with Retrieval-Augmented Generation (RAG) and Model Context Protocol (MCP) from freeCodeCamp"
  zh: "学习使用检索增强生成(RAG)和模型上下文协议(MCP)构建集成AI系统"
date: 2026-01-22
tags: ["ai", "rag", "mcp", "llm", "embeddings", "vector-database", "freecodecamp"]
image: "https://i2.ytimg.com/vi/I7_WXKhyGms/hqdefault.jpg"
---

import YouTube from '../../components/YouTube.astro';

<YouTube id="I7_WXKhyGms" title="RAG & MCP Fundamentals – A Hands-On Crash Course" />

:::en
This practical crash course from freeCodeCamp teaches you to build integrated AI systems rather than standalone tools. The course covers two key technologies: RAG (Retrieval-Augmented Generation) and MCP (Model Context Protocol).

## What You'll Learn

### Part 1: RAG (Retrieval-Augmented Generation)

RAG connects AI models to your own data, reducing hallucinations and providing accurate, contextual responses.

**Key Concepts:**
- **Embeddings**: Converting text into numerical vectors (384-dimensional) that capture semantic meaning
- **Vector Databases**: Storing and searching embeddings efficiently (ChromaDB, Pinecone)
- **Semantic Search**: Finding documents by meaning, not just keywords
- **Chunking Strategies**: Breaking documents into optimal pieces for retrieval

**RAG Pipeline:**
1. User query comes in
2. Query is converted to embedding
3. Similar documents are retrieved from vector database
4. Retrieved context + query sent to LLM
5. LLM generates response grounded in your data

**Chunking Methods:**
- Fixed-size chunking (simple but may break context)
- Sentence-based chunking
- Semantic chunking (preserves meaning)

**Search Techniques:**
- Keyword search (BM25)
- Semantic search (embeddings)
- Hybrid search (best of both)

### Part 2: MCP (Model Context Protocol)

MCP is a protocol developed by Anthropic that standardizes how AI agents interact with external tools and services.

**Why MCP?**
- Standardizes tool integration across different AI systems
- Enables AI agents to interact with APIs, databases, and services
- Follows client-server architecture
- Uses JSON-RPC for communication

**MCP Architecture:**
- **MCP Server**: Exposes tools and resources
- **MCP Client**: AI agent that consumes tools
- **JSON-RPC Protocol**: Communication standard (version 2.0)

**Building MCP Servers:**
- Python SDK available
- Define tools as methods
- Server can be hosted locally or remotely
- Supports HTTP and Standard IO transports

**Key Features:**
- Tools: Functions the AI can call
- Resources: Data the AI can access
- Prompts: Pre-defined interaction patterns
- Elicitation: Server requesting info from client

### Hands-On Labs

The course includes practical labs:
1. Setting up RAG pipeline with ChromaDB
2. Creating embeddings with sentence transformers
3. Building semantic search
4. Creating an MCP server from scratch
5. Integrating MCP with AI agents

### Production Considerations

**Caching:**
- LLM calls are slow and expensive
- Cache frequent queries and responses
- Reduces latency and costs

**Monitoring:**
- Prometheus for metrics
- Grafana for visualization
- Track response times, accuracy, costs

**When to Use What:**
- **RAG**: When you need AI to reference your specific documents
- **Fine-tuning**: When you need to change model behavior fundamentally
- **MCP**: When you need AI to interact with external systems

## Key Takeaways

1. RAG reduces hallucinations by grounding responses in real data
2. Embeddings capture semantic meaning in numerical form
3. Vector databases enable efficient similarity search
4. MCP standardizes AI-tool integration
5. Hybrid approaches (keyword + semantic) often work best
6. Chunking strategy significantly impacts retrieval quality
:::

:::zh
这门来自freeCodeCamp的实战速成课程教你构建集成AI系统，而非独立工具。课程涵盖两项关键技术：RAG（检索增强生成）和MCP（模型上下文协议）。

## 学习内容

### 第一部分：RAG（检索增强生成）

RAG将AI模型连接到你自己的数据，减少幻觉并提供准确的上下文响应。

**核心概念：**
- **嵌入向量**：将文本转换为捕获语义含义的数值向量（384维）
- **向量数据库**：高效存储和搜索嵌入向量（ChromaDB、Pinecone）
- **语义搜索**：按含义而非关键词查找文档
- **分块策略**：将文档分割成最优的检索片段

**RAG流程：**
1. 用户查询进入
2. 查询转换为嵌入向量
3. 从向量数据库检索相似文档
4. 检索到的上下文+查询发送给LLM
5. LLM生成基于你数据的响应

**分块方法：**
- 固定大小分块（简单但可能破坏上下文）
- 基于句子的分块
- 语义分块（保留含义）

**搜索技术：**
- 关键词搜索（BM25）
- 语义搜索（嵌入向量）
- 混合搜索（两者结合）

### 第二部分：MCP（模型上下文协议）

MCP是Anthropic开发的协议，标准化AI代理与外部工具和服务的交互方式。

**为什么需要MCP？**
- 标准化不同AI系统的工具集成
- 使AI代理能与API、数据库和服务交互
- 遵循客户端-服务器架构
- 使用JSON-RPC进行通信

**MCP架构：**
- **MCP服务器**：暴露工具和资源
- **MCP客户端**：消费工具的AI代理
- **JSON-RPC协议**：通信标准（版本2.0）

**构建MCP服务器：**
- 提供Python SDK
- 将工具定义为方法
- 服务器可本地或远程托管
- 支持HTTP和标准IO传输

**关键特性：**
- 工具：AI可调用的函数
- 资源：AI可访问的数据
- 提示：预定义的交互模式
- 引出：服务器向客户端请求信息

### 实践实验

课程包含实践实验：
1. 使用ChromaDB设置RAG流程
2. 使用sentence transformers创建嵌入向量
3. 构建语义搜索
4. 从零创建MCP服务器
5. 将MCP与AI代理集成

### 生产环境考虑

**缓存：**
- LLM调用慢且昂贵
- 缓存频繁的查询和响应
- 降低延迟和成本

**监控：**
- Prometheus用于指标
- Grafana用于可视化
- 跟踪响应时间、准确性、成本

**何时使用什么：**
- **RAG**：当需要AI引用你的特定文档时
- **微调**：当需要从根本上改变模型行为时
- **MCP**：当需要AI与外部系统交互时

## 关键要点

1. RAG通过将响应基于真实数据来减少幻觉
2. 嵌入向量以数值形式捕获语义含义
3. 向量数据库实现高效的相似性搜索
4. MCP标准化AI-工具集成
5. 混合方法（关键词+语义）通常效果最好
6. 分块策略显著影响检索质量
:::
