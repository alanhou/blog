---
title:
  en: "LLM Novice Uplift on Dual-Use, In Silico Biology Tasks"
  zh: "大语言模型对新手在双重用途生物学任务中的能力提升研究"
description:
  en: "A comprehensive study revealing that LLMs enable novices to achieve 4.16x better accuracy on biosecurity-relevant tasks, often matching or exceeding expert performance, raising critical questions about dual-use risks and AI safety."
  zh: "一项综合研究表明,大语言模型使新手在生物安全相关任务上的准确率提高4.16倍,通常达到或超过专家水平,引发了关于双重用途风险和AI安全的关键问题。"
date: 2026-02-27
tags: ["arxiv", "ai", "cs.ai", "cs.cl", "cs.cr", "cs.cy", "cs.hc"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.23329](https://arxiv.org/abs/2602.23329)
**Authors**: Chen Bo Calvin Zhang, Christina Q. Knight, Nicholas Kruus, Jason Hausenloy, Pedro Medeiros, Nathaniel Li, Aiden Kim, Yury Orlovskiy, Coleman Breen, Bryce Cai
**Categories**: cs.AI, cs.CL, cs.CR, cs.CY, cs.HC

## Abstract

This paper presents a rigorous empirical investigation into whether large language models genuinely uplift novice users on complex biological tasks with dual-use implications. While LLMs demonstrate impressive performance on biology benchmarks, the critical question of whether they enable non-experts to perform tasks previously requiring specialized training has remained largely unexplored. The researchers conducted a multi-model, multi-benchmark study comparing novices with LLM access against those with internet-only access across eight biosecurity-relevant task sets. The results are striking: LLM-assisted novices achieved 4.16 times higher accuracy than controls (95% CI [2.63, 6.87]) and outperformed internet-only experts on three out of four benchmarks. Notably, standalone LLMs often exceeded human-LLM collaborative performance, suggesting users struggle to fully leverage model capabilities. Despite existing safeguards, 89.6% of participants reported minimal difficulty accessing dual-use information, highlighting urgent biosecurity concerns.

## Key Contributions

- First large-scale human uplift study measuring LLM impact on novice performance in biosecurity-relevant biological tasks
- Quantitative demonstration of substantial uplift: novices with LLMs achieved 4.16x accuracy improvement over internet-only controls
- Evidence that LLM-assisted novices can match or exceed expert-level performance on complex in silico biology tasks
- Discovery that standalone LLMs often outperform human-LLM collaboration, indicating suboptimal human prompting strategies
- Documentation that current safeguards provide minimal barriers to dual-use information access (89.6% success rate)
- Establishment of a methodological framework for interactive uplift evaluations beyond static benchmarks

## Experimental Design and Methodology

The study employed a rigorous between-subjects design with participants randomly assigned to either LLM-access or internet-only control conditions. Eight distinct task sets were developed spanning biosecurity-relevant domains, including protein engineering, synthetic biology pathway design, and computational virology. Tasks were designed to be complex enough to require substantial expertise while remaining tractable for motivated novices given sufficient time and resources.

Participants were given generous time allocations—up to 13 hours for the most demanding tasks—to ensure that performance differences reflected genuine capability gaps rather than time pressure artifacts. The LLM-access group could use multiple state-of-the-art models, while controls had unrestricted internet access including scientific databases, literature, and online tools. This design choice was deliberate: the goal was to measure whether LLMs provide uplift beyond what comprehensive internet resources already offer.

The researchers implemented multiple quality control measures, including attention checks, expert validation of task difficulty, and post-hoc analysis of participant strategies. Baseline expert performance was established for four of the eight benchmarks using domain specialists with internet-only access, providing crucial reference points for interpreting novice performance.

## Results and Performance Analysis

The quantitative results reveal substantial and statistically significant uplift. The primary finding—a 4.16x accuracy improvement (95% CI [2.63, 6.87])—represents a dramatic capability enhancement. This effect size is particularly noteworthy given that control participants had full internet access, suggesting LLMs provide capabilities beyond information retrieval and synthesis.

Perhaps most striking is the comparison with expert baselines. On three of four benchmarks where expert performance data was available, LLM-assisted novices matched or exceeded expert accuracy. This finding challenges conventional assumptions about the irreplaceability of domain expertise for complex technical tasks. The one benchmark where experts maintained superiority involved highly specialized knowledge of regulatory frameworks, suggesting that LLMs may be less effective for tasks requiring deep contextual understanding of institutional structures.

The performance gap between standalone LLMs and human-LLM collaboration presents an intriguing puzzle. In many cases, the models alone achieved higher accuracy than when assisting human users. This suggests that novices may lack the prompting sophistication, domain knowledge to validate outputs, or strategic thinking needed to fully leverage model capabilities. The implication is that current uplift measurements may actually underestimate the potential risk if users develop more effective interaction strategies.

Regarding safeguards, the results are concerning from a biosecurity perspective. Despite existing content filters and safety measures, 89.6% of participants reported encountering minimal friction when seeking dual-use information. This high success rate suggests that current mitigation strategies are insufficient for preventing misuse by motivated actors.

## Implications for Biosecurity and AI Safety

The findings carry profound implications for biosecurity policy and AI governance. The demonstrated ability of LLMs to uplift novices to expert-level performance on sensitive biological tasks represents a qualitative shift in dual-use risk landscape. Previously, certain capabilities were effectively gatekept by the years of training required to develop relevant expertise. LLMs appear to substantially lower this barrier.

The research highlights a critical gap in current AI safety evaluations. Traditional benchmarks measure model capabilities in isolation but fail to capture the interactive, human-in-the-loop dynamics that characterize real-world use. An LLM might perform poorly on a static benchmark while still providing dangerous uplift to malicious actors through iterative refinement and strategic prompting.

The ineffectiveness of current safeguards demands urgent attention. Content filtering and refusal training appear insufficient when users can iteratively probe models, rephrase queries, or use indirect approaches. More sophisticated mitigation strategies may be needed, potentially including usage monitoring, capability throttling for sensitive domains, or mandatory authentication and audit trails.

The finding that standalone LLMs often outperform human-LLM collaboration suggests a complex risk trajectory. As users develop better prompting strategies and mental models of LLM capabilities, uplift effects may increase substantially. This implies that current measurements may represent a lower bound on potential dual-use risks.

## Takeaways

1. LLMs provide dramatic uplift to novices on complex biological tasks, with a 4.16x accuracy improvement over internet-only access, fundamentally altering the accessibility landscape for specialized capabilities.

2. LLM-assisted novices can match or exceed expert performance on most biosecurity-relevant benchmarks, suggesting that years of specialized training may no longer serve as an effective barrier to certain dual-use capabilities.

3. Current AI safeguards are largely ineffective, with 89.6% of participants reporting minimal difficulty accessing dual-use information, highlighting urgent need for more robust mitigation strategies.

4. Standalone LLMs often outperform human-LLM collaboration, indicating that users are not yet fully leveraging model capabilities—a concerning finding given that improved prompting strategies could increase dual-use risks.

5. Traditional static benchmarks are insufficient for assessing dual-use risks; interactive uplift evaluations that measure human-AI collaborative performance are essential for comprehensive safety assessment.

6. The research establishes a methodological framework for rigorous uplift studies, emphasizing the importance of generous time allocations, expert baselines, and ecologically valid task design in evaluating real-world AI impacts.
:::

:::zh
**论文**: [2602.23329](https://arxiv.org/abs/2602.23329)
**作者**: Chen Bo Calvin Zhang, Christina Q. Knight, Nicholas Kruus, Jason Hausenloy, Pedro Medeiros, Nathaniel Li, Aiden Kim, Yury Orlovskiy, Coleman Breen, Bryce Cai
**分类**: cs.AI, cs.CL, cs.CR, cs.CY, cs.HC

## 摘要

本文对大语言模型是否真正提升新手在具有双重用途影响的复杂生物学任务上的能力进行了严格的实证研究。虽然大语言模型在生物学基准测试中表现出色,但一个关键问题仍未得到充分探索:它们是否能让非专业人士完成以前需要专业训练的任务。研究人员进行了一项多模型、多基准的研究,在八个与生物安全相关的任务集上比较了使用大语言模型的新手与仅使用互联网资源的新手。结果令人震惊:在大语言模型辅助下,新手的准确率比对照组高4.16倍(95%置信区间[2.63, 6.87]),并且在四个有专家基线的基准测试中,有三个超过了仅使用互联网的专家。值得注意的是,独立运行的大语言模型往往超过人机协作的表现,这表明用户难以充分利用模型能力。尽管存在安全防护措施,89.6%的参与者报告在获取双重用途信息时几乎没有遇到困难,这凸显了紧迫的生物安全问题。

## 主要贡献

- 首次进行大规模人类能力提升研究,测量大语言模型对新手在生物安全相关生物学任务上表现的影响
- 定量证明了显著的能力提升:使用大语言模型的新手比仅使用互联网的对照组准确率提高4.16倍
- 证明在大语言模型辅助下的新手可以在复杂的计算生物学任务上达到或超过专家水平
- 发现独立运行的大语言模型往往优于人机协作,表明人类提示策略尚未达到最优
- 记录了当前安全防护措施对双重用途信息访问提供的障碍极小(89.6%的成功率)
- 建立了超越静态基准测试的交互式能力提升评估方法框架

## 实验设计与方法论

该研究采用了严格的组间设计,参与者被随机分配到大语言模型访问组或仅互联网对照组。研究开发了八个不同的任务集,涵盖与生物安全相关的领域,包括蛋白质工程、合成生物学途径设计和计算病毒学。任务设计得足够复杂,需要大量专业知识,但对于有充足时间和资源的积极新手来说仍然可以完成。

参与者获得了充裕的时间分配——最复杂的任务可达13小时——以确保性能差异反映的是真实的能力差距,而非时间压力造成的假象。大语言模型访问组可以使用多个最先进的模型,而对照组则可以无限制地访问互联网,包括科学数据库、文献和在线工具。这种设计选择是有意为之:目标是测量大语言模型是否提供了超越全面互联网资源已经提供的能力提升。

研究人员实施了多项质量控制措施,包括注意力检查、专家对任务难度的验证,以及对参与者策略的事后分析。对于八个基准测试中的四个,使用仅有互联网访问权限的领域专家建立了基线专家表现,为解释新手表现提供了关键参考点。

## 结果与性能分析

定量结果显示了显著且具有统计学意义的能力提升。主要发现——4.16倍的准确率提升(95%置信区间[2.63, 6.87])——代表了巨大的能力增强。考虑到对照组参与者拥有完全的互联网访问权限,这个效应量尤其值得注意,表明大语言模型提供的能力超越了信息检索和综合。

也许最引人注目的是与专家基线的比较。在四个有专家表现数据的基准测试中,大语言模型辅助的新手在三个测试上达到或超过了专家准确率。这一发现挑战了关于领域专业知识在复杂技术任务中不可替代性的传统假设。专家保持优势的那个基准测试涉及监管框架的高度专业化知识,表明大语言模型在需要对制度结构有深入情境理解的任务上可能效果较差。

独立运行的大语言模型与人机协作之间的性能差距呈现出一个有趣的谜题。在许多情况下,模型单独运行时的准确率高于辅助人类用户时。这表明新手可能缺乏提示技巧、验证输出的领域知识,或充分利用模型能力所需的战略思维。这意味着,如果用户开发出更有效的交互策略,当前的能力提升测量实际上可能低估了潜在风险。

关于安全防护措施,从生物安全角度来看,结果令人担忧。尽管存在内容过滤器和安全措施,89.6%的参与者报告在寻求双重用途信息时遇到的阻力极小。这一高成功率表明,当前的缓解策略不足以防止有动机的行为者滥用。

## 对生物安全和AI安全的影响

这些发现对生物安全政策和AI治理具有深远影响。大语言模型将新手提升到专家级别表现的能力,代表了双重用途风险格局的质变。以前,某些能力实际上被开发相关专业知识所需的多年训练所把关。大语言模型似乎大幅降低了这一门槛。

该研究突显了当前AI安全评估中的一个关键缺口。传统基准测试孤立地测量模型能力,但未能捕捉到表征现实世界使用的交互式、人在回路中的动态。一个大语言模型可能在静态基准测试上表现不佳,但仍然通过迭代改进和战略提示为恶意行为者提供危险的能力提升。

当前安全防护措施的无效性需要紧急关注。当用户可以迭代探测模型、重新表述查询或使用间接方法时,内容过滤和拒绝训练似乎不够充分。可能需要更复杂的缓解策略,包括使用监控、敏感领域的能力限制,或强制性身份验证和审计跟踪。

独立运行的大语言模型往往优于人机协作这一发现表明了复杂的风险轨迹。随着用户开发出更好的提示策略和大语言模型能力的心智模型,能力提升效应可能会大幅增加。这意味着当前的测量可能代表了潜在双重用途风险的下限。

## 要点总结

1. 大语言模型为新手在复杂生物学任务上提供了显著的能力提升,准确率比仅使用互联网提高4.16倍,从根本上改变了专业能力的可及性格局。

2. 在大语言模型辅助下的新手可以在大多数与生物安全相关的基准测试上达到或超过专家表现,表明多年的专业训练可能不再是某些双重用途能力的有效障碍。

3. 当前的AI安全防护措施基本无效,89.6%的参与者报告在获取双重用途信息时几乎没有遇到困难,凸显了对更强大缓解策略的迫切需求。

4. 独立运行的大语言模型往往优于人机协作,表明用户尚未充分利用模型能力——考虑到改进的提示策略可能增加双重用途风险,这是一个令人担忧的发现。

5. 传统的静态基准测试不足以评估双重用途风险;测量人机协作表现的交互式能力提升评估对于全面的安全评估至关重要。

6. 该研究建立了严格的能力提升研究方法框架,强调了充裕的时间分配、专家基线和生态有效的任务设计在评估现实世界AI影响中的重要性。
:::
