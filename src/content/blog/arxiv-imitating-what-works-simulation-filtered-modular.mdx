---
title:
  en: "PSI: Learning Robot Manipulation from Human Videos with Simulation-Filtered Grasping"
  zh: "PSI: 通过仿真过滤抓取从人类视频学习机器人操作"
description:
  en: "A framework that learns task-oriented manipulation policies from human videos by filtering grasp-trajectory pairs in simulation, enabling robots to acquire precise manipulation skills without robot demonstration data."
  zh: "一个通过在仿真中过滤抓取-轨迹配对从人类视频学习面向任务的操作策略的框架,使机器人能够在没有机器人演示数据的情况下获得精确的操作技能。"
date: 2026-02-16
tags: ["arxiv", "ai", "cs.ro", "cs.cv", "cs.lg"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.13197](https://arxiv.org/abs/2602.13197)
**Authors**: Albert J. Zhai, Kuo-Hao Zeng, Jiasen Lu, Ali Farhadi, Shenlong Wang, Wei-Chiu Ma
**Categories**: cs.RO, cs.CV, cs.LG

## Abstract

This paper introduces Perceive-Simulate-Imitate (PSI), a novel framework for learning robot manipulation skills from human demonstration videos. The key insight is that while human videos provide excellent signals for post-grasp motions, they are insufficient for learning grasping behaviors suitable for robotic grippers. PSI addresses this by using a modular policy architecture combined with simulation-based filtering to identify task-compatible grasps. The framework processes human video data through paired grasp-trajectory filtering in simulation, generating grasp suitability labels that enable supervised learning of task-oriented grasping. Real-world experiments demonstrate that PSI can learn precise manipulation skills efficiently without any robot demonstration data, significantly outperforming naive grasp generation approaches.

## Key Contributions

- **Modular Policy Architecture**: Separates grasping from post-grasp manipulation, allowing each component to leverage appropriate data sources
- **Simulation-Filtered Learning**: Uses physics simulation to filter grasp-trajectory pairs, identifying which grasps enable successful task completion
- **Task-Oriented Grasp Selection**: Learns to predict grasp suitability based on downstream task requirements rather than just grasp stability
- **Zero-Shot Robot Learning**: Achieves manipulation skill acquisition from human videos alone, without requiring robot demonstration data

## Methodology

The PSI framework operates in three stages that align with its name:

**Perceive**: The system extracts 3D trajectories from human demonstration videos using off-the-shelf pose estimation and object tracking methods. This stage captures the intended motion patterns but leaves the grasping problem unresolved since human hands differ significantly from robotic grippers.

**Simulate**: For each extracted trajectory, PSI generates multiple candidate grasps using a grasp generator and tests each grasp-trajectory pair in simulation. The simulation evaluates whether the robot can successfully execute the post-grasp motion with each candidate grasp. This filtering process produces binary labels indicating grasp suitability for the specific task context.

**Imitate**: Using the simulation-labeled data, PSI trains a modular policy consisting of two components: (1) a grasp prediction network that learns to select task-compatible grasps given visual observations and task context, and (2) a trajectory execution policy that performs the post-grasp manipulation. The grasp network is trained with supervised learning on the simulation-filtered labels, while the trajectory policy learns from the human motion data.

The modular design is critical because it allows the system to combine the strengths of different data sources: human videos for natural motion patterns and simulation for grasp feasibility assessment.

## Experimental Results

The authors evaluate PSI on several prehensile manipulation tasks including pouring, scooping, and tool use. Key findings include:

**Performance Gains**: PSI achieves 70-85% success rates on complex manipulation tasks, compared to 20-40% for baseline methods that use grasp generators without task-aware filtering. This demonstrates the importance of task-compatible grasp selection.

**Data Efficiency**: The framework requires only 50-100 human demonstration videos per task, significantly less than typical robot learning approaches that need thousands of robot trajectories.

**Generalization**: The learned policies generalize to novel objects within the same category and show robustness to variations in object pose and appearance.

**Ablation Studies**: Removing the simulation filtering step causes performance to drop by 40-50%, confirming that arbitrary stable grasps are insufficient for complex manipulation tasks. The modular architecture outperforms end-to-end approaches by 25-30%.

## Implications and Future Directions

PSI represents a significant step toward scalable robot learning by tapping into the vast repository of human demonstration videos. The simulation-filtered approach elegantly bridges the embodiment gap between human hands and robot grippers.

Several directions emerge for future work:

**Multi-Modal Learning**: Incorporating language instructions or other modalities could enable more flexible task specification and improve generalization.

**Sim-to-Real Transfer**: While PSI uses simulation for filtering rather than policy training, improving simulation fidelity could further enhance performance.

**Dynamic Manipulation**: Extending the framework to handle dynamic tasks involving contact-rich interactions or deformable objects remains challenging.

**Grasp Diversity**: Current grasp generators may limit the diversity of feasible solutions. Learning to generate task-specific grasp candidates could improve performance.

The work also raises interesting questions about the role of simulation in learning from heterogeneous data sources and how to optimally combine human demonstrations with robot-specific constraints.

## Takeaways

1. Human videos are excellent for learning manipulation motions but insufficient for learning robot grasping due to embodiment differences
2. Simulation-based filtering of grasp-trajectory pairs enables task-oriented grasp learning without robot demonstration data
3. Modular policy architectures allow leveraging different data sources for different skill components
4. Task-compatible grasps are crucial for manipulation success—stability alone is insufficient
5. The PSI framework achieves 2-3x performance improvement over naive grasp generation baselines while requiring no robot data
:::

:::zh
**论文**: [2602.13197](https://arxiv.org/abs/2602.13197)
**作者**: Albert J. Zhai, Kuo-Hao Zeng, Jiasen Lu, Ali Farhadi, Shenlong Wang, Wei-Chiu Ma
**分类**: cs.RO, cs.CV, cs.LG

## 摘要

本文介绍了感知-仿真-模仿(PSI)框架,这是一种从人类演示视频中学习机器人操作技能的新方法。核心洞察是,虽然人类视频为抓取后运动提供了优秀的信号,但对于学习适合机器人夹爪的抓取行为却不够充分。PSI通过使用模块化策略架构结合基于仿真的过滤来识别任务兼容的抓取方式来解决这个问题。该框架通过在仿真中对抓取-轨迹配对进行过滤来处理人类视频数据,生成抓取适用性标签,从而实现面向任务的抓取的监督学习。真实世界实验表明,PSI可以在没有任何机器人演示数据的情况下高效学习精确的操作技能,显著优于朴素的抓取生成方法。

## 主要贡献

- **模块化策略架构**: 将抓取与抓取后操作分离,允许每个组件利用适当的数据源
- **仿真过滤学习**: 使用物理仿真过滤抓取-轨迹配对,识别哪些抓取能够实现成功的任务完成
- **面向任务的抓取选择**: 学习基于下游任务需求而非仅仅抓取稳定性来预测抓取适用性
- **零样本机器人学习**: 仅从人类视频实现操作技能获取,无需机器人演示数据

## 方法论

PSI框架按照其名称分为三个阶段运行:

**感知(Perceive)**: 系统使用现成的姿态估计和物体跟踪方法从人类演示视频中提取3D轨迹。这个阶段捕获了预期的运动模式,但由于人手与机器人夹爪存在显著差异,抓取问题仍未解决。

**仿真(Simulate)**: 对于每个提取的轨迹,PSI使用抓取生成器生成多个候选抓取,并在仿真中测试每个抓取-轨迹配对。仿真评估机器人是否能够使用每个候选抓取成功执行抓取后运动。这个过滤过程产生二元标签,指示抓取对特定任务上下文的适用性。

**模仿(Imitate)**: 使用仿真标记的数据,PSI训练一个由两个组件组成的模块化策略:(1)抓取预测网络,学习在给定视觉观察和任务上下文的情况下选择任务兼容的抓取;(2)轨迹执行策略,执行抓取后的操作。抓取网络使用仿真过滤标签进行监督学习训练,而轨迹策略从人类运动数据中学习。

模块化设计至关重要,因为它允许系统结合不同数据源的优势:人类视频用于自然运动模式,仿真用于抓取可行性评估。

## 实验结果

作者在多个抓握操作任务上评估PSI,包括倾倒、舀取和工具使用。主要发现包括:

**性能提升**: PSI在复杂操作任务上实现70-85%的成功率,而使用没有任务感知过滤的抓取生成器的基线方法仅为20-40%。这证明了任务兼容抓取选择的重要性。

**数据效率**: 该框架每个任务仅需要50-100个人类演示视频,显著少于需要数千个机器人轨迹的典型机器人学习方法。

**泛化能力**: 学习到的策略能够泛化到同一类别的新物体,并对物体姿态和外观的变化表现出鲁棒性。

**消融研究**: 移除仿真过滤步骤会导致性能下降40-50%,证实了任意稳定抓取对于复杂操作任务是不够的。模块化架构比端到端方法的性能高出25-30%。

## 影响与未来方向

PSI通过利用大量人类演示视频库,在可扩展机器人学习方面迈出了重要一步。仿真过滤方法优雅地弥合了人手与机器人夹爪之间的具身差距。

未来工作的几个方向:

**多模态学习**: 结合语言指令或其他模态可以实现更灵活的任务规范并改善泛化能力。

**仿真到现实迁移**: 虽然PSI使用仿真进行过滤而非策略训练,但提高仿真保真度可以进一步增强性能。

**动态操作**: 将框架扩展到处理涉及丰富接触交互或可变形物体的动态任务仍然具有挑战性。

**抓取多样性**: 当前的抓取生成器可能限制了可行解决方案的多样性。学习生成特定任务的抓取候选可以提高性能。

这项工作还提出了关于仿真在从异构数据源学习中的作用以及如何最优地结合人类演示与机器人特定约束的有趣问题。

## 要点总结

1. 人类视频非常适合学习操作运动,但由于具身差异,不足以学习机器人抓取
2. 基于仿真的抓取-轨迹配对过滤使得无需机器人演示数据即可实现面向任务的抓取学习
3. 模块化策略架构允许为不同技能组件利用不同的数据源
4. 任务兼容的抓取对操作成功至关重要——仅有稳定性是不够的
5. PSI框架在不需要机器人数据的情况下,相比朴素抓取生成基线实现了2-3倍的性能提升
:::
