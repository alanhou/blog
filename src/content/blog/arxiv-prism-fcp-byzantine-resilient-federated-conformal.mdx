---
title:
  en: "PRISM-FCP: Byzantine-Resilient Federated Conformal Prediction via Partial Sharing"
  zh: "PRISM-FCP: 通过部分共享实现拜占庭容错的联邦保形预测"
description:
  en: "A novel federated conformal prediction framework that achieves end-to-end Byzantine resilience through partial model sharing during training and robust calibration, maintaining coverage guarantees while reducing communication overhead."
  zh: "一种新型联邦保形预测框架,通过训练期间的部分模型共享和鲁棒校准实现端到端的拜占庭容错,在降低通信开销的同时保持覆盖保证。"
date: 2026-02-23
tags: ["arxiv", "ai", "cs.lg", "eess.sp", "math.pr", "stat.ap", "stat.ml"]
image: "/arxiv-visuals/arxiv-prism-fcp-byzantine-resilient-federated-conformal.png"
---

:::en
**Paper**: [2602.18396](https://arxiv.org/abs/2602.18396)
**Authors**: Ehsan Lari, Reza Arablouei, Stefan Werner
**Categories**: cs.LG, eess.SP, math.PR, stat.AP, stat.ML

## Abstract

This paper introduces PRISM-FCP, a Byzantine-resilient federated conformal prediction framework that addresses a critical gap in existing approaches: vulnerability to adversarial attacks during model training. While traditional federated conformal prediction (FCP) methods focus solely on protecting the calibration stage, PRISM-FCP provides end-to-end protection by implementing partial model sharing during training and robust calibration mechanisms. The framework transmits only $M$ out of $D$ parameters per communication round, which mathematically attenuates adversarial perturbation energy by a factor of $M/D$. During calibration, the system employs distance-based maliciousness scoring to identify and downweight Byzantine contributions. Experimental validation on synthetic and real-world datasets demonstrates that PRISM-FCP maintains nominal coverage guarantees under attack while producing tighter prediction intervals and reducing communication costs compared to standard FCP.

## Key Contributions

- **End-to-end Byzantine resilience**: Unlike existing FCP methods that only protect calibration, PRISM-FCP mitigates adversarial attacks throughout both training and calibration phases
- **Partial sharing mechanism**: Introduces a communication-efficient approach where clients transmit only $M$ of $D$ parameters per round, reducing adversarial impact by factor $M/D$
- **Robust calibration protocol**: Develops a distance-based maliciousness scoring system that converts nonconformity scores into characterization vectors for Byzantine detection
- **Theoretical guarantees**: Provides mathematical analysis showing reduced mean-square error (MSE) and tighter prediction intervals under partial sharing
- **Empirical validation**: Demonstrates maintained coverage guarantees and reduced interval inflation on UCI Superconductivity dataset and synthetic data

## Methodology and Technical Framework

PRISM-FCP operates through two distinct phases, each incorporating Byzantine-resilient mechanisms.

**Training Phase with Partial Sharing**: During federated learning, each client computes local model updates but transmits only a subset of parameters. Specifically, if the full parameter vector has dimension $D$, clients randomly select and share $M < D$ parameters per round. This partial sharing strategy has a profound mathematical consequence: it attenuates the expected energy of any adversarial perturbation in the aggregated update by the ratio $M/D$. For Byzantine attackers attempting to inject malicious gradients, this means their influence is systematically diluted across the aggregation process. The server aggregates these partial updates using robust aggregation methods, which further filters outlier contributions.

**Calibration Phase with Robust Scoring**: After training, the calibration phase constructs prediction intervals with statistical coverage guarantees. Each client computes nonconformity scores on their local calibration data—these scores measure how "unusual" each prediction is. PRISM-FCP transforms these scores into characterization vectors that capture their statistical properties. The framework then computes distance-based maliciousness scores by measuring how far each client's characterization vector deviates from the median behavior. Clients with high maliciousness scores are either downweighted or filtered entirely before the conformal quantile estimation. This ensures that the final prediction intervals reflect honest client behavior while maintaining the theoretical coverage guarantee of $1-\alpha$ for a specified miscoverage rate $\alpha$.

## Experimental Results and Performance Analysis

The experimental evaluation demonstrates PRISM-FCP's effectiveness across multiple dimensions.

**Coverage Maintenance Under Attack**: On the UCI Superconductivity dataset with 30% Byzantine clients, PRISM-FCP maintains the nominal 90% coverage rate while standard FCP degrades significantly. The framework achieves this without the interval inflation typically observed when defending against attacks—prediction intervals remain tight and informative.

**Communication Efficiency**: By transmitting only $M/D$ of the parameters (experiments used $M/D = 0.5$), PRISM-FCP reduces communication overhead by 50% compared to full parameter sharing. This reduction comes with minimal impact on model accuracy, as the partial sharing mechanism still captures sufficient gradient information for convergence.

**MSE Reduction**: The partial sharing strategy yields lower mean-square error in the learned model compared to full sharing under Byzantine attacks. This counterintuitive result occurs because partial sharing acts as an implicit regularizer that prevents adversarial perturbations from dominating the aggregated update.

**Robustness to Attack Intensity**: Experiments varied the percentage of Byzantine clients from 10% to 40%. PRISM-FCP maintained stable performance across this range, while baseline methods showed progressive degradation. The distance-based maliciousness scoring proved particularly effective at identifying coordinated attacks where multiple Byzantine clients attempt to bias the conformal quantile estimation.

## Implications for Federated Learning and Uncertainty Quantification

PRISM-FCP addresses a fundamental challenge in federated learning: providing reliable uncertainty quantification in adversarial environments. The framework's implications extend across several domains.

**Trustworthy AI Deployment**: In safety-critical applications like healthcare or autonomous systems, prediction intervals must remain valid even when some participants are compromised. PRISM-FCP enables deployment of federated models with formal uncertainty guarantees despite Byzantine threats.

**Privacy-Preserving Collaboration**: The partial sharing mechanism provides an additional privacy benefit—clients reveal less information per round, making it harder for adversaries to reconstruct private data through gradient inversion attacks.

**Scalability Considerations**: The communication reduction from partial sharing becomes increasingly valuable as federated networks scale to thousands of clients. The $M/D$ ratio can be tuned based on network bandwidth constraints and threat models.

**Theoretical Foundations**: The work establishes that Byzantine resilience and communication efficiency are not necessarily competing objectives. The mathematical analysis showing that partial sharing reduces adversarial impact while maintaining convergence opens new directions for federated algorithm design.

## Takeaways

1. PRISM-FCP is the first federated conformal prediction framework to provide end-to-end Byzantine resilience, protecting both training and calibration phases
2. Partial parameter sharing (transmitting $M$ of $D$ parameters) mathematically attenuates adversarial perturbation energy by factor $M/D$ while reducing communication by $(D-M)/D$
3. Distance-based maliciousness scoring effectively identifies Byzantine clients during calibration by analyzing characterization vectors of nonconformity scores
4. The framework maintains nominal coverage guarantees (e.g., 90%) under Byzantine attacks while avoiding the interval inflation observed in standard FCP
5. Experimental results on UCI Superconductivity dataset demonstrate lower MSE, tighter prediction intervals, and 50% communication reduction compared to baselines
6. The approach provides a practical solution for deploying uncertainty-aware federated learning in adversarial environments with formal statistical guarantees
:::

:::zh
**论文**: [2602.18396](https://arxiv.org/abs/2602.18396)
**作者**: Ehsan Lari, Reza Arablouei, Stefan Werner
**分类**: cs.LG, eess.SP, math.PR, stat.AP, stat.ML

## 摘要

本文提出了PRISM-FCP,一种拜占庭容错的联邦保形预测框架,填补了现有方法的关键空白:模型训练期间对抗攻击的脆弱性。传统的联邦保形预测(FCP)方法仅关注保护校准阶段,而PRISM-FCP通过在训练期间实施部分模型共享和鲁棒校准机制提供端到端保护。该框架每轮通信仅传输$D$个参数中的$M$个,从数学上将对抗性扰动能量衰减$M/D$倍。在校准阶段,系统采用基于距离的恶意评分来识别和降权拜占庭贡献。在合成数据集和真实数据集上的实验验证表明,PRISM-FCP在攻击下保持名义覆盖保证,同时产生更紧密的预测区间并降低通信成本。

## 主要贡献

- **端到端拜占庭容错**:与仅保护校准的现有FCP方法不同,PRISM-FCP在训练和校准两个阶段都能缓解对抗攻击
- **部分共享机制**:引入通信高效的方法,客户端每轮仅传输$D$个参数中的$M$个,将对抗影响降低$M/D$倍
- **鲁棒校准协议**:开发基于距离的恶意评分系统,将非一致性分数转换为特征向量用于拜占庭检测
- **理论保证**:提供数学分析,表明部分共享下均方误差(MSE)降低且预测区间更紧密
- **实证验证**:在UCI超导数据集和合成数据上证明保持覆盖保证并减少区间膨胀

## 方法论与技术框架

PRISM-FCP通过两个不同阶段运行,每个阶段都融合了拜占庭容错机制。

**带部分共享的训练阶段**:在联邦学习过程中,每个客户端计算本地模型更新,但仅传输参数子集。具体而言,如果完整参数向量维度为$D$,客户端每轮随机选择并共享$M < D$个参数。这种部分共享策略具有深远的数学意义:它将聚合更新中任何对抗性扰动的期望能量衰减$M/D$倍。对于试图注入恶意梯度的拜占庭攻击者,这意味着他们的影响在聚合过程中被系统性地稀释。服务器使用鲁棒聚合方法汇总这些部分更新,进一步过滤异常值贡献。

**带鲁棒评分的校准阶段**:训练后,校准阶段构建具有统计覆盖保证的预测区间。每个客户端在其本地校准数据上计算非一致性分数——这些分数衡量每个预测的"异常"程度。PRISM-FCP将这些分数转换为捕获其统计特性的特征向量。然后框架通过测量每个客户端的特征向量与中位数行为的偏离程度来计算基于距离的恶意评分。在估计保形分位数之前,具有高恶意评分的客户端被降权或完全过滤。这确保最终预测区间反映诚实客户端行为,同时保持指定误覆盖率$\alpha$下$1-\alpha$的理论覆盖保证。

## 实验结果与性能分析

实验评估从多个维度展示了PRISM-FCP的有效性。

**攻击下的覆盖保持**:在包含30%拜占庭客户端的UCI超导数据集上,PRISM-FCP保持90%的名义覆盖率,而标准FCP显著退化。该框架在实现这一目标的同时避免了防御攻击时通常观察到的区间膨胀——预测区间保持紧密且信息丰富。

**通信效率**:通过仅传输$M/D$的参数(实验使用$M/D = 0.5$),PRISM-FCP相比完整参数共享减少50%的通信开销。这种减少对模型精度影响极小,因为部分共享机制仍然捕获足够的梯度信息以实现收敛。

**MSE降低**:在拜占庭攻击下,部分共享策略在学习模型中产生比完整共享更低的均方误差。这一反直觉的结果是因为部分共享充当隐式正则化器,防止对抗性扰动主导聚合更新。

**对攻击强度的鲁棒性**:实验将拜占庭客户端比例从10%变化到40%。PRISM-FCP在此范围内保持稳定性能,而基线方法显示渐进退化。基于距离的恶意评分在识别协同攻击方面特别有效,即多个拜占庭客户端试图偏置保形分位数估计。

## 对联邦学习和不确定性量化的影响

PRISM-FCP解决了联邦学习中的一个基本挑战:在对抗环境中提供可靠的不确定性量化。该框架的影响延伸到多个领域。

**可信AI部署**:在医疗保健或自主系统等安全关键应用中,即使某些参与者被攻陷,预测区间也必须保持有效。PRISM-FCP使联邦模型能够在拜占庭威胁下以形式化不确定性保证进行部署。

**隐私保护协作**:部分共享机制提供额外的隐私优势——客户端每轮透露更少信息,使对手更难通过梯度反演攻击重建私有数据。

**可扩展性考虑**:随着联邦网络扩展到数千个客户端,部分共享带来的通信减少变得越来越有价值。$M/D$比率可以根据网络带宽约束和威胁模型进行调整。

**理论基础**:该工作确立了拜占庭容错和通信效率不一定是竞争目标。数学分析表明部分共享在保持收敛的同时减少对抗影响,为联邦算法设计开辟了新方向。

## 要点总结

1. PRISM-FCP是首个提供端到端拜占庭容错的联邦保形预测框架,保护训练和校准两个阶段
2. 部分参数共享(传输$D$个参数中的$M$个)从数学上将对抗性扰动能量衰减$M/D$倍,同时减少$(D-M)/D$的通信量
3. 基于距离的恶意评分通过分析非一致性分数的特征向量有效识别校准期间的拜占庭客户端
4. 该框架在拜占庭攻击下保持名义覆盖保证(如90%),同时避免标准FCP中观察到的区间膨胀
5. UCI超导数据集上的实验结果表明,相比基线方法,MSE更低、预测区间更紧密且通信减少50%
6. 该方法为在对抗环境中部署具有形式化统计保证的不确定性感知联邦学习提供了实用解决方案
:::
