---
title:
  en: "Function-Space Decoupled Diffusion for Forward and Inverse Modeling in Carbon Capture and Storage"
  zh: "函数空间解耦扩散模型用于碳捕获与封存的正向和反向建模"
description:
  en: "A novel generative framework combining function-space diffusion models with neural operator surrogates to solve sparse-observation inverse problems in subsurface flow modeling, achieving 11x improvement over standard methods."
  zh: "一种结合函数空间扩散模型与神经算子代理的生成框架,用于解决地下流动建模中的稀疏观测反问题,性能较标准方法提升11倍。"
date: 2026-02-14
tags: ["arxiv", "ai", "cs.lg", "physics.geo-ph"]
image: "/arxiv-visuals/arxiv-function-space-decoupled-diffusion-for-forward.png"
---

:::en
**Paper**: [2602.12274](https://arxiv.org/abs/2602.12274)
**Authors**: Xin Ju, Jiachen Yao, Anima Anandkumar, Sally M. Benson, Gege Wen
**Categories**: cs.LG, physics.geo-ph

## Abstract

Carbon Capture and Storage (CCS) requires accurate characterization of subsurface flow dynamics, but faces fundamental challenges from sparse observational data and ill-posed inverse problems. This paper introduces Fun-DDPS (Function-space Decoupled Diffusion Posterior Sampling), a generative framework that decouples the learning of geological parameter distributions from physics-based dynamics modeling. The approach trains a diffusion model on geological parameters (geomodels) while using a Local Neural Operator (LNO) surrogate to provide differentiable physics guidance for cross-field conditioning. This architecture enables robust recovery of missing information in parameter space while maintaining physical consistency in the dynamics field through efficient gradient-based data assimilation.

## Key Contributions

- **Decoupled Architecture**: Separates prior learning in parameter space from physics-based guidance in dynamics space, enabling single-channel diffusion models to handle complex multi-field problems
- **Extreme Sparsity Handling**: Achieves 7.7% relative error with only 25% observations versus 86.9% for standard surrogates—an 11x improvement demonstrating capability where deterministic methods completely fail
- **Rigorous Validation Framework**: First work to validate diffusion-based inverse solvers against asymptotically exact Rejection Sampling posteriors, achieving Jensen-Shannon divergence < 0.06
- **Physical Consistency**: Produces artifact-free realizations while joint-state baselines suffer from high-frequency artifacts, with 4x better sample efficiency than rejection sampling

## Methodology: Function-Space Decoupling

The core innovation lies in architectural decoupling. Traditional joint-state approaches like DPS condition diffusion models on both geological parameters and flow dynamics simultaneously, requiring multi-channel models that struggle with cross-field dependencies. Fun-DDPS instead:

1. **Prior Learning**: Trains a single-channel diffusion model $p_\theta(x)$ exclusively on geological parameter fields $x$ (permeability, porosity), learning the natural distribution of subsurface structures
2. **Physics Surrogate**: Employs a pre-trained Local Neural Operator $\mathcal{G}_\phi: x \rightarrow y$ mapping parameters to dynamics (pressure, saturation fields)
3. **Guided Sampling**: During inference, uses the surrogate to compute gradients $\nabla_x \log p(y_{obs}|x)$ for data likelihood, guiding the diffusion process toward observations

The sampling process follows:

$$x_{t-1} = \frac{1}{\sqrt{\alpha_t}}\left(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t, t)\right) - \zeta\nabla_x\|\mathcal{G}_\phi(x_t) - y_{obs}\|^2 + \sigma_t z$$

where $\zeta$ controls guidance strength and $z \sim \mathcal{N}(0, I)$ maintains stochasticity.

## Results: Forward and Inverse Performance

**Forward Modeling Under Sparsity**: When reconstructing full dynamics fields from 25% sparse observations, Fun-DDPS demonstrates remarkable robustness. The relative $L_2$ error of 7.7% contrasts sharply with 86.9% for standard neural operator surrogates. This isn't incremental improvement—it's the difference between usable predictions and complete failure. The decoupled architecture allows the diffusion prior to "fill in" missing spatial information using learned geological structure, while the surrogate ensures physical plausibility.

**Inverse Problem Validation**: The paper provides unprecedented rigor in validating generative inverse solvers. By comparing against Rejection Sampling—which asymptotically recovers the true posterior but requires ~1000 forward simulations per sample—the authors establish ground truth. Both Fun-DDPS and Fun-DPS achieve JS divergence < 0.06, confirming they approximate the true posterior distribution. However, Fun-DDPS produces physically consistent samples without the high-frequency noise artifacts plaguing joint-state methods, while requiring only 250 function evaluations versus 1000 for rejection sampling.

**Computational Efficiency**: The Local Neural Operator surrogate enables gradient computation in milliseconds versus minutes for full physics simulators. This 1000x speedup makes iterative refinement practical, allowing Fun-DDPS to generate diverse posterior samples in reasonable time while maintaining physical fidelity through differentiable physics constraints.

## Implications for Subsurface Modeling

This work addresses a critical bottleneck in CCS deployment: uncertainty quantification under sparse monitoring. Traditional deterministic inversion methods produce single point estimates that ignore posterior uncertainty, while Monte Carlo methods are computationally prohibitive. Fun-DDPS offers a middle path—generating diverse, physically plausible scenarios that capture epistemic uncertainty while remaining computationally tractable.

The decoupling principle extends beyond CCS. Any inverse problem involving parameter-to-observation mappings through expensive physics simulators could benefit: seismic inversion, reservoir engineering, climate model calibration, or medical imaging. The key insight is that learning priors in natural parameter space (where data is abundant) and applying physics constraints through surrogates (where gradients are needed) is more effective than joint modeling.

The validation against rejection sampling sets a new standard for generative inverse modeling. Too often, diffusion-based methods are evaluated only on reconstruction metrics without verifying they actually sample from the posterior. This work demonstrates that with proper architecture and guidance, diffusion models can provably approximate Bayesian posteriors while being orders of magnitude more efficient than traditional sampling methods.

## Takeaways

1. Decoupling prior learning from physics guidance enables diffusion models to handle extreme data sparsity (75% missing observations) where deterministic methods fail completely
2. Function-space architectures with neural operator surrogates provide 11x improvement in reconstruction accuracy while maintaining 4x better sample efficiency than rejection sampling
3. First rigorous validation shows diffusion-based inverse solvers can provably approximate true Bayesian posteriors (JS divergence < 0.06) when properly designed
4. Physical consistency emerges naturally from the decoupled architecture—Fun-DDPS produces artifact-free realizations while joint-state methods suffer from high-frequency noise
5. The framework generalizes beyond CCS to any inverse problem with expensive physics simulators and sparse observations, offering a practical path to uncertainty quantification in scientific computing
:::

:::zh
**论文**: [2602.12274](https://arxiv.org/abs/2602.12274)
**作者**: Xin Ju, Jiachen Yao, Anima Anandkumar, Sally M. Benson, Gege Wen
**分类**: cs.LG, physics.geo-ph

## 摘要

碳捕获与封存(CCS)需要准确刻画地下流动动力学特征,但面临稀疏观测数据和病态反问题的根本性挑战。本文提出Fun-DDPS(函数空间解耦扩散后验采样),这是一个将地质参数分布学习与基于物理的动力学建模解耦的生成框架。该方法在地质参数(地质模型)上训练扩散模型,同时使用局部神经算子(LNO)代理为动力学场的跨场条件提供可微物理引导。这种架构能够在参数空间中鲁棒地恢复缺失信息,同时通过高效的基于梯度的数据同化在动力学场中保持物理一致性。

## 主要贡献

- **解耦架构**:将参数空间的先验学习与动力学空间的物理引导分离,使单通道扩散模型能够处理复杂的多场问题
- **极端稀疏性处理**:在仅有25%观测数据时达到7.7%相对误差,而标准代理为86.9%——11倍改进展示了在确定性方法完全失效时的能力
- **严格验证框架**:首次针对渐近精确的拒绝采样后验验证基于扩散的反问题求解器,达到Jensen-Shannon散度< 0.06
- **物理一致性**:生成无伪影的实现,而联合状态基线存在高频伪影,样本效率比拒绝采样提高4倍

## 方法论:函数空间解耦

核心创新在于架构解耦。传统的联合状态方法如DPS同时对地质参数和流动动力学进行扩散模型条件化,需要难以处理跨场依赖关系的多通道模型。Fun-DDPS则采用:

1. **先验学习**:仅在地质参数场$x$(渗透率、孔隙度)上训练单通道扩散模型$p_\theta(x)$,学习地下结构的自然分布
2. **物理代理**:采用预训练的局部神经算子$\mathcal{G}_\phi: x \rightarrow y$将参数映射到动力学(压力、饱和度场)
3. **引导采样**:推理时使用代理计算数据似然梯度$\nabla_x \log p(y_{obs}|x)$,引导扩散过程趋向观测数据

采样过程遵循:

$$x_{t-1} = \frac{1}{\sqrt{\alpha_t}}\left(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t, t)\right) - \zeta\nabla_x\|\mathcal{G}_\phi(x_t) - y_{obs}\|^2 + \sigma_t z$$

其中$\zeta$控制引导强度,$z \sim \mathcal{N}(0, I)$保持随机性。

## 结果:正向和反向性能

**稀疏条件下的正向建模**:从25%稀疏观测重建完整动力学场时,Fun-DDPS展现出显著的鲁棒性。7.7%的相对$L_2$误差与标准神经算子代理的86.9%形成鲜明对比。这不是渐进式改进——而是可用预测与完全失效之间的差异。解耦架构允许扩散先验利用学习到的地质结构"填充"缺失的空间信息,同时代理确保物理合理性。

**反问题验证**:论文为生成式反问题求解器提供了前所未有的严格验证。通过与拒绝采样对比——该方法渐近恢复真实后验但每个样本需要约1000次正向模拟——作者建立了真值基准。Fun-DDPS和Fun-DPS均达到JS散度< 0.06,确认它们近似真实后验分布。然而,Fun-DDPS生成物理一致的样本而无联合状态方法的高频噪声伪影,且仅需250次函数评估而非拒绝采样的1000次。

**计算效率**:局部神经算子代理使梯度计算从完整物理模拟器的分钟级降至毫秒级。这种1000倍加速使迭代优化变得实用,允许Fun-DDPS在合理时间内生成多样化的后验样本,同时通过可微物理约束保持物理保真度。

## 对地下建模的意义

这项工作解决了CCS部署中的关键瓶颈:稀疏监测下的不确定性量化。传统确定性反演方法产生忽略后验不确定性的单点估计,而蒙特卡洛方法计算成本过高。Fun-DDPS提供了中间路径——生成捕获认知不确定性的多样化、物理合理场景,同时保持计算可行性。

解耦原理超越了CCS应用。任何涉及通过昂贵物理模拟器进行参数到观测映射的反问题都可受益:地震反演、油藏工程、气候模型校准或医学成像。关键洞察是在自然参数空间(数据丰富)学习先验并通过代理(需要梯度)应用物理约束比联合建模更有效。

针对拒绝采样的验证为生成式反向建模设立了新标准。基于扩散的方法往往仅通过重建指标评估而不验证是否真正从后验采样。这项工作证明,通过适当的架构和引导,扩散模型可以可证明地近似贝叶斯后验,同时比传统采样方法高效几个数量级。

## 要点总结

1. 将先验学习与物理引导解耦使扩散模型能够处理极端数据稀疏性(75%缺失观测),而确定性方法完全失效
2. 函数空间架构配合神经算子代理在重建精度上提供11倍改进,同时样本效率比拒绝采样提高4倍
3. 首次严格验证表明,适当设计的基于扩散的反问题求解器可以可证明地近似真实贝叶斯后验(JS散度< 0.06)
4. 物理一致性自然地从解耦架构中涌现——Fun-DDPS生成无伪影实现,而联合状态方法存在高频噪声
5. 该框架推广到CCS之外的任何具有昂贵物理模拟器和稀疏观测的反问题,为科学计算中的不确定性量化提供实用路径
:::
