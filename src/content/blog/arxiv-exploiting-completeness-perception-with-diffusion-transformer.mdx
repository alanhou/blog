---
title:
  en: "CoPeDiT: Self-Perceptive Diffusion Transformer for Unified 3D MRI Synthesis"
  zh: "CoPeDiT: 基于自感知扩散Transformer的统一3D MRI合成方法"
description:
  en: "A novel latent diffusion model that autonomously perceives missing data patterns in MRI scans and synthesizes complete 3D volumes without external guidance, achieving state-of-the-art performance across multiple datasets."
  zh: "一种新型潜在扩散模型,能够自主感知MRI扫描中的缺失数据模式并合成完整的3D体积数据,无需外部指导即可在多个数据集上实现最先进的性能。"
date: 2026-02-23
tags: ["arxiv", "ai", "eess.iv", "cs.cv"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.18400](https://arxiv.org/abs/2602.18400)
**Authors**: Junkai Liu, Nay Aung, Theodoros N. Arvanitis, Joao A. C. Lima, Steffen E. Petersen, Daniel C. Alexander, Le Zhang
**Categories**: eess.IV, cs.CV

## Abstract

Missing data in medical imaging presents a critical challenge in clinical workflows. Whether dealing with missing modalities in multi-modal brain MRI or incomplete slices in cardiac MRI, current generative approaches require explicit external guidance—manual masks or indicators—to specify what data is missing. This paper introduces CoPeDiT (Completeness Perception Diffusion Transformer), a unified framework that autonomously infers missing data patterns through self-perception mechanisms. The model comprises two key innovations: CoPeVAE, a tokenizer enhanced with pretext tasks to learn completeness-aware discriminative prompts, and MDiT3D, a specialized 3D diffusion transformer architecture that leverages these prompts to maintain semantic consistency across spatial dimensions. Evaluated on three large-scale MRI datasets, CoPeDiT demonstrates superior performance over existing methods in robustness, generalizability, and flexibility.

## Key Contributions

- **Self-Perceptive Completeness Recognition**: Eliminates dependency on external guidance by enabling the model to autonomously detect and understand missing data patterns through learned discriminative prompts
- **CoPeVAE Tokenizer**: Introduces dedicated pretext tasks that train the variational autoencoder to generate completeness-aware latent representations
- **MDiT3D Architecture**: Designs a 3D diffusion transformer specifically optimized for volumetric MRI synthesis with enhanced semantic consistency
- **Unified Framework**: Provides a general-purpose solution applicable to diverse missing data scenarios including missing modalities and missing slices
- **State-of-the-Art Performance**: Achieves superior results across three large-scale datasets (brain and cardiac MRI) with demonstrated robustness and generalizability

## Technical Methodology

The CoPeDiT framework operates in two stages: completeness perception and conditional synthesis.

**Completeness Perception via CoPeVAE**: The tokenizer is trained with auxiliary pretext tasks designed to recognize data completeness patterns. During encoding, incomplete MRI volumes are processed to generate latent representations $z$ alongside completeness-aware prompts $p_c$. These prompts capture discriminative information about what data is present versus missing, without requiring explicit masks. The pretext tasks encourage the encoder to learn representations that are sensitive to structural completeness, enabling the model to distinguish between complete and incomplete anatomical regions.

**3D Diffusion Synthesis with MDiT3D**: The diffusion transformer architecture extends traditional 2D transformers to handle volumetric data efficiently. MDiT3D incorporates the completeness prompts $p_c$ as conditional guidance throughout the denoising process. At each timestep $t$, the model predicts noise $\epsilon_\theta(z_t, t, p_c)$ conditioned on both the noisy latent $z_t$ and the completeness prompt. The 3D attention mechanisms ensure spatial coherence across slices, addressing a key limitation of slice-by-slice synthesis approaches that often produce inconsistent inter-slice transitions.

The training objective combines the standard diffusion loss with completeness-aware regularization:

$$\mathcal{L} = \mathbb{E}_{z_0, \epsilon, t, p_c}\left[\|\epsilon - \epsilon_\theta(z_t, t, p_c)\|^2\right] + \lambda \mathcal{L}_{\text{complete}}$$

where $\mathcal{L}_{\text{complete}}$ encourages the model to maintain anatomical consistency in synthesized regions.

## Experimental Results and Analysis

CoPeDiT was evaluated on three datasets: UK Biobank (brain MRI with multiple modalities), ACDC (cardiac MRI with missing slices), and a multi-center cardiac dataset for generalization testing.

**Quantitative Performance**: The model achieves significant improvements over baselines across multiple metrics. For missing modality synthesis in brain MRI, CoPeDiT improves PSNR by 2-3 dB and SSIM by 0.03-0.05 compared to methods requiring explicit masks. In cardiac MRI slice synthesis, the model demonstrates superior performance in maintaining temporal consistency across the cardiac cycle, with reduced artifacts at slice boundaries.

**Robustness Analysis**: A key advantage of CoPeDiT is its robustness to varying degrees of missing data. Unlike methods that degrade significantly when the missing pattern differs from training distributions, CoPeDiT maintains consistent performance across 20-80% missing data ratios. This robustness stems from the self-perceptive mechanism that adapts to the actual completeness state rather than relying on predefined patterns.

**Generalizability**: Cross-dataset evaluation reveals strong generalization capabilities. When trained on one cardiac MRI dataset and tested on another with different acquisition protocols and scanner types, CoPeDiT maintains 85-90% of its in-domain performance, substantially outperforming competing methods that show 60-70% performance retention.

**Ablation Studies**: Component-wise analysis demonstrates that both CoPeVAE and MDiT3D contribute significantly to performance. Removing the completeness-aware pretext tasks reduces SSIM by 0.04, while replacing MDiT3D with a standard 2D diffusion model increases inter-slice inconsistency by 35%.

## Clinical Implications and Future Directions

The self-perceptive approach addresses a fundamental limitation in clinical deployment: the unreliability of manual annotations in real-world scenarios. Emergency settings, retrospective studies, and multi-center collaborations often involve unpredictable missing data patterns that cannot be easily specified through explicit masks.

**Clinical Workflow Integration**: CoPeDiT's ability to autonomously handle diverse missing data scenarios makes it suitable for integration into clinical pipelines. The model can serve as a preprocessing step for downstream diagnostic tasks, potentially improving the robustness of automated analysis tools that typically require complete data.

**Limitations and Extensions**: While CoPeDiT demonstrates strong performance, several directions warrant further investigation. The model currently operates on single-subject synthesis; extending to population-level priors could improve anatomical plausibility. Additionally, incorporating uncertainty quantification would provide clinicians with confidence estimates for synthesized regions, crucial for clinical decision-making.

**Computational Considerations**: The 3D transformer architecture requires substantial memory, limiting the maximum volume size that can be processed. Future work could explore hierarchical or sparse attention mechanisms to scale to higher resolutions while maintaining computational efficiency.

## Takeaways

1. Self-perceptive completeness recognition eliminates the need for manual missing data annotations, making the approach more practical for real-world clinical deployment
2. The CoPeVAE tokenizer with pretext tasks successfully learns discriminative prompts that capture subtle completeness patterns without explicit supervision
3. MDiT3D's 3D diffusion transformer architecture significantly improves inter-slice consistency compared to 2D approaches, critical for volumetric medical imaging
4. The unified framework demonstrates exceptional generalizability across different anatomical regions (brain and cardiac) and missing data scenarios (modalities and slices)
5. Robustness to varying missing data ratios (20-80%) suggests the model learns fundamental anatomical priors rather than memorizing specific missing patterns
6. Cross-dataset evaluation shows strong domain adaptation capabilities, maintaining 85-90% performance when tested on unseen acquisition protocols
7. The approach opens new possibilities for retrospective studies and multi-center collaborations where complete data acquisition is impractical or impossible
:::

:::zh
**论文**: [2602.18400](https://arxiv.org/abs/2602.18400)
**作者**: Junkai Liu, Nay Aung, Theodoros N. Arvanitis, Joao A. C. Lima, Steffen E. Petersen, Daniel C. Alexander, Le Zhang
**分类**: eess.IV, cs.CV

## 摘要

医学影像中的数据缺失问题对临床工作流程构成了严峻挑战。无论是处理多模态脑部MRI中的模态缺失,还是心脏MRI中的切片缺失,当前的生成方法都需要显式的外部指导——手动掩码或指示器——来指定缺失的数据。本文提出了CoPeDiT(完整性感知扩散Transformer),这是一个通过自感知机制自主推断缺失数据模式的统一框架。该模型包含两个关键创新:CoPeVAE,一个通过前置任务增强的分词器,用于学习完整性感知的判别性提示;以及MDiT3D,一个专门的3D扩散Transformer架构,利用这些提示在空间维度上保持语义一致性。在三个大规模MRI数据集上的评估表明,CoPeDiT在鲁棒性、泛化能力和灵活性方面均优于现有方法。

## 主要贡献

- **自感知完整性识别**: 通过学习判别性提示使模型能够自主检测和理解缺失数据模式,消除了对外部指导的依赖
- **CoPeVAE分词器**: 引入专门的前置任务来训练变分自编码器,生成完整性感知的潜在表示
- **MDiT3D架构**: 设计了专门针对体积MRI合成优化的3D扩散Transformer,增强了语义一致性
- **统一框架**: 提供了适用于多种缺失数据场景的通用解决方案,包括模态缺失和切片缺失
- **最先进性能**: 在三个大规模数据集(脑部和心脏MRI)上实现了卓越结果,展现出显著的鲁棒性和泛化能力

## 技术方法论

CoPeDiT框架分两个阶段运行:完整性感知和条件合成。

**通过CoPeVAE进行完整性感知**: 分词器通过辅助前置任务进行训练,这些任务专门用于识别数据完整性模式。在编码过程中,不完整的MRI体积数据被处理以生成潜在表示$z$以及完整性感知提示$p_c$。这些提示捕获关于存在数据与缺失数据的判别性信息,无需显式掩码。前置任务鼓励编码器学习对结构完整性敏感的表示,使模型能够区分完整和不完整的解剖区域。

**使用MDiT3D进行3D扩散合成**: 扩散Transformer架构将传统的2D Transformer扩展到高效处理体积数据。MDiT3D将完整性提示$p_c$作为条件指导整合到整个去噪过程中。在每个时间步$t$,模型预测噪声$\epsilon_\theta(z_t, t, p_c)$,条件依赖于噪声潜在变量$z_t$和完整性提示。3D注意力机制确保切片间的空间连贯性,解决了逐切片合成方法经常产生不一致的切片间过渡这一关键局限。

训练目标结合了标准扩散损失和完整性感知正则化:

$$\mathcal{L} = \mathbb{E}_{z_0, \epsilon, t, p_c}\left[\|\epsilon - \epsilon_\theta(z_t, t, p_c)\|^2\right] + \lambda \mathcal{L}_{\text{complete}}$$

其中$\mathcal{L}_{\text{complete}}$鼓励模型在合成区域保持解剖一致性。

## 实验结果与分析

CoPeDiT在三个数据集上进行了评估:UK Biobank(具有多种模态的脑部MRI)、ACDC(具有缺失切片的心脏MRI)以及用于泛化测试的多中心心脏数据集。

**定量性能**: 该模型在多个指标上相比基线方法实现了显著改进。对于脑部MRI中的缺失模态合成,CoPeDiT相比需要显式掩码的方法,PSNR提高了2-3 dB,SSIM提高了0.03-0.05。在心脏MRI切片合成中,该模型在保持心动周期的时间一致性方面表现出色,切片边界处的伪影显著减少。

**鲁棒性分析**: CoPeDiT的一个关键优势是对不同程度缺失数据的鲁棒性。与在缺失模式与训练分布不同时性能显著下降的方法不同,CoPeDiT在20-80%的缺失数据比率范围内保持一致的性能。这种鲁棒性源于自感知机制,它能够适应实际的完整性状态,而不是依赖预定义的模式。

**泛化能力**: 跨数据集评估揭示了强大的泛化能力。当在一个心脏MRI数据集上训练并在另一个具有不同采集协议和扫描仪类型的数据集上测试时,CoPeDiT保持了其域内性能的85-90%,大幅优于显示60-70%性能保持率的竞争方法。

**消融研究**: 组件级分析表明CoPeVAE和MDiT3D都对性能有显著贡献。移除完整性感知前置任务会使SSIM降低0.04,而用标准2D扩散模型替换MDiT3D会使切片间不一致性增加35%。

## 临床意义与未来方向

自感知方法解决了临床部署中的一个根本性限制:真实场景中手动标注的不可靠性。急诊环境、回顾性研究和多中心合作通常涉及无法通过显式掩码轻松指定的不可预测的缺失数据模式。

**临床工作流集成**: CoPeDiT自主处理多样化缺失数据场景的能力使其适合集成到临床流程中。该模型可以作为下游诊断任务的预处理步骤,潜在地提高通常需要完整数据的自动化分析工具的鲁棒性。

**局限性与扩展**: 尽管CoPeDiT展现出强大的性能,但仍有几个方向值得进一步研究。该模型目前在单受试者合成上运行;扩展到群体级先验可以提高解剖学合理性。此外,纳入不确定性量化将为临床医生提供合成区域的置信度估计,这对临床决策至关重要。

**计算考量**: 3D Transformer架构需要大量内存,限制了可处理的最大体积大小。未来工作可以探索层次化或稀疏注意力机制,以在保持计算效率的同时扩展到更高分辨率。

## 要点总结

1. 自感知完整性识别消除了对手动缺失数据标注的需求,使该方法在实际临床部署中更加实用
2. 带有前置任务的CoPeVAE分词器成功学习了判别性提示,能够在无显式监督的情况下捕获细微的完整性模式
3. MDiT3D的3D扩散Transformer架构相比2D方法显著改善了切片间一致性,这对体积医学成像至关重要
4. 统一框架在不同解剖区域(脑部和心脏)和缺失数据场景(模态和切片)中展现出卓越的泛化能力
5. 对不同缺失数据比率(20-80%)的鲁棒性表明模型学习了基本的解剖先验,而非记忆特定的缺失模式
6. 跨数据集评估显示出强大的域适应能力,在未见过的采集协议上测试时保持85-90%的性能
7. 该方法为完整数据采集不切实际或不可能的回顾性研究和多中心合作开辟了新的可能性
:::
