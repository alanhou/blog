---
title:
  en: "On Data Engineering for Scaling LLM Terminal Capabilities"
  zh: "大语言模型终端能力扩展的数据工程研究"
description:
  en: "NVIDIA researchers introduce Terminal-Task-Gen, a synthetic data pipeline that dramatically improves LLM terminal agent performance, achieving up to 8x improvement on Terminal-Bench 2.0."
  zh: "NVIDIA研究团队提出Terminal-Task-Gen合成数据生成管线,显著提升大语言模型终端代理性能,在Terminal-Bench 2.0上实现最高8倍的性能提升。"
date: 2026-02-25
tags: ["arxiv", "ai", "cs.cl"]
image: "/arxiv-visuals/on-data-engineering-for-scaling-llm/HeroScene.png"
---

![Concept animation](/arxiv-visuals/on-data-engineering-for-scaling-llm/ConceptScene.gif)



![Hero diagram](/arxiv-visuals/on-data-engineering-for-scaling-llm/HeroScene.png)



:::en
**Paper**: [2602.21193](https://arxiv.org/abs/2602.21193)
**Authors**: Renjie Pi, Grace Lam, Mohammad Shoeybi, Pooya Jannaty, Bryan Catanzaro, Wei Ping
**Categories**: cs.CL

## Abstract

This paper addresses a critical gap in LLM terminal agent development: the lack of transparency around training data strategies. While recent models have shown impressive terminal capabilities, the data engineering practices behind them remain largely proprietary. The authors present a systematic study introducing Terminal-Task-Gen, a lightweight synthetic task generation pipeline, and Terminal-Corpus, a large-scale open-source dataset. Their Nemotron-Terminal model family, built on Qwen3 (8B, 14B, 32B), demonstrates remarkable improvements on Terminal-Bench 2.0, with the 8B model jumping from 2.5% to 13.0%, the 14B from 4.0% to 20.2%, and the 32B from 3.4% to 27.4% success rates, matching significantly larger proprietary models.

## Key Contributions

- **Terminal-Task-Gen Pipeline**: A flexible synthetic task generation system supporting both seed-based task expansion and skill-based task construction, enabling scalable creation of diverse terminal tasks
- **Terminal-Corpus Dataset**: A large-scale, open-source dataset specifically designed for training terminal agents, addressing the data scarcity problem in this domain
- **Comprehensive Training Strategy Analysis**: Systematic evaluation of data filtering, curriculum learning, long context training, and scaling behavior for terminal agents
- **Nemotron-Terminal Model Family**: Open-source models (8B, 14B, 32B parameters) achieving state-of-the-art performance on Terminal-Bench 2.0, demonstrating 5-8x improvement over base models

## Methodology and Data Engineering

The Terminal-Task-Gen pipeline operates through two complementary approaches. The seed-based method takes existing terminal tasks and generates variations by modifying parameters, contexts, and constraints while preserving the core command structure. The skill-based approach constructs tasks from scratch by combining atomic terminal skills (file operations, process management, network utilities) into complex multi-step scenarios.

The data engineering process emphasizes quality over quantity through aggressive filtering. The authors implement multiple validation layers: syntax checking for command correctness, execution verification in sandboxed environments, and difficulty calibration to ensure appropriate task complexity. This filtering reduces the raw synthetic data by approximately 40% but significantly improves training efficiency.

Curriculum learning plays a crucial role in the training strategy. Tasks are organized by complexity metrics including command depth, number of steps, and prerequisite knowledge. Models are first trained on simpler single-command tasks, then progressively exposed to multi-step workflows and complex system administration scenarios. This staged approach prevents the model from being overwhelmed by difficult examples early in training.

## Results and Performance Analysis

The performance gains are substantial across all model sizes. Nemotron-Terminal-8B achieves 13.0% on Terminal-Bench 2.0, a 5.2x improvement over the base Qwen3-8B (2.5%). The 14B variant reaches 20.2% (5.05x improvement from 4.0%), while the 32B model hits 27.4% (8.06x improvement from 3.4%). These results are particularly impressive given that the 32B model matches or exceeds the performance of proprietary models with significantly more parameters.

The scaling behavior reveals interesting patterns. While larger models generally perform better, the improvement is not strictly linear with parameter count. The jump from 8B to 14B shows a 55% relative improvement, while 14B to 32B shows a 36% relative improvement, suggesting diminishing returns at larger scales. However, all model sizes benefit substantially from the synthetic training data, indicating that data quality matters more than raw model capacity for terminal tasks.

Long context training proves essential for complex multi-step terminal workflows. The authors extend the context window during training to handle tasks requiring multiple command executions and state tracking across extended sessions. Models trained with longer contexts show 15-20% better performance on tasks requiring more than 5 sequential commands compared to models trained on shorter contexts.

## Implications for AI Agent Development

This work has significant implications for the broader AI agent ecosystem. First, it demonstrates that synthetic data generation, when done carefully with proper validation, can effectively substitute for expensive human-annotated data in specialized domains. The Terminal-Task-Gen pipeline is lightweight enough to run on modest computational resources, making it accessible to researchers beyond large institutions.

Second, the open-sourcing of both the dataset and model checkpoints lowers the barrier to entry for terminal agent research. Previously, researchers needed either access to proprietary datasets or significant resources to collect and annotate terminal interaction data. Terminal-Corpus provides a strong foundation that can be extended or adapted for specific use cases.

Third, the systematic analysis of training strategies provides actionable insights for practitioners. The finding that curriculum learning and aggressive filtering outperform naive scaling of synthetic data challenges the "more data is always better" assumption. This suggests that thoughtful data engineering can be more impactful than simply increasing dataset size.

The results also highlight the importance of domain-specific benchmarks. Terminal-Bench 2.0 provides a rigorous evaluation framework that exposes weaknesses in general-purpose LLMs when applied to terminal tasks. The dramatic improvements shown by Nemotron-Terminal models underscore the value of specialized training for specific agent capabilities.

## Takeaways

1. Synthetic data generation with proper validation can effectively train high-performance terminal agents, achieving 5-8x improvements over base models
2. Data quality through aggressive filtering and curriculum learning outperforms naive scaling of synthetic data volume
3. The 32B Nemotron-Terminal model matches proprietary models with significantly more parameters, demonstrating efficient scaling
4. Long context training is essential for multi-step terminal workflows, improving performance by 15-20% on complex tasks
5. Open-sourcing training data and models accelerates research progress and democratizes access to terminal agent capabilities
:::

:::zh
**论文**: [2602.21193](https://arxiv.org/abs/2602.21193)
**作者**: Renjie Pi, Grace Lam, Mohammad Shoeybi, Pooya Jannaty, Bryan Catanzaro, Wei Ping
**分类**: cs.CL

## 摘要

本文针对大语言模型终端代理开发中的关键空白展开研究:训练数据策略的透明度不足。尽管近期模型展现出令人印象深刻的终端能力,但背后的数据工程实践大多处于保密状态。作者进行了系统性研究,提出了Terminal-Task-Gen轻量级合成任务生成管线和Terminal-Corpus大规模开源数据集。基于Qwen3(8B、14B、32B)构建的Nemotron-Terminal模型家族在Terminal-Bench 2.0上取得显著提升:8B模型从2.5%提升至13.0%,14B模型从4.0%提升至20.2%,32B模型从3.4%提升至27.4%,达到了参数规模更大的专有模型的性能水平。

## 主要贡献

- **Terminal-Task-Gen管线**: 灵活的合成任务生成系统,支持基于种子的任务扩展和基于技能的任务构建,实现多样化终端任务的可扩展创建
- **Terminal-Corpus数据集**: 专门为训练终端代理设计的大规模开源数据集,解决该领域的数据稀缺问题
- **全面的训练策略分析**: 系统评估数据过滤、课程学习、长上下文训练和终端代理的扩展行为
- **Nemotron-Terminal模型家族**: 开源模型(8B、14B、32B参数)在Terminal-Bench 2.0上达到最先进性能,相比基础模型实现5-8倍提升

## 方法论与数据工程

Terminal-Task-Gen管线通过两种互补方法运作。基于种子的方法从现有终端任务出发,通过修改参数、上下文和约束条件生成变体,同时保留核心命令结构。基于技能的方法从零开始构建任务,将原子级终端技能(文件操作、进程管理、网络工具)组合成复杂的多步骤场景。

数据工程过程强调质量优于数量,采用激进的过滤策略。作者实施多层验证机制:命令正确性的语法检查、沙箱环境中的执行验证,以及难度校准以确保适当的任务复杂度。这种过滤将原始合成数据减少约40%,但显著提高了训练效率。

课程学习在训练策略中发挥关键作用。任务按复杂度指标组织,包括命令深度、步骤数量和前置知识要求。模型首先在简单的单命令任务上训练,然后逐步接触多步骤工作流和复杂的系统管理场景。这种分阶段方法防止模型在训练早期被困难样本压垮。

## 结果与性能分析

所有模型规模的性能提升都很显著。Nemotron-Terminal-8B在Terminal-Bench 2.0上达到13.0%,相比基础Qwen3-8B(2.5%)提升5.2倍。14B变体达到20.2%(从4.0%提升5.05倍),而32B模型达到27.4%(从3.4%提升8.06倍)。考虑到32B模型匹配或超越了参数规模显著更大的专有模型,这些结果尤为令人印象深刻。

扩展行为揭示了有趣的模式。虽然更大的模型通常表现更好,但改进与参数数量并非严格线性关系。从8B到14B的跃升显示55%的相对改进,而14B到32B显示36%的相对改进,表明在更大规模上存在收益递减。然而,所有模型规模都从合成训练数据中获得实质性收益,表明对于终端任务而言,数据质量比原始模型容量更重要。

长上下文训练对复杂的多步骤终端工作流至关重要。作者在训练期间扩展上下文窗口,以处理需要多次命令执行和跨扩展会话状态跟踪的任务。使用更长上下文训练的模型在需要超过5个连续命令的任务上,相比使用较短上下文训练的模型表现出15-20%的性能提升。

## 对AI代理开发的影响

这项工作对更广泛的AI代理生态系统具有重要意义。首先,它证明了合成数据生成在经过适当验证的情况下,可以有效替代专业领域中昂贵的人工标注数据。Terminal-Task-Gen管线足够轻量,可以在适度的计算资源上运行,使大型机构之外的研究人员也能使用。

其次,数据集和模型检查点的开源降低了终端代理研究的准入门槛。以前,研究人员需要访问专有数据集或投入大量资源来收集和标注终端交互数据。Terminal-Corpus提供了可以针对特定用例扩展或调整的坚实基础。

第三,训练策略的系统分析为实践者提供了可操作的见解。课程学习和激进过滤优于合成数据的简单扩展这一发现,挑战了"更多数据总是更好"的假设。这表明深思熟虑的数据工程比简单增加数据集规模更有影响力。

结果还突出了领域特定基准的重要性。Terminal-Bench 2.0提供了严格的评估框架,暴露了通用大语言模型应用于终端任务时的弱点。Nemotron-Terminal模型展示的显著改进强调了针对特定代理能力进行专门训练的价值。

## 要点总结

1. 经过适当验证的合成数据生成可以有效训练高性能终端代理,相比基础模型实现5-8倍提升
2. 通过激进过滤和课程学习实现的数据质量优于合成数据量的简单扩展
3. 32B Nemotron-Terminal模型匹配参数规模显著更大的专有模型,展示了高效扩展能力
4. 长上下文训练对多步骤终端工作流至关重要,在复杂任务上提升15-20%的性能
5. 开源训练数据和模型加速研究进展,使终端代理能力的获取更加民主化
:::
