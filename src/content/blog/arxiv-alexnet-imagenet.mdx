---
title:
  en: "AlexNet: ImageNet Classification with Deep Convolutional Neural Networks"
  zh: "AlexNet：使用深度卷积神经网络进行ImageNet分类"
description:
  en: "The landmark 2012 paper that sparked the deep learning revolution using ReLU, Dropout, and data augmentation"
  zh: "2012年里程碑式论文，使用ReLU、Dropout和数据增强技术开启深度学习革命"
date: 2012-12-03
tags: ["arxiv", "cnn", "imagenet", "deep-learning", "computer-vision", "relu", "landmark-paper"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::zh
## 论文信息

- **标题**: ImageNet Classification with Deep Convolutional Neural Networks
- **作者**: Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton
- **机构**: University of Toronto
- **发表时间**: 2012 (NeurIPS)
- **论文链接**: [PDF](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

## 核心贡献

AlexNet 是深度学习革命的标志性工作。它在 2012 年 ImageNet 竞赛中以巨大优势获胜，将 top-5 错误率从 26% 降低到 15.3%，震惊了整个计算机视觉领域。

### 主要创新

1. **ReLU 激活函数**: 首次大规模使用 ReLU，解决梯度消失问题
2. **GPU 训练**: 使用两块 GTX 580 GPU 并行训练
3. **Dropout 正则化**: 防止过拟合的有效技术
4. **数据增强**: 图像翻转、裁剪、颜色变换
5. **局部响应归一化 (LRN)**: 增强泛化能力

## 网络架构

```
输入: 224×224×3 图像

Conv1: 96 filters, 11×11, stride 4 → ReLU → LRN → MaxPool
Conv2: 256 filters, 5×5 → ReLU → LRN → MaxPool
Conv3: 384 filters, 3×3 → ReLU
Conv4: 384 filters, 3×3 → ReLU
Conv5: 256 filters, 3×3 → ReLU → MaxPool
FC6: 4096 → ReLU → Dropout
FC7: 4096 → ReLU → Dropout
FC8: 1000 (softmax)

总参数: ~60M
```

## 关键技术

### ReLU 激活函数

```python
def relu(x):
    return max(0, x)
```

相比 sigmoid/tanh：
- 计算更快
- 缓解梯度消失
- 稀疏激活

### Dropout

训练时随机将神经元输出置零（概率 0.5），测试时使用全部神经元但输出减半。

### 数据增强

- 随机裁剪 224×224 区域
- 水平翻转
- PCA 颜色增强

## 实验结果

| 方法 | Top-1 错误率 | Top-5 错误率 |
|------|-------------|-------------|
| 传统方法 | 45.7% | 25.7% |
| AlexNet (1 CNN) | 40.7% | 18.2% |
| AlexNet (5 CNNs) | 38.1% | 16.4% |
| AlexNet (7 CNNs) | **36.7%** | **15.3%** |

## 历史影响

AlexNet 的成功标志着：

1. **深度学习复兴**: 证明了深度神经网络的强大能力
2. **GPU 计算时代**: 开启了 GPU 训练深度学习的先河
3. **计算机视觉革命**: 彻底改变了图像识别的方法论
4. **产业变革**: 推动了 AI 在工业界的广泛应用

## 总结

AlexNet 是深度学习历史上最重要的里程碑之一，它证明了深度卷积网络在大规模图像识别任务上的巨大潜力，开启了现代深度学习时代。
:::

:::en
## Paper Information

- **Title**: ImageNet Classification with Deep Convolutional Neural Networks
- **Authors**: Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton
- **Institution**: University of Toronto
- **Published**: 2012 (NeurIPS)
- **Paper Link**: [PDF](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

## Core Contributions

AlexNet is the landmark work of the deep learning revolution. It won the 2012 ImageNet competition by a huge margin, reducing the top-5 error rate from 26% to 15.3%, shocking the entire computer vision community.

### Key Innovations

1. **ReLU Activation**: First large-scale use of ReLU, solving vanishing gradient problem
2. **GPU Training**: Parallel training using two GTX 580 GPUs
3. **Dropout Regularization**: Effective technique to prevent overfitting
4. **Data Augmentation**: Image flipping, cropping, color transformations
5. **Local Response Normalization (LRN)**: Enhanced generalization

## Network Architecture

The network consists of 5 convolutional layers followed by 3 fully connected layers, with approximately 60 million parameters.

## Key Techniques

### ReLU Activation

Compared to sigmoid/tanh:
- Faster computation
- Mitigates vanishing gradients
- Sparse activation

### Dropout

Randomly zeros neuron outputs during training (probability 0.5), uses all neurons at test time with halved outputs.

### Data Augmentation

- Random 224×224 crops
- Horizontal flipping
- PCA color augmentation

## Historical Impact

AlexNet's success marked:

1. **Deep Learning Renaissance**: Proved the power of deep neural networks
2. **GPU Computing Era**: Pioneered GPU training for deep learning
3. **Computer Vision Revolution**: Completely changed image recognition methodology
4. **Industry Transformation**: Drove widespread AI adoption in industry

## Summary

AlexNet is one of the most important milestones in deep learning history, proving the enormous potential of deep convolutional networks for large-scale image recognition and ushering in the modern deep learning era.
:::
