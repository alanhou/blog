---
title:
  en: "The Geometry of Noise: Why Diffusion Models Don't Need Noise Conditioning"
  zh: "噪声的几何学:扩散模型为何不需要噪声条件"
description:
  en: "This paper resolves a fundamental paradox in autonomous diffusion models by formalizing Marginal Energy and proving that noise-agnostic generation is a Riemannian gradient flow with implicit geometric stabilization."
  zh: "本文通过形式化边缘能量,解决了自主扩散模型中的基本悖论,证明了无噪声感知生成是一种具有隐式几何稳定化的黎曼梯度流。"
date: 2026-02-23
tags: ["arxiv", "ai", "cs.lg", "cs.cv", "eess.iv"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.18428](https://arxiv.org/abs/2602.18428)
**Authors**: Mojtaba Sahraee-Ardakan, Mauricio Delbracio, Peyman Milanfar
**Categories**: cs.LG, cs.CV, eess.IV

## Abstract

Autonomous generative models like Equilibrium Matching and blind diffusion learn a single time-invariant vector field without explicit noise-level conditioning, challenging conventional diffusion paradigms. This paper resolves a fundamental paradox: how can noise-agnostic networks remain stable near data manifolds where gradients typically diverge? The authors formalize Marginal Energy $E_{\text{marg}}(\mathbf{u}) = -\log p(\mathbf{u})$, where $p(\mathbf{u}) = \int p(\mathbf{u}|t)p(t)dt$ integrates over unknown noise levels. They prove autonomous generation is Riemannian gradient flow on this landscape, where learned fields implicitly incorporate conformal metrics that counteract $1/t^p$ singularities, converting infinite potential wells into stable attractors. The work identifies a "Jensen Gap" causing catastrophic failures in noise-prediction parameterizations while proving velocity-based approaches are inherently stable.

## Key Contributions

- Formalization of Marginal Energy as the optimization landscape for autonomous diffusion models, integrating over noise-level uncertainty
- Proof that autonomous generation implements Riemannian gradient flow with implicit conformal metric correction
- Novel relative energy decomposition revealing how time-invariant fields stabilize geometric singularities near data manifolds
- Identification of the "Jensen Gap" phenomenon explaining why noise-prediction parameterizations fail catastrophically in blind settings
- Theoretical guarantee that velocity-based parameterizations satisfy bounded-gain conditions for stable sampling

## The Marginal Energy Framework

The core insight lies in recognizing that when noise levels are unknown, the relevant optimization landscape is not the conditional energy $E(\mathbf{u}|t)$ but the Marginal Energy:

$$E_{\text{marg}}(\mathbf{u}) = -\log \int p(\mathbf{u}|t)p(t)dt$$

This formulation treats the noise level $t$ as a latent random variable with prior $p(t)$. The authors prove that autonomous models performing blind denoising are actually following the gradient flow:

$$\frac{d\mathbf{u}}{ds} = -
abla E_{\text{marg}}(\mathbf{u})$$

This perspective transforms the problem from "how can a model denoise without knowing noise levels?" to "what is the geometry of the marginalized energy landscape?" The marginal density naturally weights different noise levels according to their posterior probability given the observation, enabling implicit noise-level estimation through geometric structure alone.

## Geometric Stabilization Mechanism

A critical challenge is that near the data manifold, the conditional energy $E(\mathbf{u}|t)$ exhibits a $1/t^p$ singularity in the normal direction, creating infinitely steep gradients. The authors demonstrate through relative energy decomposition that autonomous models learn to incorporate a local conformal metric $g(\mathbf{u})$ such that:

$$
abla_g E_{\text{marg}}(\mathbf{u}) = g(\mathbf{u})^{-1} 
abla E_{\text{marg}}(\mathbf{u})$$

This metric precisely counteracts the geometric singularity. While the raw energy landscape has unbounded gradients, the Riemannian gradient flow in the learned metric space remains bounded and stable. The time-invariant network implicitly learns this metric through training, converting what would be an unstable divergent flow into a smooth convergence toward the data manifold.

The stabilization is not accidental but emerges from the structure of the marginal distribution itself. The integration over noise levels in $p(\mathbf{u})$ naturally smooths the singularities present in individual conditional distributions $p(\mathbf{u}|t)$.

## Parameterization Stability Analysis

The paper provides rigorous analysis of why different parameterizations exhibit vastly different stability properties in autonomous settings:

**Noise-Prediction Parameterization**: Models predicting noise $\epsilon$ suffer from the Jensen Gap:

$$\mathbb{E}[\epsilon_\theta(\mathbf{u}_t)] \neq \epsilon_{\text{true}}$$

This gap acts as a high-gain amplifier. Small estimation errors in the noise prediction get amplified by the $1/t$ scaling factor inherent in converting noise predictions to velocity fields. The authors prove this leads to unbounded error accumulation, explaining catastrophic failures observed empirically in deterministic blind diffusion models.

**Velocity Parameterization**: Models directly predicting velocity $\mathbf{v}_\theta$ satisfy a bounded-gain condition:

$$\|\mathbf{v}_\theta(\mathbf{u}) - \mathbf{v}_{\text{true}}(\mathbf{u})\| \leq C$$

The posterior uncertainty over noise levels gets absorbed into smooth geometric drift rather than amplified. This inherent stability makes velocity-based autonomous models practical and robust. The bounded-gain property ensures that even with imperfect noise-level estimation, the sampling trajectory remains well-behaved and converges to the data distribution.

## Implications for Generative Modeling

This work fundamentally reframes our understanding of what diffusion models learn. Rather than viewing noise conditioning as essential, the geometric perspective reveals it as one possible implementation choice. Autonomous models learn the intrinsic geometry of the data distribution marginalized over noise uncertainty.

The theoretical framework suggests several practical implications:

- Velocity parameterization should be strongly preferred for autonomous/blind diffusion applications
- The success of models like Equilibrium Matching is not mysterious but follows from principled geometric properties
- Training objectives can be designed to explicitly encourage learning of stabilizing conformal metrics
- The framework extends beyond diffusion to other stochastic generative processes with latent uncertainty

The Marginal Energy perspective also connects diffusion models to broader themes in geometric deep learning and optimal transport, suggesting that successful generative models implicitly learn Riemannian structures adapted to their data distributions.

## Takeaways

1. Autonomous diffusion models optimize Marginal Energy, a landscape integrating over noise-level uncertainty rather than conditioning on known noise levels
2. Generation in autonomous models is Riemannian gradient flow where learned networks implicitly incorporate conformal metrics that stabilize geometric singularities
3. The "Jensen Gap" in noise-prediction parameterizations causes high-gain error amplification, explaining catastrophic failures in blind settings
4. Velocity-based parameterizations are provably stable due to bounded-gain conditions that absorb posterior uncertainty into smooth drift
5. The geometric framework reveals that noise conditioning is not fundamental but rather one implementation choice among many possible approaches
:::

:::zh
**论文**: [2602.18428](https://arxiv.org/abs/2602.18428)
**作者**: Mojtaba Sahraee-Ardakan, Mauricio Delbracio, Peyman Milanfar
**分类**: cs.LG, cs.CV, eess.IV

## 摘要

平衡匹配和盲扩散等自主生成模型学习单一的时不变向量场,无需显式的噪声级别条件,挑战了传统扩散范式。本文解决了一个基本悖论:无噪声感知网络如何在梯度通常发散的数据流形附近保持稳定?作者形式化了边缘能量 $E_{\text{marg}}(\mathbf{u}) = -\log p(\mathbf{u})$,其中 $p(\mathbf{u}) = \int p(\mathbf{u}|t)p(t)dt$ 对未知噪声级别进行积分。他们证明自主生成是该景观上的黎曼梯度流,学习到的场隐式地包含了共形度量,抵消了 $1/t^p$ 奇点,将无限势阱转化为稳定吸引子。研究识别了导致噪声预测参数化灾难性失败的"詹森间隙",同时证明基于速度的方法本质上是稳定的。

## 主要贡献

- 将边缘能量形式化为自主扩散模型的优化景观,对噪声级别不确定性进行积分
- 证明自主生成实现了带有隐式共形度量校正的黎曼梯度流
- 提出新颖的相对能量分解,揭示时不变场如何稳定数据流形附近的几何奇点
- 识别"詹森间隙"现象,解释噪声预测参数化在盲设置中灾难性失败的原因
- 理论保证基于速度的参数化满足有界增益条件以实现稳定采样

## 边缘能量框架

核心洞察在于认识到当噪声级别未知时,相关的优化景观不是条件能量 $E(\mathbf{u}|t)$ 而是边缘能量:

$$E_{\text{marg}}(\mathbf{u}) = -\log \int p(\mathbf{u}|t)p(t)dt$$

该公式将噪声级别 $t$ 视为具有先验 $p(t)$ 的潜在随机变量。作者证明执行盲去噪的自主模型实际上遵循梯度流:

$$\frac{d\mathbf{u}}{ds} = -
abla E_{\text{marg}}(\mathbf{u})$$

这一视角将问题从"模型如何在不知道噪声级别的情况下去噪?"转变为"边缘化能量景观的几何结构是什么?"边缘密度根据给定观测的后验概率自然地对不同噪声级别进行加权,仅通过几何结构就能实现隐式噪声级别估计。

## 几何稳定化机制

一个关键挑战是在数据流形附近,条件能量 $E(\mathbf{u}|t)$ 在法向方向上表现出 $1/t^p$ 奇点,产生无限陡峭的梯度。作者通过相对能量分解证明,自主模型学习包含局部共形度量 $g(\mathbf{u})$,使得:

$$
abla_g E_{\text{marg}}(\mathbf{u}) = g(\mathbf{u})^{-1} 
abla E_{\text{marg}}(\mathbf{u})$$

该度量精确地抵消了几何奇点。虽然原始能量景观具有无界梯度,但学习度量空间中的黎曼梯度流保持有界且稳定。时不变网络通过训练隐式学习该度量,将原本不稳定的发散流转化为向数据流形的平滑收敛。

稳定化不是偶然的,而是从边缘分布本身的结构中涌现的。对 $p(\mathbf{u})$ 中噪声级别的积分自然地平滑了单个条件分布 $p(\mathbf{u}|t)$ 中存在的奇点。

## 参数化稳定性分析

论文对不同参数化在自主设置中表现出截然不同的稳定性特性进行了严格分析:

**噪声预测参数化**: 预测噪声 $\epsilon$ 的模型受詹森间隙影响:

$$\mathbb{E}[\epsilon_\theta(\mathbf{u}_t)] 
eq \epsilon_{\text{true}}$$

该间隙充当高增益放大器。噪声预测中的小估计误差被转换为速度场时固有的 $1/t$ 缩放因子放大。作者证明这导致无界误差累积,解释了在确定性盲扩散模型中观察到的灾难性失败。

**速度参数化**: 直接预测速度 $\mathbf{v}_\theta$ 的模型满足有界增益条件:

$$\|\mathbf{v}_\theta(\mathbf{u}) - \mathbf{v}_{\text{true}}(\mathbf{u})\| \leq C$$

噪声级别上的后验不确定性被吸收到平滑的几何漂移中而非被放大。这种固有稳定性使基于速度的自主模型实用且鲁棒。有界增益特性确保即使噪声级别估计不完美,采样轨迹仍保持良好行为并收敛到数据分布。

## 对生成建模的启示

这项工作从根本上重构了我们对扩散模型学习内容的理解。与其将噪声条件视为必不可少,几何视角揭示它只是一种可能的实现选择。自主模型学习在噪声不确定性上边缘化的数据分布的内在几何。

理论框架提出了几个实践启示:

- 对于自主/盲扩散应用应强烈优先选择速度参数化
- 平衡匹配等模型的成功不是神秘的,而是遵循原则性几何特性
- 训练目标可以设计为显式鼓励学习稳定化共形度量
- 该框架扩展到具有潜在不确定性的其他随机生成过程

边缘能量视角还将扩散模型与几何深度学习和最优传输中的更广泛主题联系起来,表明成功的生成模型隐式学习适应其数据分布的黎曼结构。

## 要点总结

1. 自主扩散模型优化边缘能量,这是一个对噪声级别不确定性进行积分而非条件于已知噪声级别的景观
2. 自主模型中的生成是黎曼梯度流,学习到的网络隐式包含稳定几何奇点的共形度量
3. 噪声预测参数化中的"詹森间隙"导致高增益误差放大,解释了盲设置中的灾难性失败
4. 基于速度的参数化由于满足将后验不确定性吸收到平滑漂移的有界增益条件而可证明稳定
5. 几何框架揭示噪声条件不是基础性的,而是众多可能方法中的一种实现选择
:::
