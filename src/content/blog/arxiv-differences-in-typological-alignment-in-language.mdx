---
title:
  en: "Language Models Show Selective Typological Alignment in Differential Argument Marking"
  zh: "语言模型在差异论元标记中展现选择性类型学对齐"
description:
  en: "Research reveals that GPT-2 models trained on synthetic corpora reproduce human-like preferences for markedness direction in differential argument marking, but fail to capture the cross-linguistic object preference pattern."
  zh: "研究发现，在合成语料上训练的GPT-2模型能够复现人类语言中差异论元标记的自然标记性方向偏好,但未能捕捉跨语言的宾语偏好模式。"
date: 2026-02-21
tags: ["arxiv", "ai", "cs.cl"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.17653](https://arxiv.org/abs/2602.17653)
**Authors**: Iskar Deng, Nathalia Xu, Shane Steinert-Threlkeld
**Categories**: cs.CL

## Abstract

This paper investigates whether language models can acquire typological preferences for differential argument marking (DAM), a morphological system where case marking depends on semantic prominence. By training GPT-2 models on 18 synthetic corpora implementing different DAM configurations, the authors discover a critical dissociation: models successfully learn the natural markedness direction (marking semantically atypical arguments), mirroring human language universals, but fail to reproduce the strong cross-linguistic preference for marking objects over subjects. This asymmetry suggests that different typological tendencies in human languages may emerge from fundamentally different cognitive or communicative pressures.

## Key Contributions

- Extends synthetic language learning paradigm from syntactic phenomena to semantic licensing systems (differential argument marking)
- Demonstrates that GPT-2 models trained on controlled synthetic corpora can acquire natural markedness direction preferences consistent with human language typology
- Reveals a systematic failure of models to learn object preference in DAM systems, despite this being a robust cross-linguistic pattern
- Provides evidence that typological universals may arise from multiple distinct sources rather than a unified underlying mechanism
- Introduces a rigorous minimal pairs evaluation methodology for testing DAM generalization in language models

## Methodology and Experimental Design

The researchers employed a controlled synthetic learning approach to isolate specific typological variables. They generated 18 distinct synthetic corpora, each implementing a different DAM system along two key dimensions:

**Markedness Direction**: Systems varied in whether overt morphological marking targeted semantically typical or atypical arguments. In natural languages, marking typically targets atypical arguments—for instance, animate objects receive overt case marking more often than inanimate ones, since objects are prototypically inanimate.

**Argument Role**: Systems varied in whether DAM applied to subjects or objects. Cross-linguistically, DAM systems overwhelmingly target objects rather than subjects, a pattern known as the "object preference."

Each synthetic corpus was carefully controlled for vocabulary size, sentence structure complexity, and frequency distributions to ensure that observed learning patterns reflected genuine typological biases rather than statistical artifacts. GPT-2 models were trained from scratch on each corpus using identical hyperparameters, then evaluated using minimal pairs that tested generalization to novel semantic contexts.

The minimal pairs methodology involved presenting models with sentence pairs differing only in the presence or absence of DAM marking, then measuring whether models assigned higher probability to grammatical versus ungrammatical variants. This approach directly tests whether models have internalized the underlying semantic licensing conditions rather than merely memorizing surface patterns.

## Results and Analysis

The experimental results revealed a striking dissociation between the two typological dimensions:

**Markedness Direction**: Models consistently demonstrated human-like preferences, assigning higher probabilities to systems where overt marking targeted semantically atypical arguments. For example, in object-marking systems, models preferred configurations where animate objects (atypical) received overt case marking while inanimate objects (typical) remained unmarked. This pattern held across different semantic features (animacy, definiteness, person) and emerged reliably across multiple training runs.

**Object Preference**: In stark contrast, models showed no systematic preference for object-marking over subject-marking DAM systems. When trained on subject-DAM and object-DAM corpora with identical statistical properties, models learned both systems equally well, failing to reproduce the strong cross-linguistic bias toward object marking observed in human languages.

Statistical analysis confirmed these patterns were robust and not attributable to random variation or specific corpus characteristics. The dissociation persisted across different model sizes and training durations, suggesting it reflects a fundamental property of the learning dynamics rather than insufficient capacity or data.

## Implications for Linguistic Theory and AI

These findings carry significant implications for both linguistic typology and our understanding of language model capabilities:

**Multiple Sources of Typological Universals**: The dissociation suggests that different typological patterns may arise from distinct underlying mechanisms. Natural markedness direction may emerge from domain-general learning biases or information-theoretic principles that language models naturally capture. In contrast, object preference may reflect functional pressures specific to human communication (such as discourse management or processing efficiency) that are absent from pure distributional learning.

**Limits of Distributional Learning**: The results demonstrate that not all cross-linguistic regularities are equally learnable from distributional patterns alone. While models successfully acquire some typological preferences, others require additional inductive biases or learning signals beyond what standard language modeling provides.

**Cognitive vs. Functional Explanations**: The findings support theoretical frameworks that distinguish between cognitive constraints (which may be captured by neural networks) and functional pressures (which may require explicit communicative goals). Natural markedness direction may reflect cognitive processing preferences, while object preference may serve discourse-functional purposes.

**Implications for Multilingual Models**: Understanding which typological patterns emerge naturally from distributional learning versus which require explicit architectural biases can inform the design of more linguistically sophisticated multilingual language models.

## Takeaways

1. Language models trained on synthetic corpora can acquire some but not all typological preferences observed in human languages, revealing selective alignment with linguistic universals.

2. GPT-2 models reliably learn natural markedness direction in DAM systems, preferring configurations where overt marking targets semantically atypical arguments—consistent with cross-linguistic patterns.

3. Models fail to reproduce the strong object preference in human DAM systems, showing no bias toward object-marking over subject-marking configurations despite identical training conditions.

4. The dissociation between markedness direction and object preference suggests that different typological universals may arise from fundamentally different sources—some from domain-general learning biases, others from human-specific functional pressures.

5. These findings highlight both the potential and limitations of using language models as cognitive models, demonstrating that distributional learning alone cannot account for all aspects of linguistic typology.
:::

:::zh
**论文**: [2602.17653](https://arxiv.org/abs/2602.17653)
**作者**: Iskar Deng, Nathalia Xu, Shane Steinert-Threlkeld
**分类**: cs.CL

## 摘要

本文研究语言模型能否习得差异论元标记(DAM)的类型学偏好。差异论元标记是一种形态系统,其中格标记取决于语义突显性。通过在18个实现不同DAM配置的合成语料库上训练GPT-2模型,作者发现了一个关键的分离现象:模型成功学习了自然标记性方向(标记语义上非典型的论元),这与人类语言普遍性相符;但模型未能复现跨语言中标记宾语而非主语的强烈偏好。这种不对称性表明,人类语言中不同的类型学倾向可能源于根本不同的认知或交际压力。

## 主要贡献

- 将合成语言学习范式从句法现象扩展到语义许可系统(差异论元标记)
- 证明在受控合成语料上训练的GPT-2模型能够习得与人类语言类型学一致的自然标记性方向偏好
- 揭示模型系统性地未能学习DAM系统中的宾语偏好,尽管这是一个稳健的跨语言模式
- 提供证据表明类型学普遍性可能源于多个不同来源,而非统一的底层机制
- 引入严格的最小对比评估方法来测试语言模型中的DAM泛化能力

## 方法论与实验设计

研究者采用受控的合成学习方法来隔离特定的类型学变量。他们生成了18个不同的合成语料库,每个语料库沿两个关键维度实现不同的DAM系统:

**标记性方向**: 系统在显性形态标记是针对语义上典型还是非典型论元方面有所不同。在自然语言中,标记通常针对非典型论元——例如,有生命的宾语比无生命的宾语更常接受显性格标记,因为宾语原型上是无生命的。

**论元角色**: 系统在DAM应用于主语还是宾语方面有所不同。跨语言来看,DAM系统压倒性地针对宾语而非主语,这种模式被称为"宾语偏好"。

每个合成语料库在词汇量大小、句子结构复杂度和频率分布方面都经过仔细控制,以确保观察到的学习模式反映真正的类型学偏见,而非统计伪影。GPT-2模型使用相同的超参数在每个语料库上从头训练,然后使用测试新语义语境泛化能力的最小对比进行评估。

最小对比方法涉及向模型呈现仅在DAM标记存在与否上有差异的句子对,然后测量模型是否为合语法变体分配了比不合语法变体更高的概率。这种方法直接测试模型是否内化了底层的语义许可条件,而不仅仅是记忆表层模式。

## 结果与分析

实验结果揭示了两个类型学维度之间的显著分离:

**标记性方向**: 模型一致地表现出类人偏好,为显性标记针对语义上非典型论元的系统分配更高概率。例如,在宾语标记系统中,模型偏好有生命宾语(非典型)接受显性格标记而无生命宾语(典型)保持无标记的配置。这种模式在不同语义特征(有生性、定指性、人称)中保持一致,并在多次训练运行中可靠地出现。

**宾语偏好**: 形成鲜明对比的是,模型对宾语标记DAM系统相比主语标记DAM系统没有表现出系统性偏好。当在具有相同统计属性的主语DAM和宾语DAM语料库上训练时,模型对两种系统的学习效果相当,未能复现人类语言中观察到的对宾语标记的强烈跨语言偏见。

统计分析证实这些模式是稳健的,不能归因于随机变异或特定语料库特征。这种分离在不同模型规模和训练时长中持续存在,表明它反映了学习动力学的基本属性,而非能力或数据不足。

## 对语言学理论和人工智能的启示

这些发现对语言类型学和我们对语言模型能力的理解都具有重要意义:

**类型学普遍性的多重来源**: 这种分离表明不同的类型学模式可能源于不同的底层机制。自然标记性方向可能源于语言模型自然捕获的领域通用学习偏见或信息论原则。相反,宾语偏好可能反映了人类交际特有的功能压力(如话语管理或处理效率),这些在纯分布学习中是缺失的。

**分布学习的局限**: 结果表明,并非所有跨语言规律都能从分布模式中同等地学习。虽然模型成功习得了一些类型学偏好,但其他偏好需要标准语言建模提供之外的额外归纳偏见或学习信号。

**认知与功能解释**: 研究结果支持区分认知约束(可能被神经网络捕获)和功能压力(可能需要明确的交际目标)的理论框架。自然标记性方向可能反映认知处理偏好,而宾语偏好可能服务于话语功能目的。

**对多语言模型的启示**: 理解哪些类型学模式自然地从分布学习中涌现,哪些需要明确的架构偏见,可以为设计更具语言学复杂性的多语言语言模型提供信息。

## 要点总结

1. 在合成语料上训练的语言模型能够习得人类语言中观察到的部分而非全部类型学偏好,揭示了与语言普遍性的选择性对齐。

2. GPT-2模型可靠地学习DAM系统中的自然标记性方向,偏好显性标记针对语义上非典型论元的配置——这与跨语言模式一致。

3. 模型未能复现人类DAM系统中的强宾语偏好,在相同训练条件下对宾语标记和主语标记配置没有表现出偏见。

4. 标记性方向和宾语偏好之间的分离表明,不同的类型学普遍性可能源于根本不同的来源——一些来自领域通用学习偏见,另一些来自人类特有的功能压力。

5. 这些发现突显了使用语言模型作为认知模型的潜力和局限,表明仅靠分布学习无法解释语言类型学的所有方面。
:::
