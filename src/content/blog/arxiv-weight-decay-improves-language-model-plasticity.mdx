---
title:
  en: "Weight Decay Improves Language Model Plasticity"
  zh: "权重衰减提升语言模型可塑性"
description:
  en: "Research showing that higher weight decay during pretraining enhances a language model's ability to adapt to downstream tasks, challenging conventional hyperparameter optimization focused solely on validation loss."
  zh: "研究表明预训练期间更高的权重衰减能增强语言模型适应下游任务的能力,挑战了仅关注验证损失的传统超参数优化方法。"
date: 2026-02-12
tags: ["arxiv", "ai", "cs.lg", "cs.ai", "cs.cl"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.11137](https://arxiv.org/abs/2602.11137)
**Authors**: Tessa Han, Sebastian Bordt, Hanlin Zhang, Sham Kakade
**Categories**: cs.LG, cs.AI, cs.CL

## Abstract

This paper challenges the standard approach to language model pretraining by examining model plasticity—the capacity to adapt effectively through fine-tuning—rather than just validation loss. The authors demonstrate that weight decay, a fundamental regularization hyperparameter, plays a crucial role in determining downstream adaptability. Through systematic experiments, they reveal that models pretrained with higher weight decay values exhibit superior plasticity, achieving better performance on downstream tasks even when their base pretraining loss is higher. This counterintuitive finding suggests that optimizing solely for pretraining loss may be suboptimal for real-world deployment scenarios where fine-tuning is essential.

## Key Contributions

- Introduces model plasticity as a critical evaluation metric for pretraining, complementing traditional validation loss measurements
- Demonstrates empirically that higher weight decay during pretraining leads to more plastic models with better fine-tuning performance
- Reveals a counterintuitive trade-off: base models with worse pretraining loss can outperform lower-loss models after fine-tuning
- Provides mechanistic insights into how weight decay affects model behavior: promoting linearly separable representations, regularizing attention matrices, and reducing overfitting
- Challenges current hyperparameter optimization practices that focus exclusively on pretraining metrics

## Methodology and Experimental Design

The research employs a systematic experimental framework to isolate the effects of weight decay on model plasticity. The authors pretrain language models with varying weight decay values while controlling for other hyperparameters, then evaluate both pretraining performance and downstream task adaptation through fine-tuning.

The experimental setup includes multiple downstream tasks spanning different domains and difficulty levels, ensuring that plasticity measurements are robust across diverse scenarios. By comparing models with identical architectures but different weight decay settings, the study establishes a clear causal relationship between this regularization parameter and downstream adaptability.

The authors also conduct mechanistic analyses to understand why weight decay improves plasticity. They examine learned representations through linear probing, analyze attention pattern distributions, and measure generalization gaps between training and validation performance. These investigations reveal that weight decay acts as more than simple L2 regularization—it fundamentally shapes how models encode and organize information.

## Results and Findings

The experimental results demonstrate a consistent pattern: models trained with higher weight decay values show significantly larger performance improvements when fine-tuned on downstream tasks. This effect holds across various model sizes and task types, suggesting it's a fundamental property rather than an artifact of specific experimental conditions.

Particularly striking is the discovery of performance inversions. In several cases, models with higher pretraining loss (due to stronger weight decay) ultimately achieve better downstream performance than models with lower pretraining loss. This finding directly contradicts the common assumption that lower pretraining loss always translates to better overall model quality.

The mechanistic analyses reveal three key effects of weight decay:

1. **Linearly separable representations**: Higher weight decay encourages the model to learn representations where different concepts and categories are more easily distinguished through linear boundaries, facilitating efficient adaptation to new tasks.

2. **Attention regularization**: Weight decay prevents attention matrices from becoming overly peaked or specialized, maintaining flexibility that enables the model to redirect attention patterns during fine-tuning.

3. **Reduced overfitting**: Models with higher weight decay show smaller gaps between training and validation performance, indicating better generalization that transfers to downstream scenarios.

## Implications for LLM Development

This research has significant implications for how we approach language model development and hyperparameter optimization. The current paradigm of optimizing pretraining hyperparameters based solely on validation loss may be leaving performance on the table, particularly for models intended for fine-tuning applications.

The findings suggest that practitioners should consider multi-objective optimization strategies that balance pretraining performance with downstream plasticity. This might involve evaluating candidate hyperparameter configurations on a small set of representative downstream tasks during the pretraining phase, rather than waiting until after pretraining is complete.

For organizations deploying LLMs, these results indicate that selecting base models should involve more than comparing pretraining benchmarks. Models with slightly higher pretraining loss but better plasticity characteristics may ultimately deliver superior performance in production environments where task-specific fine-tuning is standard practice.

The work also raises important questions about scaling laws and their relationship to plasticity. If weight decay affects how models scale with compute and data, existing scaling law formulations may need revision to account for downstream adaptability alongside pretraining loss.

## Takeaways

1. Model plasticity—the ability to adapt through fine-tuning—should be considered alongside pretraining loss when evaluating language models and optimizing hyperparameters.

2. Higher weight decay during pretraining consistently improves downstream task performance, even when it increases pretraining loss, revealing a fundamental trade-off in model development.

3. Weight decay's benefits stem from multiple mechanisms: promoting linearly separable representations, regularizing attention patterns, and reducing overfitting on pretraining data.

4. Current hyperparameter optimization practices that focus exclusively on pretraining metrics may be suboptimal for real-world deployment scenarios involving fine-tuning.

5. The relationship between a single hyperparameter and model behavior is multifaceted, suggesting that simple interpretations of regularization effects may miss important dynamics in large-scale model training.
:::

:::zh
**论文**: [2602.11137](https://arxiv.org/abs/2602.11137)
**作者**: Tessa Han, Sebastian Bordt, Hanlin Zhang, Sham Kakade
**分类**: cs.LG, cs.AI, cs.CL

## 摘要

本文通过研究模型可塑性——即通过微调有效适应的能力——而非仅关注验证损失,挑战了语言模型预训练的标准方法。作者证明权重衰减这一基础正则化超参数在决定下游适应性方面发挥着关键作用。通过系统性实验,他们揭示了使用更高权重衰减值预训练的模型表现出更优的可塑性,即使其基础预训练损失更高,在下游任务上也能获得更好的性能。这一反直觉的发现表明,仅针对预训练损失进行优化可能对于需要微调的实际部署场景并非最优。

## 主要贡献

- 引入模型可塑性作为预训练的关键评估指标,补充传统的验证损失测量
- 通过实证证明预训练期间更高的权重衰减能产生可塑性更强、微调性能更好的模型
- 揭示了一个反直觉的权衡:预训练损失更差的基础模型在微调后可能超越低损失模型
- 提供了权重衰减如何影响模型行为的机制性洞察:促进线性可分表示、正则化注意力矩阵、减少过拟合
- 挑战了当前仅关注预训练指标的超参数优化实践

## 方法论与实验设计

该研究采用系统性实验框架来分离权重衰减对模型可塑性的影响。作者在控制其他超参数的情况下,使用不同的权重衰减值预训练语言模型,然后通过微调评估预训练性能和下游任务适应能力。

实验设置包括跨越不同领域和难度级别的多个下游任务,确保可塑性测量在多样化场景中具有鲁棒性。通过比较架构相同但权重衰减设置不同的模型,该研究在这一正则化参数与下游适应性之间建立了明确的因果关系。

作者还进行了机制性分析以理解权重衰减为何能提升可塑性。他们通过线性探测检查学习到的表示,分析注意力模式分布,并测量训练与验证性能之间的泛化差距。这些研究揭示权重衰减不仅仅是简单的L2正则化——它从根本上塑造了模型如何编码和组织信息。

## 结果与发现

实验结果展示了一致的模式:使用更高权重衰减值训练的模型在下游任务微调时表现出显著更大的性能提升。这一效应在各种模型规模和任务类型中都成立,表明这是一个基本属性而非特定实验条件的产物。

特别引人注目的是性能反转的发现。在多个案例中,由于更强的权重衰减而具有更高预训练损失的模型,最终在下游性能上超越了预训练损失更低的模型。这一发现直接反驳了更低预训练损失总能转化为更好整体模型质量的常见假设。

机制性分析揭示了权重衰减的三个关键效应:

1. **线性可分表示**:更高的权重衰减鼓励模型学习不同概念和类别通过线性边界更容易区分的表示,促进对新任务的高效适应。

2. **注意力正则化**:权重衰减防止注意力矩阵变得过度尖锐或专门化,保持灵活性使模型能够在微调期间重定向注意力模式。

3. **减少过拟合**:具有更高权重衰减的模型在训练和验证性能之间显示出更小的差距,表明更好的泛化能力可以迁移到下游场景。

## 对大语言模型开发的启示

这项研究对我们如何进行语言模型开发和超参数优化具有重要意义。当前仅基于验证损失优化预训练超参数的范式可能会遗漏性能潜力,特别是对于用于微调应用的模型。

研究结果表明,实践者应考虑平衡预训练性能与下游可塑性的多目标优化策略。这可能涉及在预训练阶段对候选超参数配置在一小组代表性下游任务上进行评估,而不是等到预训练完成后。

对于部署大语言模型的组织,这些结果表明选择基础模型应该涉及的不仅仅是比较预训练基准。预训练损失略高但可塑性特征更好的模型,在任务特定微调是标准实践的生产环境中可能最终提供更优的性能。

这项工作还提出了关于缩放定律及其与可塑性关系的重要问题。如果权重衰减影响模型如何随计算和数据扩展,现有的缩放定律公式可能需要修订以考虑下游适应性以及预训练损失。

## 要点总结

1. 模型可塑性——通过微调适应的能力——在评估语言模型和优化超参数时应与预训练损失一起考虑。

2. 预训练期间更高的权重衰减能持续改善下游任务性能,即使它增加了预训练损失,揭示了模型开发中的基本权衡。

3. 权重衰减的益处源于多种机制:促进线性可分表示、正则化注意力模式、减少预训练数据上的过拟合。

4. 当前仅关注预训练指标的超参数优化实践,对于涉及微调的实际部署场景可能并非最优。

5. 单个超参数与模型行为之间的关系是多方面的,表明对正则化效应的简单解释可能会遗漏大规模模型训练中的重要动态。
:::
