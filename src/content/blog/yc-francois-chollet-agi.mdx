---
title:
  en: "François Chollet: How We Get To AGI"
  zh: "François Chollet：我们如何实现AGI"
description:
  en: "Keras creator François Chollet discusses the path to AGI, the ARC benchmark, and the difference between intelligence and skill"
  zh: "Keras创始人François Chollet讨论通往AGI的道路、ARC基准测试以及智能与技能的区别"
date: 2025-07-03
tags: ["ycombinator", "ai", "francois-chollet", "agi", "arc-prize", "keras"]
image: "https://i2.ytimg.com/vi/5QcCeSsNRks/hqdefault.jpg"
---

import YouTube from '../../components/YouTube.astro';

<YouTube id="5QcCeSsNRks" title="François Chollet: How We Get To AGI | Y Combinator" />

:::en
François Chollet, creator of Keras and the ARC benchmark, discusses the path to AGI, the fundamental difference between intelligence and skill, and why current AI systems are missing a crucial component.

## The Deep Learning Revolution

### The Cost of Compute
- Cost of compute has fallen by two orders of magnitude every decade since 1940
- Deep learning started working in the 2010s when GPU compute became available
- Large datasets (ImageNet) combined with compute enabled the breakthrough

### The Scaling Paradigm
- Pre-training on massive datasets became the dominant approach
- Scaling laws showed predictable improvements with more compute and data
- But this paradigm has limitations that are becoming apparent

## Intelligence vs. Skill

### The Key Distinction
François makes a crucial distinction between two concepts:

- **Skill**: The ability to perform a specific task (static, memorized)
- **Intelligence**: The ability to handle novel situations efficiently (dynamic, adaptive)

### The Road Analogy
- **Skill** is like a road network - static infrastructure that enables travel
- **Intelligence** is like a road-building company - the ability to create new roads when needed
- Current AI systems are building massive road networks but lack the road-building capability

### Two Definitions of Intelligence
1. **Minsky View**: Intelligence as task performance (can it do X?)
2. **McCarthy View**: Intelligence as handling novelty (can it adapt to new situations?)

François argues the McCarthy view is more useful for understanding AGI.

## The ARC Benchmark

### Why ARC Was Created
- Released in 2019 as an "IQ test for machines"
- Designed to measure fluid intelligence, not memorized skills
- Tasks require understanding abstract patterns with minimal examples

### How ARC Works
- Each task shows a few input-output examples
- The system must infer the underlying rule and apply it to a new input
- Tasks are designed to be easy for humans but hard for systems that rely on memorization

### ARC-AGI Evolution
- **ARC-AGI 1**: Original benchmark, now largely solved
- **ARC-AGI 2**: Released March 2025, harder tasks
- **ARC-AGI 3**: In development, will assess agency and interactive learning

## The 2024 Paradigm Shift

### Test-Time Adaptation
- 2024 marked a shift from pre-training scaling to test-time compute
- Systems like OpenAI's O1 and O3 use more compute at inference time
- O3 achieved human-level performance on ARC-AGI 1

### What This Means
- The field is moving toward systems that can adapt on the fly
- But current approaches still have fundamental limitations
- True intelligence requires more than just scaling test-time compute

## The Kaleidoscope Hypothesis

### Core Idea
- Everything in the universe is a recombination of "atoms of meaning"
- Like a kaleidoscope creating infinite patterns from finite pieces
- Intelligence is the ability to identify and recombine these atoms

### Implications
- Learning is about discovering the right atoms of meaning
- Generalization comes from compositional recombination
- This explains why humans can generalize from few examples

## Two Types of Abstraction

### Type 1: Value-Centric (Continuous)
- Based on perception and intuition
- Handles continuous, fuzzy patterns
- What transformers excel at
- Examples: recognizing faces, understanding language nuance

### Type 2: Program-Centric (Discrete)
- Based on reasoning and planning
- Handles discrete, logical structures
- What current AI struggles with
- Examples: mathematical proofs, novel problem-solving

### The Missing Piece
- Current AI systems are strong at Type 1 but weak at Type 2
- True AGI requires combining both types
- Need systems that can synthesize programs, not just interpolate patterns

## The Path Forward

### Program Synthesis
- Future AI needs to be more like programmers
- Synthesizing programs on the fly to solve novel problems
- Discrete search over program space, not just continuous optimization

### The Shortcut Rule
- In engineering, the first solution is rarely optimal
- Need to explore the space of possibilities
- Current AI takes shortcuts that limit true generalization

### What's Needed
- Combine deep learning (Type 1) with program synthesis (Type 2)
- Systems that can build new abstractions, not just use existing ones
- True compositional generalization

## Key Takeaways

1. **Intelligence is not skill** - Being good at tasks doesn't mean being intelligent
2. **Novelty is the test** - True intelligence handles new situations efficiently
3. **Two types of thinking** - We need both intuition (Type 1) and reasoning (Type 2)
4. **Program synthesis is key** - The path to AGI involves synthesizing programs
5. **Benchmarks matter** - ARC measures what other benchmarks miss

## Notable Quotes

> "Skill is like a road network. Intelligence is like a road-building company."

> "The question is not 'can it do X?' but 'can it handle novelty?'"

> "Current AI is very good at interpolation but struggles with true invention."
:::

:::zh
François Chollet，Keras和ARC基准测试的创建者，讨论通往AGI的道路、智能与技能的根本区别，以及为什么当前AI系统缺少一个关键组件。

## 深度学习革命

### 计算成本
- 自1940年以来，计算成本每十年下降两个数量级
- 深度学习在2010年代GPU计算可用时开始发挥作用
- 大型数据集（ImageNet）与计算能力的结合实现了突破

### 扩展范式
- 在海量数据集上预训练成为主导方法
- 扩展定律显示更多计算和数据带来可预测的改进
- 但这种范式的局限性正在显现

## 智能与技能

### 关键区别
François对两个概念做出了关键区分：

- **技能**：执行特定任务的能力（静态、记忆的）
- **智能**：高效处理新情况的能力（动态、适应性的）

### 道路类比
- **技能**就像道路网络——实现出行的静态基础设施
- **智能**就像道路建设公司——在需要时建造新道路的能力
- 当前AI系统正在建设庞大的道路网络，但缺乏道路建设能力

### 智能的两种定义
1. **Minsky观点**：智能作为任务表现（它能做X吗？）
2. **McCarthy观点**：智能作为处理新颖性（它能适应新情况吗？）

François认为McCarthy的观点对理解AGI更有用。

## ARC基准测试

### 为什么创建ARC
- 2019年发布，作为"机器的智商测试"
- 设计用于测量流体智能，而非记忆技能
- 任务需要用最少的例子理解抽象模式

### ARC如何工作
- 每个任务展示几个输入-输出示例
- 系统必须推断底层规则并将其应用于新输入
- 任务设计为对人类容易但对依赖记忆的系统困难

### ARC-AGI演进
- **ARC-AGI 1**：原始基准，现已基本解决
- **ARC-AGI 2**：2025年3月发布，更难的任务
- **ARC-AGI 3**：开发中，将评估代理能力和交互学习

## 2024年范式转变

### 测试时适应
- 2024年标志着从预训练扩展到测试时计算的转变
- OpenAI的O1和O3等系统在推理时使用更多计算
- O3在ARC-AGI 1上达到人类水平表现

### 这意味着什么
- 该领域正在转向能够即时适应的系统
- 但当前方法仍有根本局限
- 真正的智能需要的不仅仅是扩展测试时计算

## 万花筒假说

### 核心思想
- 宇宙中的一切都是"意义原子"的重组
- 就像万花筒用有限的碎片创造无限的图案
- 智能是识别和重组这些原子的能力

### 含义
- 学习是关于发现正确的意义原子
- 泛化来自组合重组
- 这解释了为什么人类可以从少量例子中泛化

## 两种抽象类型

### 类型1：以价值为中心（连续）
- 基于感知和直觉
- 处理连续、模糊的模式
- Transformer擅长的领域
- 例子：识别面孔、理解语言细微差别

### 类型2：以程序为中心（离散）
- 基于推理和规划
- 处理离散、逻辑结构
- 当前AI困难的领域
- 例子：数学证明、新颖问题解决

### 缺失的部分
- 当前AI系统在类型1上强但在类型2上弱
- 真正的AGI需要结合两种类型
- 需要能够合成程序的系统，而不仅仅是插值模式

## 前进的道路

### 程序合成
- 未来AI需要更像程序员
- 即时合成程序来解决新问题
- 在程序空间上进行离散搜索，而不仅仅是连续优化

### 捷径规则
- 在工程中，第一个解决方案很少是最优的
- 需要探索可能性空间
- 当前AI走捷径限制了真正的泛化

### 需要什么
- 结合深度学习（类型1）和程序合成（类型2）
- 能够构建新抽象的系统，而不仅仅是使用现有的
- 真正的组合泛化

## 关键要点

1. **智能不是技能** - 擅长任务不意味着有智能
2. **新颖性是测试** - 真正的智能高效处理新情况
3. **两种思维类型** - 我们需要直觉（类型1）和推理（类型2）
4. **程序合成是关键** - 通往AGI的道路涉及合成程序
5. **基准测试很重要** - ARC测量其他基准测试遗漏的内容

## 值得注意的引言

> "技能就像道路网络。智能就像道路建设公司。"

> "问题不是'它能做X吗？'而是'它能处理新颖性吗？'"

> "当前AI非常擅长插值，但在真正的发明上有困难。"
:::
