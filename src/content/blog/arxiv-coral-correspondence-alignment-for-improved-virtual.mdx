---
title:
  en: "CORAL: Correspondence Alignment for Improved Virtual Try-On"
  zh: "CORAL:通过对应关系对齐改进虚拟试衣效果"
description:
  en: "A Diffusion Transformer-based framework that explicitly aligns person-garment correspondences through attention mechanism analysis, achieving superior detail preservation in virtual try-on tasks."
  zh: "基于扩散Transformer的框架,通过注意力机制分析显式对齐人物-服装对应关系,在虚拟试衣任务中实现卓越的细节保留效果。"
date: 2026-02-21
tags: ["arxiv", "ai", "cs.cv"]
image: "/arxiv-visuals/arxiv-coral-correspondence-alignment-for-improved-virtual.png"
---

:::en
**Paper**: [2602.17636](https://arxiv.org/abs/2602.17636)
**Authors**: Jiyoung Kim, Youngjin Shin, Siyoon Jin, Dahyun Chung, Jisu Nam, Tongmin Kim, Jongjae Park, Hyeonwoo Kang, Seungryong Kim
**Categories**: cs.CV

## Abstract

Virtual Try-On (VTON) systems face significant challenges in preserving fine garment details, particularly in unpaired settings where establishing accurate person-garment correspondence is critical. This paper introduces CORAL (CORrespondence ALignment), a novel DiT-based framework that addresses these limitations through explicit correspondence alignment. The authors first conduct a systematic analysis of full 3D attention mechanisms in Diffusion Transformers, revealing that person-garment correspondence fundamentally depends on precise query-key matching within the attention layers. CORAL leverages this insight by integrating two complementary loss functions: a correspondence distillation loss that aligns external robust matches with attention patterns, and an entropy minimization loss that sharpens attention distributions. The framework also introduces a VLM-based evaluation protocol to better capture human preferences in try-on quality assessment.

## Key Contributions

- Systematic analysis of full 3D attention in DiT architectures, revealing the critical role of query-key matching in establishing person-garment correspondence
- CORAL framework that explicitly enforces correspondence alignment through two complementary loss components
- Correspondence distillation loss that transfers knowledge from robust external correspondence models to the attention mechanism
- Entropy minimization loss that sharpens attention distributions for more precise alignment
- VLM-based evaluation protocol that better reflects human preference compared to traditional metrics
- Comprehensive ablation studies validating each design choice and demonstrating consistent improvements in both global shape transfer and local detail preservation

## Methodology and Technical Approach

The CORAL framework builds upon Diffusion Transformer architectures, specifically targeting the full 3D attention mechanism that processes concatenated person and garment features. The key insight is that effective virtual try-on requires the attention mechanism to implicitly learn correct correspondences between person body parts and garment regions.

The correspondence distillation loss $\mathcal{L}_{distill}$ operates by first obtaining robust correspondences from external models (such as optical flow or feature matching networks), then encouraging the attention weights to align with these correspondences. Formally, given attention weights $A \in \mathbb{R}^{N_p \times N_g}$ between person tokens and garment tokens, and external correspondence map $C$, the loss minimizes the divergence between $A$ and $C$.

The entropy minimization loss $\mathcal{L}_{entropy}$ complements this by encouraging sharper, more confident attention distributions. This prevents the attention from being diffuse across multiple garment regions for a single person location, which would result in blurred or mixed details. The entropy term is computed as:

$$\mathcal{L}_{entropy} = -\sum_{i,j} A_{ij} \log A_{ij}$$

where lower entropy indicates more concentrated attention patterns.

The total training objective combines these losses with the standard diffusion loss:

$$\mathcal{L}_{total} = \mathcal{L}_{diffusion} + \lambda_1 \mathcal{L}_{distill} + \lambda_2 \mathcal{L}_{entropy}$$

## Experimental Results and Analysis

CORAL demonstrates consistent improvements over baseline DiT-based VTON methods across multiple benchmarks. The experiments evaluate both paired and unpaired settings, with unpaired scenarios being particularly challenging due to the lack of ground-truth person-garment alignment.

Quantitative results show improvements in standard metrics including FID, LPIPS, and SSIM. More importantly, the proposed VLM-based evaluation reveals that CORAL better aligns with human preferences, particularly in preserving intricate garment patterns, textures, and structural details like collars, sleeves, and hemlines.

Ablation studies systematically validate each component. Removing the correspondence distillation loss results in misaligned garment placement and distorted patterns. Without entropy minimization, the model produces blurrier results with mixed details from multiple garment regions. The combination of both losses yields the best performance, demonstrating their complementary nature.

Qualitative comparisons highlight CORAL's superiority in challenging scenarios: complex patterns (stripes, florals, text), loose-fitting garments, and cases with significant pose differences between person and garment images. The attention visualization confirms that CORAL learns more precise correspondences, with attention weights concentrated on semantically correct regions.

## Implications and Future Directions

CORAL's explicit correspondence alignment approach represents a significant advancement in understanding and improving DiT-based generative models for structured tasks. The framework's success suggests several broader implications:

First, the analysis of attention mechanisms in DiTs provides valuable insights for other correspondence-dependent tasks beyond virtual try-on, such as image editing, style transfer, and multi-modal generation. The finding that query-key matching drives correspondence learning could inform architecture design for these applications.

Second, the correspondence distillation paradigm offers a general strategy for injecting structural priors into diffusion models without requiring architectural modifications. This approach could be extended to incorporate other types of geometric or semantic constraints.

Third, the VLM-based evaluation protocol addresses a critical gap in generative model assessment. Traditional metrics often fail to capture perceptual quality and alignment with human preferences, particularly for detail-oriented tasks. This evaluation approach could be adopted more broadly in the generative modeling community.

Future work could explore adaptive weighting schemes for the loss components, investigate alternative correspondence sources (such as 3D body models or semantic segmentation), and extend the framework to video-based virtual try-on where temporal consistency becomes crucial.

## Takeaways

1. Person-garment correspondence in DiT-based VTON critically depends on precise query-key matching within full 3D attention mechanisms
2. Explicit correspondence alignment through distillation and entropy minimization significantly improves detail preservation compared to implicit learning
3. The correspondence distillation loss effectively transfers knowledge from robust external correspondence models to the attention mechanism
4. Entropy minimization sharpens attention distributions, preventing detail mixing and improving local fidelity
5. VLM-based evaluation protocols better capture human preferences than traditional metrics for perceptual quality assessment
6. The framework achieves consistent improvements in both global shape transfer and fine-grained detail preservation across diverse garment types and poses
7. Ablation studies confirm the complementary nature of the two loss components, with both necessary for optimal performance
:::

:::zh
**论文**: [2602.17636](https://arxiv.org/abs/2602.17636)
**作者**: Jiyoung Kim, Youngjin Shin, Siyoon Jin, Dahyun Chung, Jisu Nam, Tongmin Kim, Jongjae Park, Hyeonwoo Kang, Seungryong Kim
**分类**: cs.CV

## 摘要

虚拟试衣(VTON)系统在保留精细服装细节方面面临重大挑战,特别是在需要建立准确人物-服装对应关系的非配对场景中。本文提出了CORAL(对应关系对齐)框架,这是一个基于扩散Transformer的新型方法,通过显式对应关系对齐来解决这些局限性。作者首先对扩散Transformer中的全3D注意力机制进行了系统分析,揭示了人物-服装对应关系从根本上依赖于注意力层内精确的查询-键匹配。CORAL利用这一洞察,整合了两个互补的损失函数:对应关系蒸馏损失将外部鲁棒匹配与注意力模式对齐,以及熵最小化损失来锐化注意力分布。该框架还引入了基于视觉语言模型的评估协议,以更好地捕捉人类对试衣质量评估的偏好。

## 主要贡献

- 对DiT架构中全3D注意力的系统分析,揭示了查询-键匹配在建立人物-服装对应关系中的关键作用
- CORAL框架通过两个互补的损失组件显式强制对应关系对齐
- 对应关系蒸馏损失将鲁棒外部对应模型的知识迁移到注意力机制
- 熵最小化损失锐化注意力分布以实现更精确的对齐
- 基于VLM的评估协议,相比传统指标更好地反映人类偏好
- 全面的消融研究验证了每个设计选择,并展示了在全局形状迁移和局部细节保留方面的一致性改进

## 方法论与技术路径

CORAL框架建立在扩散Transformer架构之上,专门针对处理人物和服装特征拼接的全3D注意力机制。核心洞察在于,有效的虚拟试衣需要注意力机制隐式学习人物身体部位与服装区域之间的正确对应关系。

对应关系蒸馏损失$\mathcal{L}_{distill}$的工作原理是首先从外部模型(如光流或特征匹配网络)获取鲁棒对应关系,然后鼓励注意力权重与这些对应关系对齐。形式上,给定人物token和服装token之间的注意力权重$A \in \mathbb{R}^{N_p \times N_g}$以及外部对应关系图$C$,该损失最小化$A$和$C$之间的差异。

熵最小化损失$\mathcal{L}_{entropy}$通过鼓励更锐利、更自信的注意力分布来补充这一点。这防止了注意力在单个人物位置对应多个服装区域时变得分散,从而避免模糊或混合的细节。熵项计算为:

$$\mathcal{L}_{entropy} = -\sum_{i,j} A_{ij} \log A_{ij}$$

其中较低的熵表示更集中的注意力模式。

总训练目标将这些损失与标准扩散损失结合:

$$\mathcal{L}_{total} = \mathcal{L}_{diffusion} + \lambda_1 \mathcal{L}_{distill} + \lambda_2 \mathcal{L}_{entropy}$$

## 实验结果与分析

CORAL在多个基准测试中展示了相对于基线DiT-based VTON方法的一致性改进。实验评估了配对和非配对设置,其中非配对场景由于缺乏真实人物-服装对齐而特别具有挑战性。

定量结果显示在标准指标(包括FID、LPIPS和SSIM)上的改进。更重要的是,提出的基于VLM的评估揭示了CORAL更好地符合人类偏好,特别是在保留复杂服装图案、纹理和结构细节(如领口、袖子和下摆)方面。

消融研究系统地验证了每个组件。移除对应关系蒸馏损失会导致服装放置错位和图案扭曲。没有熵最小化,模型会产生更模糊的结果,混合了来自多个服装区域的细节。两种损失的组合产生最佳性能,证明了它们的互补性。

定性比较突出了CORAL在挑战性场景中的优越性:复杂图案(条纹、花卉、文字)、宽松服装,以及人物和服装图像之间存在显著姿态差异的情况。注意力可视化证实CORAL学习了更精确的对应关系,注意力权重集中在语义正确的区域。

## 影响与未来方向

CORAL的显式对应关系对齐方法代表了在理解和改进基于DiT的结构化任务生成模型方面的重大进展。该框架的成功表明了几个更广泛的影响:

首先,对DiT中注意力机制的分析为虚拟试衣之外的其他依赖对应关系的任务提供了宝贵见解,如图像编辑、风格迁移和多模态生成。查询-键匹配驱动对应关系学习的发现可以为这些应用的架构设计提供信息。

其次,对应关系蒸馏范式为在不需要架构修改的情况下向扩散模型注入结构先验提供了通用策略。这种方法可以扩展到整合其他类型的几何或语义约束。

第三,基于VLM的评估协议解决了生成模型评估中的关键差距。传统指标往往无法捕捉感知质量和与人类偏好的对齐,特别是对于注重细节的任务。这种评估方法可以在生成建模社区中更广泛地采用。

未来工作可以探索损失组件的自适应权重方案,研究替代对应关系来源(如3D身体模型或语义分割),并将框架扩展到基于视频的虚拟试衣,其中时间一致性变得至关重要。

## 要点总结

1. 基于DiT的VTON中人物-服装对应关系关键依赖于全3D注意力机制内精确的查询-键匹配
2. 通过蒸馏和熵最小化的显式对应关系对齐相比隐式学习显著改善细节保留
3. 对应关系蒸馏损失有效地将鲁棒外部对应模型的知识迁移到注意力机制
4. 熵最小化锐化注意力分布,防止细节混合并提高局部保真度
5. 基于VLM的评估协议相比传统指标更好地捕捉人类对感知质量评估的偏好
6. 该框架在不同服装类型和姿态下实现了全局形状迁移和精细细节保留的一致性改进
7. 消融研究证实了两个损失组件的互补性,两者对于最优性能都是必需的
:::
