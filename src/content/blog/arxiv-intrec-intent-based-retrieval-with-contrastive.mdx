---
title:
  en: "IntRec: Intent-based Retrieval with Contrastive Refinement"
  zh: "IntRec: 基于意图的对比细化检索框架"
description:
  en: "An interactive object retrieval framework that refines predictions through user feedback using dual memory sets and contrastive alignment, achieving significant improvements on LVIS benchmarks."
  zh: "一个交互式物体检索框架,通过用户反馈使用双记忆集和对比对齐来细化预测,在LVIS基准测试中取得显著改进。"
date: 2026-02-21
tags: ["arxiv", "ai", "cs.cv"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.17639](https://arxiv.org/abs/2602.17639)
**Authors**: Pourya Shamsolmoali, Masoumeh Zareapoor, Eric Granger, Yue Lu
**Categories**: cs.CV

## Abstract

IntRec addresses a fundamental limitation in open-vocabulary object detection: the inability to refine predictions based on user feedback. Traditional detectors operate in a one-shot manner, making them ineffective when queries are ambiguous or scenes contain multiple similar objects. This paper introduces an interactive retrieval framework centered on an Intent State (IS) mechanism that maintains dual memory sets—positive anchors for confirmed cues and negative constraints for rejected hypotheses. Through contrastive alignment, the system ranks candidate objects by maximizing similarity to positive examples while penalizing rejected ones, enabling precise disambiguation in cluttered environments.

## Key Contributions

- Introduction of Intent State (IS), a dual-memory mechanism that tracks both positive anchors (user-confirmed objects) and negative constraints (rejected candidates) throughout the interaction loop
- A contrastive alignment function that dynamically ranks objects by balancing similarity to positive cues against dissimilarity from negative examples
- Demonstration of substantial performance gains with minimal computational overhead: +7.9 AP improvement on LVIS-Ambiguous after single feedback with &lt;30ms latency
- State-of-the-art results on LVIS dataset (35.4 AP), outperforming existing methods like OVMR (+2.3), CoDet (+3.7), and CAKE (+0.5)

## Methodology and Architecture

The IntRec framework operates through an iterative refinement process. At initialization, the system processes a user query through an open-vocabulary detector to generate initial candidate proposals. The Intent State module then maintains two evolving memory banks: $\mathcal{M}^+$ for positive anchors and $\mathcal{M}^-$ for negative constraints.

The core innovation lies in the contrastive alignment function:

$$
s(c_i) = \alpha \cdot \text{sim}(c_i, \mathcal{M}^+) - \beta \cdot \text{sim}(c_i, \mathcal{M}^-)
$$

where $c_i$ represents a candidate object, $\text{sim}(\cdot)$ computes feature similarity, and $\alpha, \beta$ are weighting hyperparameters. This formulation explicitly models user intent by simultaneously attracting candidates toward confirmed examples and repelling them from rejected ones.

When users provide feedback—either confirming a correct detection or rejecting an incorrect one—the system updates the respective memory bank and recomputes rankings. This iterative process continues until the user's target object is successfully retrieved or a maximum interaction limit is reached.

## Experimental Results and Analysis

On the LVIS dataset, IntRec achieves 35.4 AP in the interactive setting, establishing new state-of-the-art performance. The improvements are particularly pronounced in challenging scenarios: on LVIS-Ambiguous, a benchmark specifically designed to test disambiguation capabilities, the framework shows a remarkable +7.9 AP gain over its one-shot baseline after just a single corrective feedback iteration.

The efficiency metrics are equally impressive. Each interaction cycle adds less than 30ms of latency, making the system practical for real-time applications. This minimal overhead stems from the efficient memory update mechanism and the lightweight nature of the contrastive alignment computation.

Ablation studies reveal that both memory components are essential: removing positive anchors reduces performance by 4.2 AP, while eliminating negative constraints causes a 3.8 AP drop. The contrastive formulation outperforms alternative ranking strategies, including pure similarity-based and attention-based approaches.

## Implications and Future Directions

IntRec represents a paradigm shift from static to interactive object detection. By incorporating user feedback into the retrieval loop, the framework addresses real-world scenarios where initial queries may be ambiguous or underspecified. The dual-memory architecture provides a principled way to accumulate knowledge across interactions, effectively learning user intent on-the-fly without requiring additional training data.

The minimal latency overhead suggests potential for deployment in interactive applications such as robotic manipulation, augmented reality interfaces, and assistive technologies. The framework's modular design also allows integration with various backbone detectors, making it adaptable to future advances in open-vocabulary detection.

Future work could explore multi-modal feedback mechanisms (e.g., pointing gestures, verbal corrections), extend the approach to video sequences where temporal consistency matters, and investigate how the Intent State could be personalized to individual user preferences over longer interaction histories.

## Takeaways

1. Interactive refinement through user feedback significantly outperforms one-shot detection, especially in ambiguous scenarios (+7.9 AP on LVIS-Ambiguous)
2. Dual-memory architecture (positive anchors + negative constraints) provides a principled framework for modeling user intent
3. Contrastive alignment enables fine-grained disambiguation by simultaneously maximizing similarity to confirmed objects and minimizing similarity to rejected ones
4. Real-time performance is maintained with &lt;30ms latency per interaction, making the approach practical for interactive applications
5. The framework achieves state-of-the-art results on LVIS (35.4 AP) while remaining agnostic to the underlying detection backbone
:::

:::zh
**论文**: [2602.17639](https://arxiv.org/abs/2602.17639)
**作者**: Pourya Shamsolmoali, Masoumeh Zareapoor, Eric Granger, Yue Lu
**分类**: cs.CV

## 摘要

IntRec解决了开放词汇物体检测中的一个根本性限制:无法根据用户反馈细化预测结果。传统检测器以单次方式运行,在查询模糊或场景包含多个相似物体时效果不佳。本文提出了一个交互式检索框架,其核心是意图状态(IS)机制,该机制维护双记忆集——用于确认线索的正锚点和用于拒绝假设的负约束。通过对比对齐,系统通过最大化与正样本的相似性同时惩罚被拒绝的样本来对候选物体进行排序,从而在杂乱环境中实现精确消歧。

## 主要贡献

- 提出意图状态(IS)机制,这是一种双记忆机制,在整个交互循环中跟踪正锚点(用户确认的物体)和负约束(被拒绝的候选)
- 设计对比对齐函数,通过平衡与正线索的相似性和与负样本的差异性来动态排序物体
- 展示了以最小计算开销获得的显著性能提升:在LVIS-Ambiguous上单次反馈后提升+7.9 AP,延迟&lt;30ms
- 在LVIS数据集上达到最先进结果(35.4 AP),超越OVMR(+2.3)、CoDet(+3.7)和CAKE(+0.5)等现有方法

## 方法论与架构设计

IntRec框架通过迭代细化过程运行。在初始化阶段,系统通过开放词汇检测器处理用户查询以生成初始候选提案。意图状态模块随后维护两个演化的记忆库:$\mathcal{M}^+$用于正锚点,$\mathcal{M}^-$用于负约束。

核心创新在于对比对齐函数:

$$
s(c_i) = \alpha \cdot \text{sim}(c_i, \mathcal{M}^+) - \beta \cdot \text{sim}(c_i, \mathcal{M}^-)
$$

其中$c_i$表示候选物体,$\text{sim}(\cdot)$计算特征相似度,$\alpha, \beta$是权重超参数。该公式通过同时将候选吸引向确认样本并将其排斥离被拒绝样本来显式建模用户意图。

当用户提供反馈——确认正确检测或拒绝错误检测时,系统更新相应的记忆库并重新计算排序。这个迭代过程持续进行,直到成功检索到用户的目标物体或达到最大交互限制。

## 实验结果与分析

在LVIS数据集上,IntRec在交互设置下达到35.4 AP,建立了新的最先进性能。在挑战性场景中改进尤为显著:在专门设计用于测试消歧能力的LVIS-Ambiguous基准上,该框架在仅一次纠正反馈迭代后就显示出显著的+7.9 AP增益,相比其单次基线。

效率指标同样令人印象深刻。每个交互周期增加的延迟不到30ms,使系统适用于实时应用。这种最小开销源于高效的记忆更新机制和对比对齐计算的轻量级特性。

消融研究表明两个记忆组件都是必不可少的:移除正锚点会降低4.2 AP的性能,而消除负约束会导致3.8 AP的下降。对比公式优于替代排序策略,包括纯基于相似性和基于注意力的方法。

## 影响与未来方向

IntRec代表了从静态到交互式物体检测的范式转变。通过将用户反馈纳入检索循环,该框架解决了初始查询可能模糊或未充分指定的真实场景。双记忆架构提供了一种原则性方法来跨交互累积知识,有效地即时学习用户意图而无需额外的训练数据。

最小的延迟开销表明在机器人操作、增强现实界面和辅助技术等交互式应用中部署的潜力。该框架的模块化设计还允许与各种骨干检测器集成,使其能够适应开放词汇检测的未来进展。

未来工作可以探索多模态反馈机制(如指向手势、口头纠正),将方法扩展到时间一致性重要的视频序列,并研究如何在更长的交互历史中将意图状态个性化到个人用户偏好。

## 要点总结

1. 通过用户反馈的交互式细化显著优于单次检测,特别是在模糊场景中(LVIS-Ambiguous上+7.9 AP)
2. 双记忆架构(正锚点+负约束)为建模用户意图提供了原则性框架
3. 对比对齐通过同时最大化与确认物体的相似性和最小化与被拒绝物体的相似性来实现细粒度消歧
4. 每次交互延迟&lt;30ms,保持实时性能,使该方法适用于交互式应用
5. 该框架在LVIS上达到最先进结果(35.4 AP),同时对底层检测骨干保持不可知性
:::
