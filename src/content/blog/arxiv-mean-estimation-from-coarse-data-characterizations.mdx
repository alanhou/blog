---
title:
  en: "Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms"
  zh: "粗粒度数据的均值估计:可识别性刻画与高效算法"
description:
  en: "This paper resolves fundamental questions about when Gaussian means can be identified from coarsely observed data and provides polynomial-time algorithms for efficient estimation under convex partitions."
  zh: "本文解决了从粗粒度观测数据中识别高斯均值的基本问题,并在凸分割条件下提供了多项式时间的高效估计算法。"
date: 2026-02-28
tags: ["arxiv", "ai", "cs.lg", "cs.ds", "math.st", "stat.ml"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.23341](https://arxiv.org/abs/2602.23341)
**Authors**: Alkis Kalavasis, Anay Mehrotra, Manolis Zampetakis, Felix Zhou, Ziyu Zhu
**Categories**: cs.LG, cs.DS, math.ST, stat.ML

## Abstract

This paper addresses the problem of estimating the mean of a Gaussian distribution when observations are coarse—that is, when each sample $x$ drawn from a $d$-dimensional Gaussian with identity covariance is only revealed through the partition element containing it. The authors resolve two fundamental open questions: (1) providing a complete characterization of when the mean is identifiable under convex partitions, and (2) establishing that computationally efficient estimation is possible whenever the mean is identifiable. The work introduces polynomial-time algorithms that achieve sample complexity matching information-theoretic lower bounds, bridging the gap between statistical identifiability and computational tractability in coarse data settings.

## Key Contributions

- Complete characterization of identifiability for Gaussian mean estimation under convex partitions, resolving an open problem from prior work
- Polynomial-time algorithms for mean estimation that are both sample-efficient and computationally tractable when identifiability holds
- Tight information-theoretic lower bounds showing that the proposed algorithms achieve optimal sample complexity
- Extension of results to handle approximate identifiability and robustness guarantees
- Novel technical tools connecting convex geometry, optimization, and statistical estimation theory

## Identifiability Characterization

The paper's first major contribution is a precise characterization of when the mean $\mu$ of a Gaussian distribution is identifiable from coarse observations. Given a partition $\mathcal{P}$ of $\mathbb{R}^d$ into convex sets, identifiability depends on the geometric relationship between $\mu$ and the partition structure.

The authors show that identifiability is equivalent to a geometric condition: the mean $\mu$ must be the unique point that maximizes a certain potential function derived from the partition geometry. Specifically, for each partition element $P \in \mathcal{P}$, the probability mass $\Pr[x \in P]$ when $x \sim \mathcal{N}(\mu, I)$ must uniquely determine $\mu$.

This characterization is both necessary and sufficient, providing a complete answer to when mean estimation is theoretically possible. The geometric perspective reveals that identifiability fails precisely when multiple means would produce indistinguishable coarse observation distributions—a situation that occurs when the partition lacks sufficient "resolution" relative to the Gaussian's spread.

## Algorithmic Framework

Building on the identifiability characterization, the paper develops polynomial-time algorithms for mean estimation. The key algorithmic insight is to formulate estimation as a convex optimization problem that can be solved efficiently.

The algorithm operates by constructing an empirical loss function based on observed partition memberships. Given $n$ coarse samples (each revealing only which partition element contains the true sample), the estimator solves:

$$\hat{\mu} = \arg\min_{\mu \in \mathbb{R}^d} \sum_{i=1}^n \ell(P_i, \mu)$$

where $P_i$ is the observed partition element for sample $i$, and $\ell$ is a carefully designed loss function that exploits the convex geometry of the partition.

The authors prove that this optimization can be solved in polynomial time using standard convex programming techniques, and that the resulting estimator achieves sample complexity $O(d/\epsilon^2)$ to estimate $\mu$ within $\ell_2$ error $\epsilon$—matching information-theoretic lower bounds up to constant factors.

## Technical Innovation and Analysis

The technical analysis combines tools from several areas. The proof of identifiability uses convex geometry to characterize when the mapping from means to observation distributions is injective. The algorithmic analysis employs concentration inequalities and uniform convergence arguments to bound estimation error.

A particularly elegant aspect is the connection to optimal transport theory. The authors show that the estimation problem can be viewed through the lens of Wasserstein distances between probability measures, providing both intuition and technical leverage for the analysis.

The paper also addresses robustness: when identifiability holds only approximately (e.g., when two different means produce nearly identical observation distributions), the algorithms still provide meaningful estimates with gracefully degrading guarantees. This robustness is crucial for practical applications where perfect identifiability may not hold.

## Takeaways

1. Gaussian mean estimation from coarse data is computationally tractable whenever it is information-theoretically possible under convex partitions, closing the gap between statistical and computational feasibility.

2. The identifiability of the mean can be characterized geometrically through the relationship between the unknown mean and the partition structure, providing a practical test for when estimation is possible.

3. Polynomial-time algorithms achieve optimal sample complexity $O(d/\epsilon^2)$, matching information-theoretic lower bounds and demonstrating that no computational-statistical tradeoff exists in this setting.

4. The framework extends beyond exact identifiability to handle approximate settings with robustness guarantees, making it applicable to realistic scenarios with imperfect partition structures.

5. The techniques developed—connecting convex optimization, optimal transport, and statistical estimation—may have broader applications to other problems involving partial or coarse observations.
:::

:::zh
**论文**: [2602.23341](https://arxiv.org/abs/2602.23341)
**作者**: Alkis Kalavasis, Anay Mehrotra, Manolis Zampetakis, Felix Zhou, Ziyu Zhu
**分类**: cs.LG, cs.DS, math.ST, stat.ML

## 摘要

本文研究了在观测数据为粗粒度时估计高斯分布均值的问题——即当从具有单位协方差的$d$维高斯分布中抽取的样本$x$仅通过包含它的分割元素被揭示时。作者解决了两个基本的开放问题:(1)给出了在凸分割下均值可识别性的完整刻画,(2)证明了只要均值可识别,就存在计算高效的估计算法。该工作引入了多项式时间算法,其样本复杂度达到信息论下界,在粗粒度数据设置中弥合了统计可识别性与计算可行性之间的差距。

## 主要贡献

- 完整刻画了凸分割下高斯均值估计的可识别性条件,解决了先前工作中的开放问题
- 提出了多项式时间算法,在可识别性成立时同时实现样本高效性和计算可行性
- 建立了紧致的信息论下界,证明所提算法达到最优样本复杂度
- 将结果扩展到近似可识别性和鲁棒性保证
- 发展了连接凸几何、优化和统计估计理论的新技术工具

## 可识别性刻画

论文的第一个主要贡献是精确刻画了何时高斯分布的均值$\mu$可以从粗粒度观测中识别。给定$\mathbb{R}^d$的凸集分割$\mathcal{P}$,可识别性取决于$\mu$与分割结构之间的几何关系。

作者证明可识别性等价于一个几何条件:均值$\mu$必须是唯一最大化某个由分割几何导出的势函数的点。具体而言,对于每个分割元素$P \in \mathcal{P}$,当$x \sim \mathcal{N}(\mu, I)$时的概率质量$\Pr[x \in P]$必须唯一确定$\mu$。

这一刻画既是必要的也是充分的,完整回答了何时均值估计在理论上是可能的。几何视角揭示了可识别性失效恰好发生在多个均值会产生无法区分的粗粒度观测分布时——这种情况出现在分割相对于高斯分布的扩散缺乏足够"分辨率"时。

## 算法框架

基于可识别性刻画,论文开发了均值估计的多项式时间算法。关键的算法洞察是将估计问题表述为可以高效求解的凸优化问题。

算法通过基于观测到的分割成员关系构造经验损失函数来运作。给定$n$个粗粒度样本(每个仅揭示包含真实样本的分割元素),估计器求解:

$$\hat{\mu} = \arg\min_{\mu \in \mathbb{R}^d} \sum_{i=1}^n \ell(P_i, \mu)$$

其中$P_i$是样本$i$观测到的分割元素,$\ell$是精心设计的损失函数,利用了分割的凸几何性质。

作者证明这个优化问题可以使用标准凸规划技术在多项式时间内求解,并且得到的估计器达到样本复杂度$O(d/\epsilon^2)$以在$\ell_2$误差$\epsilon$内估计$\mu$——在常数因子内匹配信息论下界。

## 技术创新与分析

技术分析结合了多个领域的工具。可识别性的证明使用凸几何来刻画从均值到观测分布的映射何时是单射的。算法分析采用集中不等式和一致收敛论证来界定估计误差。

一个特别优雅的方面是与最优传输理论的联系。作者表明估计问题可以通过概率测度之间的Wasserstein距离来理解,为分析提供了直觉和技术杠杆。

论文还处理了鲁棒性问题:当可识别性仅近似成立时(例如,两个不同的均值产生几乎相同的观测分布),算法仍然提供有意义的估计,保证优雅地退化。这种鲁棒性对于完美可识别性可能不成立的实际应用至关重要。

## 要点总结

1. 在凸分割条件下,只要信息论上可行,从粗粒度数据进行高斯均值估计就是计算可行的,弥合了统计可行性与计算可行性之间的差距。

2. 均值的可识别性可以通过未知均值与分割结构之间的几何关系来刻画,为判断何时估计可能提供了实用测试。

3. 多项式时间算法达到最优样本复杂度$O(d/\epsilon^2)$,匹配信息论下界,证明在此设置中不存在计算-统计权衡。

4. 该框架超越了精确可识别性,能够处理具有鲁棒性保证的近似设置,使其适用于具有不完美分割结构的现实场景。

5. 所发展的技术——连接凸优化、最优传输和统计估计——可能对涉及部分或粗粒度观测的其他问题具有更广泛的应用价值。
:::
