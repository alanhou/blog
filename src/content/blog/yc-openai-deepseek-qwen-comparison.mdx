---
title:
  en: "Notes: OpenAI vs. DeepSeek vs. Qwen - Comparing Open Source LLM Architectures"
  zh: "笔记：OpenAI vs. DeepSeek vs. Qwen - 开源 LLM 架构对比"
description:
  en: "Y Combinator's technical deep dive comparing GPT OSS, DeepSeek V3, and Qwen 3 architectures, training methods, and design choices"
  zh: "Y Combinator 技术深度解析：对比 GPT OSS、DeepSeek V3 和 Qwen 3 的架构、训练方法和设计选择"
date: 2025-08-29
tags: ["ycombinator", "ai", "openai", "deepseek", "qwen", "llm", "architecture"]
image: "https://i2.ytimg.com/vi/raTbhtKZTZA/hqdefault.jpg"
---

import YouTube from '../../components/YouTube.astro';

<YouTube id="raTbhtKZTZA" title="OpenAI vs. Deepseek vs. Qwen: Comparing Open Source LLM Architectures" />

:::en
This post summarizes Y Combinator's technical comparison of three major open source LLM architectures: OpenAI's GPT OSS, DeepSeek V3, and Alibaba's Qwen 3.

## GPT OSS: OpenAI's Open Weights Model

OpenAI recently released GPT OSS, its first open weights model since GPT-2 in 2019. It's one of the highest profile open source model launches since DeepSeek R1 made waves in January.

### Architecture Overview

GPT OSS is a **Mixture of Experts (MoE)** model available in two sizes:
- **120 billion parameters** (5.1B activated per token)
- **20 billion parameters** (3.6B activated per token)

Each token activates the **top 4 experts**, meaning only a portion of total parameters are used at any given time. This allows for efficient inference without sacrificing the benefits of a larger model.

### Key Technical Features

As a decoder-only transformer, GPT OSS incorporates modern LLM features:

- **Grouped Query Attention (GQA)**: Multiple query heads share the same key-value pairs to reduce memory use and speed up inference
- **SwiGLU Activations**: More nuanced transformations than simpler activations like ReLU in feed-forward layers
- **Rotary Positional Embeddings (RoPE)**: Encodes token position directly into the attention mechanism to support longer contexts
- **RMS Norm with Pre-normalization**: Scales inputs by their root mean square for more stable training

### Context Window

GPT OSS achieves a **131,000 token context window** by applying YaRN scaling during pre-training rather than as an inference-time adjustment. This means the model's weights have learned to work natively with long contexts.

### Tokenizer and Training Data

- Uses OpenAI's open-source **O200K Harmony tokenizer** (byte pair encoding with over 200,000 tokens)
- Trained on a text-only corpus in the **trillions of tokens**
- Focus on STEM, coding, and general knowledge
- Harmful content filtered out for safety

### Release Format

- Released in **quantized format by default** for deployment on modest hardware
- Can run on consumer-grade GPUs and laptops
- No unquantized version available
- Underwent substantial post-training for safety and alignment

## Qwen 3: Alibaba's Model Family

Qwen 3, developed by Alibaba Cloud, dropped in April with benchmark scores rivaling DeepSeek V3 and Llama 4.

### Model Variants

**Dense Models** (7 size classes):
- Range from **0.6 billion to 32 billion parameters**
- Activate all parameters for each query

**Mixture of Experts Models** (2 sizes):
- **30 billion parameters**
- **235 billion parameters**
- 128 total experts, 8 activated per token
- MoE models match dense model performance with only 1/5 as many active parameters

### Architecture

Qwen 3 dense models are similar to Qwen 2.5, incorporating:
- Group Query Attention
- SwiGLU
- RoPE
- RMS Norm

**Key Innovation - QK Norm**: Replaces QKV bias (static offset) with a normalization step that dynamically rescales query and key vectors to maintain constant magnitudes, keeping attention scores stable at scale.

### Training Pipeline

**Pre-training (3 stages)**:

1. **General Stage**: 30+ trillion tokens covering 119 languages at 4,096 sequence length
2. **Reasoning Stage**: Additional 5 trillion higher-quality tokens featuring STEM reasoning and coding problems
3. **Long Context Stage**: Extended to 32,000+ tokens using ABF, YaRN, and dual chunk attention

Total: **36 trillion pre-training tokens** (twice as many as Qwen 2.5)

Qwen 3 also uses Qwen 2.5 models to generate **trillions of tokens of synthetic data** in formats like textbooks, instructions, and code snippets.

### Post-Training Pipeline (4 steps)

Goals: Give users control over reasoning depth and enable efficient distillation to smaller models.

1. **Long Chain of Thought Cold Start**: Curated dataset of challenging reasoning problems from math, logic, and STEM with verifiable answers
2. **Reasoning RL Stage**: Uses GRPO (originally developed by DeepSeek) on roughly 4,000 query-verifier pairs
3. **Thinking Mode Fusion**: Key Qwen 3 innovation - integrates reasoning and non-reasoning into a single model, letting users switch modes without changing models
4. **General RL**: Broadens capabilities in instruction following, formatting, preference alignment, tool use, and specialized scenarios

**Strong-to-Weak Distillation**: Allows training smaller models from larger ones.

## DeepSeek V3: The Efficiency Pioneer

Released in December, DeepSeek V3 was one of the most ambitious open source LLMs from a major lab.

### Scale and Architecture

- **671 billion total parameters**
- **37 billion activated per token**
- Mixture of Experts architecture
- Designed for efficiency as much as capability

### Key Innovation: Multi-head Latent Attention (MLA)

Unlike GPT OSS and Qwen 3 which use GQA, DeepSeek V3 uses **MLA**:
- Compresses keys and values into a smaller latent space before caching
- Decompresses them during inference
- More complex to implement but delivers greater memory savings
- Better modeling performance than GQA, especially in huge long-context models

### Training Optimizations

- **Native 8-bit training** (rather than 16 or 32-bit) - huge unlock for cutting training costs
- Hardware and algorithmic optimizations throughout

### DeepSeek V3.1 Update

The newly released V3.1 builds on V3 with:
- Two-phase long context training approach
- Hybrid thinking mode (switch between reasoning-heavy and lightweight inference)
- Improved tool use and agent performance
- Same core architecture, stronger reasoning and smarter tool use

## Comparing Context Extension Approaches

**YaRN (Yet Another RoPE Extension)** stretches rotary positional embeddings to handle longer sequences than originally trained on.

Each model uses YaRN differently:

| Model | Approach | Result |
|-------|----------|--------|
| **GPT OSS** | Applied from pre-training | Born with 131K context ability |
| **DeepSeek** | Staged fine-tuning (32K → 128K) | Trained into it step by step |
| **Qwen** | Fine-tune to 32K, then inference-time YaRN scaling (4x) | Pushes limits without extra retraining |

## Key Observations

### Empirical vs. First Principles

These papers read as **empirical findings** rather than theoretical derivations:
- Each lab describes what works well for them
- Almost no one gives first-principles justification for why one tool is better
- Very different from math or theoretical physics which derive results from axioms

### Surprising Convergence

Despite using often very different techniques:
- Similar topline benchmark statistics
- Broadly same tools (attention mechanisms, activation functions, positional embeddings)
- Different training methods leading to similar results

### Reinforcement Learning's Role

All major models heavily use RL in post-training and reasoning:
- Surprisingly small data requirements (just 4,000 pairs for Qwen's reasoning RL)
- Fascinating efficiency gains

### The Data Set Moat

- Enormous work happening behind the scenes in data set engineering
- Very opaque what differences exist between labs
- Probably a significant aspect of the competitive moat
- Makes replication difficult even with open weights

## Takeaways

When reading these papers:
- Don't focus too much on benchmark performance or topline stats like context size
- Look at the **specific methods** labs use to achieve results
- Peek under the hood to find nuanced differences
- Use this as a framework for understanding future open source releases

Other notable models not covered: Kimi K2, Google Gemma 3, and many more with their own interesting design choices.
:::

:::zh
本文总结了 Y Combinator 对三大开源 LLM 架构的技术对比：OpenAI 的 GPT OSS、DeepSeek V3 和阿里巴巴的 Qwen 3。

## GPT OSS：OpenAI 的开放权重模型

OpenAI 最近发布了 GPT OSS，这是自 2019 年 GPT-2 以来的首个开放权重模型。这是自 DeepSeek R1 在一月份引起轰动以来最受关注的开源模型发布之一。

### 架构概述

GPT OSS 是一个**混合专家（MoE）**模型，有两种规模：
- **1200 亿参数**（每个 token 激活 51 亿）
- **200 亿参数**（每个 token 激活 36 亿）

每个 token 激活**前 4 个专家**，意味着任何时候只使用总参数的一部分。这允许高效推理而不牺牲大模型的优势。

### 关键技术特性

作为仅解码器的 Transformer，GPT OSS 融合了现代 LLM 特性：

- **分组查询注意力（GQA）**：多个查询头共享相同的键值对，减少内存使用并加速推理
- **SwiGLU 激活函数**：在前馈层中比 ReLU 等简单激活函数提供更细腻的变换
- **旋转位置编码（RoPE）**：将 token 位置直接编码到注意力机制中以支持更长上下文
- **RMS Norm 预归一化**：通过均方根缩放输入以获得更稳定的训练

### 上下文窗口

GPT OSS 通过在预训练期间（而非推理时）应用 YaRN 缩放，实现了 **131,000 token 的上下文窗口**。这意味着模型权重已经学会原生处理长上下文。

### 分词器和训练数据

- 使用 OpenAI 的开源 **O200K Harmony 分词器**（字节对编码，超过 200,000 个 token）
- 在**数万亿 token** 的纯文本语料上训练
- 专注于 STEM、编程和通用知识
- 过滤有害内容以确保安全

### 发布格式

- 默认以**量化格式**发布，可在普通硬件上部署
- 可在消费级 GPU 和笔记本电脑上运行
- 没有非量化版本
- 经过大量安全和对齐的后训练

## Qwen 3：阿里巴巴的模型家族

Qwen 3 由阿里云开发，于四月发布，基准测试分数可与 DeepSeek V3 和 Llama 4 媲美。

### 模型变体

**稠密模型**（7 种规模）：
- 从 **6 亿到 320 亿参数**
- 每次查询激活所有参数

**混合专家模型**（2 种规模）：
- **300 亿参数**
- **2350 亿参数**
- 共 128 个专家，每个 token 激活 8 个
- MoE 模型仅用 1/5 的激活参数就能匹配稠密模型性能

### 架构

Qwen 3 稠密模型与 Qwen 2.5 类似，包含：
- 分组查询注意力
- SwiGLU
- RoPE
- RMS Norm

**关键创新 - QK Norm**：用动态重新缩放查询和键向量的归一化步骤替代 QKV 偏置（静态偏移），保持恒定幅度，使注意力分数在大规模时保持稳定。

### 训练流程

**预训练（3 个阶段）**：

1. **通用阶段**：30+ 万亿 token，覆盖 119 种语言，序列长度 4,096
2. **推理阶段**：额外 5 万亿高质量 token，包含 STEM 推理和编程问题
3. **长上下文阶段**：使用 ABF、YaRN 和双块注意力扩展到 32,000+ token

总计：**36 万亿预训练 token**（是 Qwen 2.5 的两倍）

Qwen 3 还使用 Qwen 2.5 模型生成**数万亿 token 的合成数据**，格式包括教科书、指令和代码片段。

### 后训练流程（4 步）

目标：让用户控制推理深度，并实现向小模型的高效蒸馏。

1. **长思维链冷启动**：精选的数学、逻辑和 STEM 挑战性推理问题数据集，带有可验证答案
2. **推理 RL 阶段**：使用 GRPO（最初由 DeepSeek 开发）在约 4,000 个查询-验证器对上训练
3. **思考模式融合**：Qwen 3 的关键创新 - 将推理和非推理整合到单一模型中，让用户无需切换模型即可切换模式
4. **通用 RL**：扩展指令遵循、格式化、偏好对齐、工具使用和专业场景的能力

**强到弱蒸馏**：允许从大模型训练小模型。

## DeepSeek V3：效率先驱

DeepSeek V3 于十二月发布，是主要实验室推出的最具雄心的开源 LLM 之一。

### 规模和架构

- **6710 亿总参数**
- **每个 token 激活 370 亿**
- 混合专家架构
- 设计上同时注重效率和能力

### 关键创新：多头潜在注意力（MLA）

与使用 GQA 的 GPT OSS 和 Qwen 3 不同，DeepSeek V3 使用 **MLA**：
- 在缓存前将键和值压缩到更小的潜在空间
- 在推理时解压缩
- 实现更复杂但内存节省更大
- 比 GQA 有更好的建模性能，特别是在大型长上下文模型中

### 训练优化

- **原生 8 位训练**（而非 16 或 32 位）- 大幅降低训练成本
- 全程硬件和算法优化

### DeepSeek V3.1 更新

新发布的 V3.1 在 V3 基础上增加了：
- 两阶段长上下文训练方法
- 混合思考模式（在重推理和轻量推理之间切换）
- 改进的工具使用和代理性能
- 相同核心架构，更强推理和更智能的工具使用

## 上下文扩展方法对比

**YaRN（又一个 RoPE 扩展）**拉伸旋转位置编码以处理比原始训练更长的序列。

每个模型使用 YaRN 的方式不同：

| 模型 | 方法 | 结果 |
|------|------|------|
| **GPT OSS** | 从预训练开始应用 | 天生具有 131K 上下文能力 |
| **DeepSeek** | 分阶段微调（32K → 128K） | 逐步训练获得 |
| **Qwen** | 微调到 32K，然后推理时 YaRN 缩放（4 倍） | 无需额外重训练即可突破限制 |

## 关键观察

### 经验性 vs. 第一性原理

这些论文读起来像是**经验性发现**而非理论推导：
- 每个实验室描述对他们有效的组合
- 几乎没有人给出为什么一个工具比另一个更好的第一性原理解释
- 与从公理推导结果的数学或理论物理非常不同

### 令人惊讶的趋同

尽管使用了非常不同的技术：
- 相似的顶线基准统计
- 大致相同的工具（注意力机制、激活函数、位置编码）
- 不同的训练方法导致相似的结果

### 强化学习的作用

所有主要模型都在后训练和推理中大量使用 RL：
- 令人惊讶的小数据需求（Qwen 的推理 RL 仅需 4,000 对）
- 令人着迷的效率提升

### 数据集护城河

- 数据集工程背后有大量工作
- 各实验室之间的差异非常不透明
- 可能是竞争护城河的重要组成部分
- 即使有开放权重也难以复制

## 要点总结

阅读这些论文时：
- 不要过于关注基准性能或上下文大小等顶线统计
- 关注实验室用于实现结果的**具体方法**
- 深入了解细微差异
- 将此作为理解未来开源发布的框架

其他未涵盖的著名模型：Kimi K2、Google Gemma 3 等，都有各自有趣的设计选择。
:::
