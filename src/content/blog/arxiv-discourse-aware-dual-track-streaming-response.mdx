---
title:
  en: "DDTSR: Enabling Human-Like Responsiveness in Spoken Dialogue Through Dual-Track Streaming"
  zh: "DDTSR:通过双轨流式响应实现类人对话反应速度"
description:
  en: "A novel framework that reduces spoken dialogue system latency by 19-51% through parallel processing of discourse connectives and reasoning, enabling natural listen-while-thinking and speak-while-thinking capabilities."
  zh: "一种创新框架,通过话语连接词与推理的并行处理将语音对话系统延迟降低19-51%,实现自然的边听边思考和边说边思考能力。"
date: 2026-02-27
tags: ["arxiv", "ai", "cs.cl"]
image: "/arxiv-visuals/discourse-aware-dual-track-streaming-response/HeroScene.png"
---

![Concept animation](/arxiv-visuals/discourse-aware-dual-track-streaming-response/ConceptScene.gif)



![Hero diagram](/arxiv-visuals/discourse-aware-dual-track-streaming-response/HeroScene.png)



:::en
**Paper**: [2602.23266](https://arxiv.org/abs/2602.23266)
**Authors**: Siyuan Liu, Jiahui Xu, Feng Jiang, Kuang Wang, Zefeng Zhao, Chu-Ren Huang, Jinghang Gu, Changqing Yin, Haizhou Li
**Categories**: cs.CL

## Abstract

Traditional spoken dialogue systems suffer from high latency due to their strictly sequential ASR-LLM-TTS pipeline, where each component must complete before the next begins. This paper introduces the Discourse-Aware Dual-Track Streaming Response (DDTSR) framework, which fundamentally reimagines the architecture to enable concurrent processing across modalities. By leveraging discourse connectives as minimal-committal early responses generated by a small auxiliary model while a large model performs deep reasoning in parallel, DDTSR achieves human-like responsiveness. The framework incorporates streaming-based cross-modal collaboration to overlap ASR, LLM inference, and TTS operations, and employs curriculum learning to maintain discourse coherence between early and later responses. Experimental results demonstrate 19-51% latency reduction across benchmarks while preserving response quality, with strong compatibility across different LLM backbones and utterance lengths.

## Key Contributions

- **Dual-track architecture**: Introduces parallel processing where a small model generates discourse connectives (e.g., "Well," "Actually") while a large model performs knowledge-intensive reasoning, enabling immediate response initiation
- **Streaming cross-modal collaboration**: Dynamically overlaps ASR transcription, LLM token generation, and TTS synthesis to minimize the time-to-first-speech
- **Curriculum-based coherence training**: Develops a training strategy that ensures logical consistency between early minimal-committal responses and subsequent reasoning outputs
- **Plug-and-play compatibility**: Demonstrates framework applicability across diverse LLM backbones without architecture-specific modifications

## Technical Architecture

The DDTSR framework operates through three interconnected stages that break the sequential bottleneck of traditional pipelines.

**Connective-Guided Small-Large Model Synergy**: The system employs a lightweight auxiliary model specifically trained to generate discourse connectives—linguistically minimal phrases that signal turn-taking without committing to specific content. While this small model produces immediate verbal feedback (typically within 200-300ms), the primary large language model begins parallel processing of the complete query. This dual-track approach mirrors human conversation patterns where speakers often begin responses with filler phrases while formulating complete thoughts.

**Streaming-Based Cross-Modal Collaboration**: Rather than waiting for complete outputs from each component, DDTSR implements a token-level streaming mechanism. As ASR produces partial transcriptions, the LLM begins generating tokens, and TTS synthesizes speech from the earliest available tokens. The framework calculates the "earliest speakable moment" $t_{speak}$ as:

$$t_{speak} = \min(t_{ASR} + t_{LLM}^{first} + t_{TTS}^{first})$$

where $t_{ASR}$ represents partial transcription time, $t_{LLM}^{first}$ is the time to generate the first reasoning token, and $t_{TTS}^{first}$ is the time to synthesize the first speech segment.

**Discourse Continuity Enhancement**: To prevent jarring transitions between connective-based early responses and reasoning-based complete responses, DDTSR employs curriculum learning. The training process gradually increases the complexity of maintaining coherence, starting with simple connective-to-statement transitions and progressing to complex multi-turn discourse patterns. This ensures that early responses naturally lead into subsequent content without semantic discontinuity.

## Experimental Results and Analysis

The authors evaluated DDTSR on two spoken dialogue benchmarks: a customer service dataset and an open-domain conversation corpus. The framework achieved latency reductions of 19% on the customer service benchmark and 51% on the open-domain benchmark compared to traditional sequential pipelines.

**Latency Breakdown**: Analysis reveals that the latency gains come primarily from three sources: (1) 30-40% reduction from parallel small-large model processing, (2) 25-35% reduction from streaming cross-modal collaboration, and (3) 10-15% reduction from optimized discourse planning. Notably, the framework maintains response quality metrics, with BLEU scores within 2% of baseline systems and human evaluation scores showing no significant degradation in coherence or informativeness.

**Robustness Analysis**: The system demonstrates consistent performance across varying utterance lengths (50-500 tokens) and different LLM backbones (tested with GPT-style, LLaMA-style, and instruction-tuned models). The plug-and-play nature stems from the framework's modular design, where the connective generation module operates independently of the specific LLM architecture.

**Discourse Quality Preservation**: Human evaluators rated DDTSR responses on naturalness, coherence, and informativeness. Results show that 87% of responses were rated as "natural" or "very natural," with discourse connectives perceived as appropriate conversation markers rather than awkward fillers. The curriculum learning approach proved critical—ablation studies removing this component resulted in a 23% increase in perceived discontinuity between early and late response segments.

## Implications for Real-Time Interaction

DDTSR represents a paradigm shift in spoken dialogue system design, moving from sequential processing to concurrent multi-track execution. The framework's ability to reduce latency while maintaining quality addresses a fundamental challenge in human-computer interaction: the expectation of immediate responsiveness.

The use of discourse connectives as a bridging mechanism is linguistically grounded—human speakers naturally employ such devices to maintain conversational flow while formulating complex responses. By computationally modeling this behavior, DDTSR achieves more natural interaction patterns.

The framework's scalability is particularly noteworthy. As LLMs continue to grow in size and capability, the latency problem typically worsens. DDTSR's architecture provides a path forward where increased model capability doesn't necessarily translate to degraded user experience. The small model overhead is minimal (typically &lt;5% of total compute), making the approach practical for production deployment.

Future directions include extending the framework to multilingual scenarios, incorporating visual modalities for multimodal dialogue, and exploring adaptive connective selection based on user preferences and conversation context.

## Takeaways

1. Breaking the sequential ASR-LLM-TTS pipeline through parallel processing can reduce spoken dialogue latency by up to 51% without sacrificing response quality
2. Discourse connectives serve as effective minimal-committal responses that maintain conversational flow while complex reasoning occurs in parallel
3. Streaming-based cross-modal collaboration enables token-level overlap between transcription, generation, and synthesis, advancing the earliest speakable moment
4. Curriculum learning is essential for maintaining discourse coherence between early connective-based responses and subsequent reasoning outputs
5. The framework functions as a plug-and-play module compatible with diverse LLM architectures, demonstrating strong practical applicability for real-time spoken interaction systems
:::

:::zh
**论文**: [2602.23266](https://arxiv.org/abs/2602.23266)
**作者**: Siyuan Liu, Jiahui Xu, Feng Jiang, Kuang Wang, Zefeng Zhao, Chu-Ren Huang, Jinghang Gu, Changqing Yin, Haizhou Li
**分类**: cs.CL

## 摘要

传统语音对话系统因其严格的顺序式ASR-LLM-TTS流水线而存在高延迟问题,每个组件必须完成后下一个才能开始。本文提出了话语感知双轨流式响应(DDTSR)框架,从根本上重新设计架构以实现跨模态并发处理。通过利用话语连接词作为由小型辅助模型生成的最小承诺早期响应,同时大型模型并行执行深度推理,DDTSR实现了类人响应速度。该框架整合了基于流式的跨模态协作以重叠ASR、LLM推理和TTS操作,并采用课程学习来维持早期与后期响应之间的话语连贯性。实验结果显示在保持响应质量的同时,跨基准测试实现了19-51%的延迟降低,并在不同LLM主干和语句长度上表现出强兼容性。

## 主要贡献

- **双轨架构**:引入并行处理机制,小型模型生成话语连接词(如"嗯"、"实际上")的同时,大型模型执行知识密集型推理,实现即时响应启动
- **流式跨模态协作**:动态重叠ASR转录、LLM令牌生成和TTS合成,最小化首次发声时间
- **基于课程的连贯性训练**:开发训练策略确保早期最小承诺响应与后续推理输出之间的逻辑一致性
- **即插即用兼容性**:展示框架在多种LLM主干上的适用性,无需架构特定修改

## 技术架构

DDTSR框架通过三个相互关联的阶段运作,打破了传统流水线的顺序瓶颈。

**连接词引导的小大模型协同**:系统采用轻量级辅助模型,专门训练用于生成话语连接词——语言学上最小化的短语,在不承诺具体内容的情况下发出轮次转换信号。当这个小模型产生即时语言反馈(通常在200-300毫秒内)时,主要的大型语言模型开始并行处理完整查询。这种双轨方法模仿了人类对话模式,说话者在构思完整思路时常以填充短语开始响应。

**基于流式的跨模态协作**:DDTSR不等待每个组件的完整输出,而是实现令牌级流式机制。当ASR产生部分转录时,LLM开始生成令牌,TTS从最早可用的令牌合成语音。框架计算"最早可说时刻"$t_{speak}$为:

$$t_{speak} = \min(t_{ASR} + t_{LLM}^{first} + t_{TTS}^{first})$$

其中$t_{ASR}$表示部分转录时间,$t_{LLM}^{first}$是生成首个推理令牌的时间,$t_{TTS}^{first}$是合成首个语音片段的时间。

**话语连续性增强**:为防止基于连接词的早期响应与基于推理的完整响应之间出现突兀转换,DDTSR采用课程学习。训练过程逐步增加维持连贯性的复杂度,从简单的连接词到陈述的转换开始,逐步发展到复杂的多轮话语模式。这确保早期响应自然过渡到后续内容,不产生语义不连续。

## 实验结果与分析

作者在两个语音对话基准上评估了DDTSR:客户服务数据集和开放域对话语料库。与传统顺序流水线相比,该框架在客户服务基准上实现了19%的延迟降低,在开放域基准上实现了51%的延迟降低。

**延迟分解**:分析显示延迟收益主要来自三个来源:(1)并行小大模型处理带来30-40%的降低,(2)流式跨模态协作带来25-35%的降低,(3)优化的话语规划带来10-15%的降低。值得注意的是,框架保持了响应质量指标,BLEU分数在基线系统的2%范围内,人类评估分数在连贯性和信息性方面没有显著下降。

**鲁棒性分析**:系统在不同语句长度(50-500令牌)和不同LLM主干(使用GPT风格、LLaMA风格和指令调优模型测试)上表现出一致性能。即插即用特性源于框架的模块化设计,连接词生成模块独立于特定LLM架构运作。

**话语质量保持**:人类评估者对DDTSR响应的自然度、连贯性和信息性进行评分。结果显示87%的响应被评为"自然"或"非常自然",话语连接词被认为是适当的对话标记而非尴尬的填充词。课程学习方法被证明至关重要——移除该组件的消融研究导致早期和后期响应片段之间感知不连续性增加23%。

## 对实时交互的影响

DDTSR代表了语音对话系统设计的范式转变,从顺序处理转向并发多轨执行。该框架在保持质量的同时降低延迟的能力,解决了人机交互中的一个基本挑战:对即时响应性的期望。

使用话语连接词作为桥接机制具有语言学基础——人类说话者在构思复杂响应时自然使用这类装置来维持对话流畅性。通过计算建模这种行为,DDTSR实现了更自然的交互模式。

框架的可扩展性尤其值得注意。随着LLM在规模和能力上持续增长,延迟问题通常会恶化。DDTSR的架构提供了一条前进道路,增加的模型能力不一定转化为用户体验的下降。小模型开销很小(通常<总计算量的5%),使该方法适合生产部署。

未来方向包括将框架扩展到多语言场景,整合视觉模态以实现多模态对话,以及探索基于用户偏好和对话上下文的自适应连接词选择。

## 要点总结

1. 通过并行处理打破顺序式ASR-LLM-TTS流水线,可在不牺牲响应质量的情况下将语音对话延迟降低高达51%
2. 话语连接词作为有效的最小承诺响应,在复杂推理并行进行时维持对话流畅性
3. 基于流式的跨模态协作实现转录、生成和合成之间的令牌级重叠,推进最早可说时刻
4. 课程学习对于维持早期基于连接词的响应与后续推理输出之间的话语连贯性至关重要
5. 该框架作为即插即用模块兼容多种LLM架构,展示了对实时语音交互系统的强实用适用性
:::
