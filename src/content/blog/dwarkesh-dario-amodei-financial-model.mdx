---
title:
  en: "Dario Amodei: The Highest-Stakes Financial Model in History"
  zh: "Dario Amodei：史上最高风险的财务模型"
description:
  en: "Dwarkesh Patel interviews Anthropic CEO Dario Amodei on scaling laws, the economics of frontier AI labs, recursive self-improvement, geopolitics, and the 'country of geniuses in a data center.'"
  zh: "Dwarkesh Patel采访Anthropic CEO Dario Amodei，探讨扩展定律、前沿AI实验室的经济学、递归自我改进、地缘政治与'数据中心中的天才国度'。"
date: 2026-02-18
tags: ["dwarkesh", "interview", "anthropic", "ai-scaling", "ai-safety", "ai-economics", "dario-amodei"]
image: "https://i2.ytimg.com/vi/n1E9IZfvGMA/hqdefault.jpg"
---

import YouTube from '../../components/YouTube.astro';

<YouTube id="n1E9IZfvGMA" title="Dario Amodei — The highest-stakes financial model in history" />

:::en
Anthropic CEO Dario Amodei sits down with Dwarkesh Patel for a wide-ranging three-hour conversation covering AI scaling, the economics of frontier labs, geopolitical implications, and what it means to approach the "country of geniuses in a data center."

## The Scaling Hypothesis Still Holds

### The Big Blob of Compute
- Dario's 2017 "big blob of compute" hypothesis remains intact: only a few things matter — raw compute, data quantity, data quality/distribution, training duration, a scalable objective function, and numerical stability
- Pre-training scaling laws continued as expected; RL scaling now shows the same log-linear improvements
- The most surprising development: the public's lack of recognition of how close we are to the end of the exponential

### RL Scaling Is Not Different
- RL follows the same pattern as pre-training — log-linear improvement with more compute
- The goal is generalization, not teaching every specific skill
- The GPT-1 to GPT-2 transition (narrow to broad data) is analogous to current RL across diverse tasks

### Pre-training: Between Evolution and Learning
- Models need far more data than humans because pre-training sits between evolution and learning
- Once trained, models show strong in-context learning within long context windows
- The human brain starts with evolutionary priors; LLMs start as random weights — pre-training fills that gap

## Timelines to the Country of Geniuses

- 90% confidence: "country of geniuses in a data center" within 10 years (by 2035)
- 50/50 hunch: more like 1-3 years away
- Near certainty on verifiable tasks (coding, math) — 1-2 years for end-to-end capability
- Slight uncertainty on non-verifiable tasks (planning a Mars mission, writing a novel)

### The Spectrum of Software Engineering Automation
Dario lays out a progression that people often conflate:
1. 90% of code written by AI (already happening at Anthropic)
2. 100% of code written by AI — a big productivity jump from 90%
3. 90% of end-to-end SWE tasks (compiling, environments, testing, memos)
4. 100% of today's SWE tasks automated
5. New higher-level tasks created for engineers
6. Eventually 90% less demand for SWEs — but this is far down the spectrum

### Productivity Gains Are Real but Gradual
- Current coding models give roughly 15-20% total factor speedup, up from ~5% six months ago
- Within Anthropic, the productivity gains are "unambiguous"
- The snowball is gathering momentum: 10%, 20%, 25%, 40%...

## The Economics of Frontier AI Labs

### Anthropic's Revenue Exponential
- Revenue growth roughly 10x per year: ~$100M (2023) -> ~$1B (2024) -> ~$9-10B (2025)
- January 2026 alone added several billion more

### The Hellish Demand Prediction Problem
This is the "highest-stakes financial model in history":
- Data centers must be purchased 1-2 years in advance
- If you buy for $1T/year revenue and actual is $800B, no hedge can save you
- Being off by even one year in growth rate can be ruinous
- Anthropic's approach: buy enough to capture strong upside, but not the full 10x/year scenario

### The Profitability Paradox
- Each individual model is profitable: high gross margins on inference
- But companies lose money because they simultaneously spend heavily training the next model
- In equilibrium, roughly 50% of compute goes to training, 50% to inference — underlying economics are profitable
- Log-linear returns mean diminishing returns after ~50% on research

### Industry Structure: Oligopoly, Not Monopoly
- Dario expects 3-4 major players, similar to cloud computing
- Very high barriers to entry (capital + expertise) prevent commoditization
- Models are more differentiated than cloud — different styles, strengths, and personalities

## Diffusion: Fast but Not Infinitely Fast

- One fast exponential: model capability improvement
- A second fast exponential downstream: economic diffusion — faster than any previous technology, but not instant
- Enterprise adoption: individual developers adopt months before large enterprises due to legal review, security compliance, procurement
- Dwarkesh's pushback: AI should diffuse faster than human labor — AI can read your entire Slack in minutes, share knowledge across copies
- Dario's key point: "We don't have the country of geniuses in a data center yet. If we did, everyone would know it."

## Continual Learning and Context Length

- Coding progressed fast partly because the codebase itself serves as external memory — reading it into context gives the model what a human needs months to learn
- Longer context windows are an engineering problem, not a research problem
- A million tokens represents days or weeks of human reading
- Pre-training generalization + in-context learning may be sufficient for most tasks without formal "continual learning"

## AI Safety, Governance, and Geopolitics

### Export Controls and China
- Dario advocates strongly for chip export controls to China
- Both sides having "country of geniuses" could create unstable equilibrium — unlike nuclear deterrence, uncertainty about which AI would "win" breeds conflict
- Authoritarian governments with powerful AI could oppress their own people in unprecedented ways

### AI Regulation
- Dario opposes the federal moratorium on state AI laws — 10 years with no regulation and no federal plan is "crazy"
- Supports federal preemption with actual standards, not blanket prohibition of state action
- Favors starting with transparency requirements, then targeted legislation as risks emerge

### Distribution Is the Hard Part
- Technology will deliver fundamental benefits almost faster than we can absorb them
- Hard problems: distribution of wealth, political freedom, access for developing nations
- Developing world access is the biggest concern: build data centers in Africa, foster AI-driven biotech startups globally

## Claude's Constitution and AI Values

- Teaching models principles rather than rules produces more consistent, generalizable behavior
- Claude is designed to be mostly "coreable" — follows user instructions by default, with hard limits for dangerous requests
- Three feedback loops: internal iteration, competition between companies' constitutions, broader societal input

## Running Anthropic: Culture as Strategy

- Dario spends 30-40% of his time on company culture
- "Dario Vision Quest" every two weeks: 3-4 page document presented to the whole company with open Q&A
- Philosophy: tell the company the truth, avoid corpo-speak, acknowledge problems directly
- What future historians will miss: how fast everything was moving, and how the world outside the AI bubble had no idea

:::

:::zh
Anthropic CEO Dario Amodei与Dwarkesh Patel进行了一场长达三小时的深度对话，涵盖AI扩展、前沿实验室的经济学、地缘政治影响，以及"数据中心中的天才国度"的愿景。

## 扩展假说依然成立

### 大计算块假说
- Dario 2017年提出的"大计算块"假说至今有效：关键因素只有几个——原始算力、数据量、数据质量与分布、训练时长、可扩展的目标函数和数值稳定性
- 预训练扩展定律持续验证；RL扩展展现出相同的对数线性改进
- 最令人惊讶的是：公众对我们距离指数增长终点有多近缺乏认知

### RL扩展并无本质不同
- RL遵循与预训练相同的模式——更多算力带来对数线性改进
- 目标是泛化，而非教授每一项具体技能

### 预训练：介于进化与学习之间
- 模型需要远超人类的数据量，因为预训练处于进化与学习之间
- 人脑从进化先验开始；LLM从随机权重开始——预训练填补了这一差距

## 天才国度的时间线

- 90%置信度：10年内（2035年前）实现"数据中心中的天才国度"
- 50/50的直觉：更可能是1-3年
- 对可验证任务（编程、数学）几乎确定——1-2年内实现端到端能力

### 软件工程自动化的光谱
Dario列出了人们经常混淆的一系列阶段：
1. 90%的代码由AI编写（已在Anthropic实现）
2. 100%的代码由AI编写——从90%到100%是巨大的生产力跃升
3. 90%的端到端软件工程任务自动化
4. 100%的当前软件工程任务自动化
5. 为工程师创造新的更高层次任务
6. 最终软件工程师需求减少90%——但这在光谱的远端

### 生产力提升真实但渐进
- 当前编程模型带来约15-20%的全要素加速，半年前约为5%
- Anthropic内部的生产力提升"毫不含糊"
- 雪球效应正在加速：10%、20%、25%、40%……

## 前沿AI实验室的经济学

### 收入指数增长
- 收入大约每年增长10倍：约1亿美元（2023）-> 约10亿（2024）-> 约90-100亿（2025）
- 2026年1月单月又增加了数十亿

### 史上最高风险的需求预测
- 数据中心需提前1-2年采购
- 如果按万亿美元年收入采购而实际收入为8000亿，没有任何对冲能避免破产
- 即使增长率预测仅偏差一年也可能致命

### 盈利悖论
- 每个单独模型都是盈利的：推理的毛利率很高
- 但公司亏损，因为同时在大量投入训练下一代模型
- 均衡状态下约50%算力用于训练、50%用于推理

### 行业结构：寡头而非垄断
- 预期3-4家主要玩家，类似云计算
- 极高的进入壁垒防止商品化

## 扩散：快但非无限快

- 模型能力提升是一条快速指数曲线；经济扩散是第二条——比以往技术都快，但并非瞬时
- 企业采用：个人开发者比大型企业早数月，因为法律审查、安全合规、采购流程都需要时间
- Dario的关键点："我们还没有数据中心中的天才国度。如果有，所有人都会知道。"

## 持续学习与上下文长度

- 编程进展快，部分原因是代码库本身作为外部记忆支架
- 更长的上下文窗口是工程问题，而非研究问题
- 百万token相当于人类数天到数周的阅读量
- 预训练泛化+上下文学习可能足以应对大多数任务

## AI安全、治理与地缘政治

### 出口管制与中国
- Dario强烈主张对华芯片出口管制
- 双方都拥有"天才国度"可能造成不稳定均衡——不同于核威慑，对哪个AI会"赢"的不确定性会滋生冲突
- 威权政府拥有强大AI可能以前所未有的方式压迫本国人民

### AI监管
- 反对联邦暂停州AI立法——在当前时间线下10年无监管是"疯狂的"
- 主张从透明度要求开始，随着风险出现再进行针对性立法

### 分配才是难题
- 技术将以超出吸收能力的速度交付基本利益
- 难题在于：财富分配、政治自由、发展中国家的获取

## Claude的宪法与AI价值观

- 教模型原则而非规则清单，能产生更一致、更可泛化的行为
- 三个反馈循环：内部迭代、公司间宪法竞争、更广泛的社会输入

## 运营Anthropic：文化即战略

- Dario花30-40%的时间维护公司文化
- 每两周一次"Dario Vision Quest"——3-4页文档面向全公司展示并开放问答
- 理念：对公司说真话，避免官腔，直面问题
- 未来历史学家会遗漏的：一切发生得有多快，以及AI泡沫之外的世界对正在发生之事的无知

:::

