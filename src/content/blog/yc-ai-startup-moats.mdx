---
title:
  en: "Notes: The 7 Most Powerful Moats For AI Startups"
  zh: "笔记：AI 创业公司的 7 大护城河"
description:
  en: "Y Combinator partners discuss Hamilton Helmer's Seven Powers framework applied to AI startups, covering speed, process power, cornered resources, switching costs, counter-positioning, network effects, scale economies, and branding"
  zh: "Y Combinator 合伙人讨论 Hamilton Helmer 的七种力量框架在 AI 创业公司中的应用，涵盖速度、流程能力、独占资源、转换成本、反定位、网络效应、规模经济和品牌"
date: 2025-10-03
tags: ["ycombinator", "ai", "startups", "moats", "strategy", "defensibility"]
image: "https://i2.ytimg.com/vi/bxBzsSsqQAM/hqdefault.jpg"
---

import YouTube from '../../components/YouTube.astro';

<YouTube id="bxBzsSsqQAM" title="The 7 Most Powerful Moats For AI Startups" />

:::en
This post summarizes a Y Combinator discussion on the most powerful moats for AI startups, based on Hamilton Helmer's book "7 Powers: The Foundations of Business Strategy."

## The Seven Powers Framework

Hamilton Helmer's book identifies seven types of competitive advantages (moats) that make businesses defensible. The YC partners discuss how these apply specifically to AI startups, plus one additional moat that's particularly relevant for early-stage companies.

## 1. Speed (The Startup's Original Moat)

While not in Helmer's book, speed is the foundational moat for startups.

**Key insight:** Startups can move faster than large incumbents because they have less to lose and fewer organizational constraints.

**Example - ChatGPT:** OpenAI shipped ChatGPT very quickly with a small team of engineers. Despite Google having all the users, the best AI researchers, and massive resources, OpenAI built the dominant consumer AI brand through speed. If someone had predicted in 2022 that ChatGPT would have more daily users than Google's Gemini, it would have seemed incredulous.

## 2. Process Power

Building complicated systems that are hard to replicate, developed through years of iteration.

**Classic example:** Toyota's assembly line - competitors couldn't just copy it because it was built through decades of refinement.

**AI application:** AI agents that have been finely honed over years of iteration. The more you work with customers and refine your workflows, the harder it becomes for competitors to replicate.

**Example - Salient:** A company doing AI phone calls for auto dealerships. They've spent years perfecting their system, making it extremely difficult for new entrants to match their quality.

## 3. Cornered Resource

Coveted assets that aren't arbitrageable - things competitors can't easily acquire.

**Types of cornered resources in AI:**
- **Patents and regulatory approval** - Especially important in regulated industries like healthcare
- **Proprietary data** - Data that only you have access to
- **Custom models** - Fine-tuned models trained on unique datasets

**Example - Happy Robot:** A company doing AI phone calls for trucking logistics. They have access to proprietary data from trucking companies that competitors can't easily obtain.

**Example - Speak:** The language learning app has built custom voice models specifically for language education that would be very difficult to replicate.

## 4. Switching Costs

When customers are "trapped" because switching to a competitor is expensive or painful.

**Classic examples:** Oracle databases, Salesforce - once you've built your workflows around them, migration is extremely costly.

**AI application:**
- Custom workflows built on top of AI systems
- Data migration challenges
- Integration with existing business processes

**Key insight:** The more deeply integrated your AI solution becomes with a customer's operations, the higher the switching costs.

## 5. Counter-Positioning

Doing something that's difficult for incumbents to copy because it would cannibalize their existing business.

**Classic example:** Per-seat pricing vs. work-delivered pricing. If an incumbent charges per seat, they can't easily switch to outcome-based pricing without destroying their revenue model.

**AI examples:**

**Legora vs. Harvey (Legal AI):** Harvey was the early winner but focused heavily on fine-tuning as their differentiation. Legora counter-positioned by focusing on the application layer and building a better product. This worked because Harvey couldn't easily abandon their fine-tuning approach.

**Speak vs. Duolingo:** Duolingo is essentially a gaming app with language learning elements. Speak counter-positioned by using LLMs and voice to actually help users practice and learn languages through speaking. Duolingo can't easily copy this because it would undermine their gamification-based engagement model.

**Google vs. OpenAI:** Google had a business model requiring them to support ads. OpenAI could build a pure AI assistant without that constraint. Google had "the greatest cash cow in the history of man" - why would they disrupt it?

## 6. Network Effects

The value of the product increases as more users or customers use it.

**Classic examples:**
- Facebook - more valuable as more friends join
- Visa - more valuable as more merchants accept it

**AI application - Data Network Effects:**
In AI, network effects often manifest through data:
- More users generate more data
- More data improves models
- Better models attract more users

**Example - Cursor:** They collect data from every mouse click and keystroke (with user consent in the free version). The more developers use Cursor, the better their autocomplete becomes, creating a compounding advantage.

**Example - ChatGPT:** All the history from ChatGPT 1, 2, 3, 4, 5 feeds into training the next version, creating a data flywheel.

**Evals as Network Effects:** For AI startups, evaluations (evals) create a flywheel - you learn what workflows work or don't work, iterate on your context engineering, and improve. This only compounds with more usage.

## 7. Scale Economies

Investing heavily to build something big, resulting in lower per-unit costs than competitors.

**Classic examples:** UPS, FedEx, Amazon delivery network - massive physical infrastructure enables lower costs per delivery.

**AI application:** This moat primarily applies at the model layer, not the application layer:
- Training state-of-the-art LLMs is extremely capital intensive
- Only a few companies can afford to do it
- Once trained, inference can be offered very inexpensively

**DeepSeek's impact:** The DeepSeek announcement was earthshattering because it suggested training frontier LLMs might be cheaper than thought, potentially diminishing this moat. However, they still built on top of large foundation models - the RL part is cheaper, but you still need the expensive base model.

**Example - Exa:** A search engine for AI agents. Building a web index is extremely expensive, creating economies of scale that make it hard for new entrants.

## 8. Branding

Becoming so well-known that consumers choose you even when equivalent products exist.

**Classic example:** Coca-Cola

**AI application:** Brand is harder to apply directly to startups because it takes time to build. However, its effects are visible:

**Example - OpenAI/ChatGPT:** Despite Google having equivalent models (Gemini Pro 2.5, Gemini Flash 2.5) and being one of the biggest consumer brands on the planet, OpenAI built the dominant AI brand. ChatGPT has more daily users than Gemini, which would have seemed impossible in 2022.

## Key Takeaways for AI Founders

1. **Speed is your first moat** - Move fast before incumbents can react
2. **Build process power through iteration** - Years of refinement create defensibility
3. **Seek cornered resources** - Proprietary data and custom models are valuable
4. **Create switching costs** - Deep integration makes customers sticky
5. **Counter-position against incumbents** - Do things they can't easily copy
6. **Build data flywheels** - More users should make your product better
7. **Consider scale economics** - Some businesses require significant capital investment
8. **Brand takes time** - But can become extremely powerful

## The Vertical AI SaaS Opportunity

The partners note that vertical AI SaaS agents will be at least 10x bigger than traditional SaaS because they tap into a different part of company spend - not the finite software budget, but the much larger labor and services budget.

**Example - Giga ML:** Competing in customer service against Sierra and Decagon. Their counter-positioning is that their product works better out of the box, enabling faster sales and onboarding. AI agents can do customer support not just as well as humans, but better - they're fluent in 200 languages and infinitely patient.
:::

:::zh
本文总结了 Y Combinator 关于 AI 创业公司最强大护城河的讨论，基于 Hamilton Helmer 的著作《7 Powers: The Foundations of Business Strategy》。

## 七种力量框架

Hamilton Helmer 的书识别了七种使企业具有防御性的竞争优势（护城河）。YC 合伙人讨论了这些如何具体应用于 AI 创业公司，以及一个对早期公司特别相关的额外护城河。

## 1. 速度（创业公司的原始护城河）

虽然不在 Helmer 的书中，但速度是创业公司的基础护城河。

**关键洞察：** 创业公司可以比大型在位者更快行动，因为他们损失更少，组织约束更少。

**例子 - ChatGPT：** OpenAI 用一个小型工程师团队非常快速地发布了 ChatGPT。尽管 Google 拥有所有用户、最好的 AI 研究人员和大量资源，OpenAI 通过速度建立了主导的消费者 AI 品牌。如果有人在 2022 年预测 ChatGPT 的日活用户会超过 Google 的 Gemini，这会显得难以置信。

## 2. 流程能力

建立难以复制的复杂系统，通过多年迭代开发。

**经典例子：** 丰田的装配线 - 竞争对手无法简单复制，因为它是通过数十年的改进建立的。

**AI 应用：** 经过多年迭代精心打磨的 AI 代理。你与客户合作和改进工作流程的时间越长，竞争对手就越难复制。

**例子 - Salient：** 一家为汽车经销商做 AI 电话的公司。他们花了多年时间完善系统，使新进入者极难匹配他们的质量。

## 3. 独占资源

不可套利的珍贵资产 - 竞争对手无法轻易获得的东西。

**AI 中的独占资源类型：**
- **专利和监管批准** - 在医疗保健等受监管行业尤为重要
- **专有数据** - 只有你能访问的数据
- **定制模型** - 在独特数据集上训练的微调模型

**例子 - Happy Robot：** 一家为卡车物流做 AI 电话的公司。他们可以访问竞争对手无法轻易获得的卡车公司专有数据。

**例子 - Speak：** 这款语言学习应用专门为语言教育构建了定制语音模型，非常难以复制。

## 4. 转换成本

当客户被"困住"时，因为切换到竞争对手是昂贵或痛苦的。

**经典例子：** Oracle 数据库、Salesforce - 一旦你围绕它们建立了工作流程，迁移成本极高。

**AI 应用：**
- 建立在 AI 系统之上的定制工作流程
- 数据迁移挑战
- 与现有业务流程的集成

**关键洞察：** 你的 AI 解决方案与客户运营集成得越深，转换成本就越高。

## 5. 反定位

做一些在位者难以复制的事情，因为这会蚕食他们现有的业务。

**经典例子：** 按席位定价 vs. 按工作交付定价。如果在位者按席位收费，他们无法轻易切换到基于结果的定价而不破坏其收入模式。

**AI 例子：**

**Legora vs. Harvey（法律 AI）：** Harvey 是早期赢家，但重点关注微调作为差异化。Legora 通过专注于应用层和构建更好的产品进行反定位。这奏效了，因为 Harvey 无法轻易放弃他们的微调方法。

**Speak vs. Duolingo：** Duolingo 本质上是一个带有语言学习元素的游戏应用。Speak 通过使用 LLM 和语音来实际帮助用户通过说话练习和学习语言进行反定位。Duolingo 无法轻易复制这一点，因为这会破坏他们基于游戏化的参与模式。

**Google vs. OpenAI：** Google 有一个需要继续支持广告的商业模式。OpenAI 可以在没有这种约束的情况下构建纯 AI 助手。Google 拥有"人类历史上最大的摇钱树" - 他们为什么要颠覆它？

## 6. 网络效应

产品的价值随着更多用户或客户使用而增加。

**经典例子：**
- Facebook - 随着更多朋友加入而更有价值
- Visa - 随着更多商家接受而更有价值

**AI 应用 - 数据网络效应：**
在 AI 中，网络效应通常通过数据体现：
- 更多用户产生更多数据
- 更多数据改进模型
- 更好的模型吸引更多用户

**例子 - Cursor：** 他们收集每次鼠标点击和按键的数据（在免费版本中经用户同意）。使用 Cursor 的开发者越多，他们的自动补全就越好，创造复合优势。

**例子 - ChatGPT：** ChatGPT 1、2、3、4、5 的所有历史都被输入到下一版本的训练中，创造数据飞轮。

**评估作为网络效应：** 对于 AI 创业公司，评估（evals）创造飞轮 - 你了解哪些工作流程有效或无效，迭代你的上下文工程，并改进。这只会随着更多使用而复合。

## 7. 规模经济

大量投资建设大型设施，从而比竞争对手拥有更低的单位成本。

**经典例子：** UPS、FedEx、亚马逊配送网络 - 大规模物理基础设施使每次配送成本更低。

**AI 应用：** 这种护城河主要适用于模型层，而非应用层：
- 训练最先进的 LLM 需要大量资本
- 只有少数公司负担得起
- 一旦训练完成，推理可以非常便宜地提供

**DeepSeek 的影响：** DeepSeek 的公告令人震惊，因为它表明训练前沿 LLM 可能比想象的更便宜，可能削弱这种护城河。然而，他们仍然建立在大型基础模型之上 - RL 部分更便宜，但你仍然需要昂贵的基础模型。

**例子 - Exa：** 一个为 AI 代理提供的搜索引擎。建立网络索引非常昂贵，创造规模经济使新进入者难以进入。

## 8. 品牌

变得如此知名，以至于即使存在同等产品，消费者也会选择你。

**经典例子：** 可口可乐

**AI 应用：** 品牌更难直接应用于创业公司，因为需要时间建立。然而，其效果是可见的：

**例子 - OpenAI/ChatGPT：** 尽管 Google 拥有同等模型（Gemini Pro 2.5、Gemini Flash 2.5）并且是地球上最大的消费者品牌之一，OpenAI 建立了主导的 AI 品牌。ChatGPT 的日活用户比 Gemini 多，这在 2022 年看起来是不可能的。

## AI 创始人的关键要点

1. **速度是你的第一个护城河** - 在在位者反应之前快速行动
2. **通过迭代建立流程能力** - 多年的改进创造防御性
3. **寻求独占资源** - 专有数据和定制模型很有价值
4. **创造转换成本** - 深度集成使客户粘性更强
5. **对在位者进行反定位** - 做他们无法轻易复制的事情
6. **建立数据飞轮** - 更多用户应该使你的产品更好
7. **考虑规模经济** - 某些业务需要大量资本投资
8. **品牌需要时间** - 但可以变得极其强大

## 垂直 AI SaaS 机会

合伙人指出，垂直 AI SaaS 代理将比传统 SaaS 大至少 10 倍，因为它们利用了公司支出的不同部分 - 不是有限的软件预算，而是更大的劳动力和服务预算。

**例子 - Giga ML：** 在客户服务领域与 Sierra 和 Decagon 竞争。他们的反定位是产品开箱即用效果更好，实现更快的销售和入职。AI 代理不仅可以像人类一样做客户支持，而且做得更好 - 他们精通 200 种语言，而且无限耐心。
:::
