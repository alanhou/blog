---
title:
  en: "RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations"
  zh: "RobustVisRAG: 视觉退化条件下的因果感知视觉检索增强生成"
description:
  en: "A causality-guided dual-path framework that improves vision-based RAG robustness under visual distortions like blur, noise, and low light, achieving significant performance gains on degraded inputs while maintaining accuracy on clean data."
  zh: "一个因果引导的双路径框架,提升视觉检索增强生成在模糊、噪声、低光等视觉退化条件下的鲁棒性,在退化输入上实现显著性能提升的同时保持清晰数据的准确性。"
date: 2026-02-26
tags: ["arxiv", "ai", "cs.cv"]
image: "/arxiv-visuals/robustvisrag-causality-aware-vision-based-retrieval/HeroScene.png"
---

![Hero diagram](/arxiv-visuals/robustvisrag-causality-aware-vision-based-retrieval/HeroScene.png)



:::en
**Paper**: [2602.22013](https://arxiv.org/abs/2602.22013)
**Authors**: I-Hsiang Chen, Yu-Wei Liu, Tse-Yu Wu, Yu-Chien Chiang, Jen-Chien Yang, Wei-Ting Chen
**Categories**: cs.CV

## Abstract

Vision-based Retrieval-Augmented Generation (VisRAG) systems combine vision-language models to retrieve relevant visual documents and generate answers from multimodal evidence. However, these systems suffer significant performance degradation when visual inputs are corrupted by real-world distortions such as blur, noise, low lighting, or shadows. The core problem lies in the entanglement of semantic content and degradation artifacts within pretrained visual encoders, causing errors to propagate through both retrieval and generation stages. RobustVisRAG addresses this challenge through a causality-guided dual-path architecture that explicitly separates degradation signals from semantic information, enabling robust performance under challenging visual conditions while preserving zero-shot generalization capabilities.

## Key Contributions

- **Causality-Guided Dual-Path Architecture**: Introduces a novel framework with a non-causal path for capturing degradation signals via unidirectional attention and a causal path for learning purified semantics guided by these signals
- **Disentanglement Objectives**: Proposes Non-Causal Distortion Modeling (NCDM) and Causal Semantic Alignment (CSA) objectives that enforce clear separation between semantic content and visual degradations
- **Distortion-VisRAG Benchmark**: Creates a comprehensive large-scale dataset spanning seven domains with 12 synthetic and 5 real-world distortion types, providing realistic evaluation conditions for robust VisRAG research
- **Significant Performance Gains**: Achieves 7.35% improvement in retrieval, 6.35% in generation, and 12.40% in end-to-end performance on real-world degradations while maintaining comparable accuracy on clean inputs

## Technical Methodology

The RobustVisRAG framework operates through a sophisticated dual-path mechanism designed to disentangle visual degradations from semantic content. The architecture consists of two parallel processing streams that work in concert to achieve robust multimodal understanding.

The **non-causal path** employs unidirectional attention mechanisms to capture degradation-specific signals without allowing these artifacts to contaminate semantic representations. This path processes visual features through layers that explicitly model distortion characteristics, learning to identify and isolate corruption patterns such as blur kernels, noise distributions, and lighting variations. The Non-Causal Distortion Modeling objective trains this path to reconstruct degradation parameters, ensuring that the model develops a comprehensive understanding of how visual quality affects the input.

The **causal path** focuses on extracting clean semantic representations by leveraging the degradation signals identified by the non-causal path. Through bidirectional attention guided by distortion awareness, this path learns to filter out corruption artifacts and maintain semantic consistency. The Causal Semantic Alignment objective ensures that semantic features remain stable across different degradation levels, enforcing invariance to visual quality while preserving content-specific information necessary for accurate retrieval and generation.

The framework integrates seamlessly with existing vision-language models, requiring no architectural changes to the base VLM. During inference, both paths process the input simultaneously, with the non-causal path providing degradation context that guides the causal path's semantic extraction. This design maintains computational efficiency while significantly improving robustness, as the additional processing overhead is minimal compared to the base model's computation.

## Experimental Results and Analysis

The evaluation on the Distortion-VisRAG benchmark reveals substantial improvements across multiple metrics and degradation types. On real-world distortions, RobustVisRAG demonstrates remarkable resilience, with retrieval accuracy improving by 7.35% over baseline VisRAG models. This improvement is particularly pronounced in scenarios involving multiple simultaneous degradations, such as documents affected by both low lighting and motion blur, where traditional approaches experience catastrophic performance drops.

Generation quality metrics show a 6.35% improvement, measured through both automated metrics and human evaluation. The model maintains factual accuracy and coherence even when source documents are severely degraded, indicating that the semantic disentanglement successfully preserves content understanding despite visual corruption. The end-to-end pipeline performance, combining retrieval and generation, achieves a 12.40% improvement, demonstrating that benefits compound across the full VisRAG workflow.

Critically, these robustness gains come without sacrificing performance on clean inputs. The model maintains comparable accuracy to baseline systems on undistorted documents, validating that the causality-guided approach does not introduce harmful biases or overfitting to degraded data. Ablation studies confirm that both the non-causal and causal paths contribute essential functionality, with removal of either component resulting in significant performance degradation.

The benchmark evaluation across synthetic and real-world distortions reveals interesting patterns in model behavior. Synthetic distortions with well-defined mathematical models (Gaussian blur, additive noise) show strong performance improvements, while real-world degradations (camera shake, compression artifacts, environmental lighting) demonstrate even larger gains, suggesting that the model learns generalizable robustness principles rather than overfitting to specific corruption types.

## Implications and Future Directions

RobustVisRAG addresses a critical gap in practical deployment of vision-based RAG systems. Real-world document collections frequently contain images captured under suboptimal conditions—scanned documents with artifacts, photographs taken in poor lighting, compressed images with quality loss, or historical documents with age-related degradation. By enabling robust performance under these conditions, the framework significantly expands the applicability of VisRAG to real-world scenarios where perfect visual quality cannot be guaranteed.

The causality-guided disentanglement approach offers broader implications for multimodal learning. The principle of explicitly separating task-relevant semantics from nuisance factors through architectural design and targeted objectives could extend to other domains where input quality varies, such as audio processing with background noise, text understanding with OCR errors, or sensor data with measurement uncertainty.

Future research directions include extending the framework to handle temporal degradations in video-based RAG, incorporating adaptive mechanisms that adjust processing based on detected degradation severity, and exploring whether similar disentanglement principles can improve robustness to adversarial perturbations. The Distortion-VisRAG benchmark provides a foundation for continued research in robust multimodal understanding, enabling systematic evaluation of future approaches.

## Takeaways

1. Visual degradations significantly impair VisRAG performance by entangling semantic content with corruption artifacts in pretrained encoders, causing errors in both retrieval and generation stages
2. Causality-guided dual-path architectures can effectively disentangle degradation signals from semantic information through specialized attention mechanisms and targeted training objectives
3. Explicit modeling of distortions via non-causal paths enables causal paths to learn purified semantic representations that remain stable across varying visual quality levels
4. Real-world degradations pose greater challenges than synthetic distortions, but causality-aware approaches show even stronger improvements on realistic corruption patterns
5. Robustness to visual degradations can be achieved without sacrificing performance on clean inputs, enabling practical deployment in mixed-quality document collections
6. The Distortion-VisRAG benchmark provides comprehensive evaluation across 17 distortion types spanning synthetic and real-world scenarios, establishing a standard for robust VisRAG research
7. Performance improvements compound across the full VisRAG pipeline, with end-to-end gains (12.40%) exceeding individual component improvements, demonstrating system-level benefits of robustness
:::

:::zh
**论文**: [2602.22013](https://arxiv.org/abs/2602.22013)
**作者**: I-Hsiang Chen, Yu-Wei Liu, Tse-Yu Wu, Yu-Chien Chiang, Jen-Chien Yang, Wei-Ting Chen
**分类**: cs.CV

## 摘要

基于视觉的检索增强生成(VisRAG)系统结合视觉-语言模型来检索相关视觉文档并从多模态证据生成答案。然而,当视觉输入受到模糊、噪声、低光照或阴影等现实世界退化的影响时,这些系统会出现显著的性能下降。核心问题在于预训练视觉编码器中语义内容与退化伪影的纠缠,导致错误在检索和生成阶段传播。RobustVisRAG通过因果引导的双路径架构解决这一挑战,显式地将退化信号与语义信息分离,在保持零样本泛化能力的同时实现在挑战性视觉条件下的鲁棒性能。

## 主要贡献

- **因果引导双路径架构**: 提出一个新颖框架,包含通过单向注意力捕获退化信号的非因果路径,以及在这些信号引导下学习纯化语义的因果路径
- **解耦目标函数**: 提出非因果退化建模(NCDM)和因果语义对齐(CSA)目标,强制实现语义内容与视觉退化的清晰分离
- **Distortion-VisRAG基准**: 创建一个跨越七个领域的综合大规模数据集,包含12种合成和5种真实世界退化类型,为鲁棒VisRAG研究提供现实评估条件
- **显著性能提升**: 在真实世界退化上实现检索7.35%、生成6.35%、端到端12.40%的性能提升,同时在清晰输入上保持相当的准确性

## 技术方法论

RobustVisRAG框架通过精密的双路径机制运作,旨在将视觉退化从语义内容中解耦。该架构由两个并行处理流组成,协同工作以实现鲁棒的多模态理解。

**非因果路径**采用单向注意力机制捕获退化特定信号,同时防止这些伪影污染语义表示。该路径通过显式建模退化特征的层处理视觉特征,学习识别和隔离诸如模糊核、噪声分布和光照变化等损坏模式。非因果退化建模目标训练该路径重建退化参数,确保模型对视觉质量如何影响输入形成全面理解。

**因果路径**专注于通过利用非因果路径识别的退化信号提取清晰的语义表示。通过退化感知引导的双向注意力,该路径学习过滤损坏伪影并保持语义一致性。因果语义对齐目标确保语义特征在不同退化级别下保持稳定,强制实现对视觉质量的不变性,同时保留准确检索和生成所需的内容特定信息。

该框架与现有视觉-语言模型无缝集成,无需对基础VLM进行架构更改。在推理期间,两条路径同时处理输入,非因果路径提供退化上下文来引导因果路径的语义提取。这种设计保持了计算效率,同时显著提高鲁棒性,因为额外的处理开销相比基础模型的计算量微不足道。

## 实验结果与分析

在Distortion-VisRAG基准上的评估揭示了跨多个指标和退化类型的实质性改进。在真实世界退化上,RobustVisRAG展现出卓越的韧性,检索准确率相比基线VisRAG模型提升7.35%。这种改进在涉及多种同时退化的场景中尤为显著,例如同时受低光照和运动模糊影响的文档,传统方法在这些情况下会经历灾难性的性能下降。

生成质量指标显示6.35%的改进,通过自动化指标和人工评估测量。即使源文档严重退化,模型仍保持事实准确性和连贯性,表明语义解耦成功地保留了内容理解,尽管存在视觉损坏。结合检索和生成的端到端流水线性能实现12.40%的提升,证明收益在完整VisRAG工作流中复合累积。

关键的是,这些鲁棒性增益没有牺牲清晰输入上的性能。模型在未失真文档上保持与基线系统相当的准确性,验证了因果引导方法不会引入有害偏差或对退化数据的过拟合。消融研究证实非因果和因果路径都贡献了关键功能,移除任一组件都会导致显著的性能下降。

跨合成和真实世界退化的基准评估揭示了模型行为的有趣模式。具有明确数学模型的合成退化(高斯模糊、加性噪声)显示出强劲的性能改进,而真实世界退化(相机抖动、压缩伪影、环境光照)展现出更大的增益,表明模型学习到可泛化的鲁棒性原则,而非过拟合特定损坏类型。

## 影响与未来方向

RobustVisRAG解决了基于视觉的RAG系统实际部署中的关键缺口。真实世界文档集合经常包含在次优条件下捕获的图像——带有伪影的扫描文档、在弱光下拍摄的照片、有质量损失的压缩图像,或具有年代相关退化的历史文档。通过在这些条件下实现鲁棒性能,该框架显著扩展了VisRAG在无法保证完美视觉质量的真实场景中的适用性。

因果引导的解耦方法为多模态学习提供了更广泛的启示。通过架构设计和针对性目标显式分离任务相关语义与干扰因素的原则,可以扩展到输入质量变化的其他领域,例如带有背景噪声的音频处理、带有OCR错误的文本理解,或带有测量不确定性的传感器数据。

未来研究方向包括将框架扩展到处理基于视频的RAG中的时序退化,整合根据检测到的退化严重程度调整处理的自适应机制,以及探索类似的解耦原则是否能提高对对抗性扰动的鲁棒性。Distortion-VisRAG基准为鲁棒多模态理解的持续研究提供了基础,使未来方法的系统评估成为可能。

## 要点总结

1. 视觉退化通过在预训练编码器中将语义内容与损坏伪影纠缠,显著损害VisRAG性能,导致检索和生成阶段的错误
2. 因果引导的双路径架构可以通过专门的注意力机制和针对性训练目标有效地将退化信号从语义信息中解耦
3. 通过非因果路径显式建模退化,使因果路径能够学习在不同视觉质量级别下保持稳定的纯化语义表示
4. 真实世界退化比合成退化带来更大挑战,但因果感知方法在现实损坏模式上显示出更强的改进
5. 可以在不牺牲清晰输入性能的情况下实现对视觉退化的鲁棒性,使在混合质量文档集合中的实际部署成为可能
6. Distortion-VisRAG基准提供跨越17种退化类型(涵盖合成和真实场景)的综合评估,为鲁棒VisRAG研究建立标准
7. 性能改进在完整VisRAG流水线中复合累积,端到端增益(12.40%)超过单个组件改进,展示了鲁棒性的系统级优势
:::
