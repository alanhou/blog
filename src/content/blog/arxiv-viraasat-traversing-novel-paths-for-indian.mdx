---
title:
  en: "VIRAASAT: Advancing Cultural Reasoning in LLMs Through Multi-Hop Knowledge Graphs"
  zh: "VIRAASAT: 通过多跳知识图谱推进大语言模型的文化推理能力"
description:
  en: "A novel framework introducing a 3,200+ question dataset for Indian cultural reasoning and a Symbolic Chain-of-Manipulation approach that outperforms standard Chain-of-Thought methods by 20%."
  zh: "一个创新框架,引入了包含3200多个问题的印度文化推理数据集,以及一种符号操作链方法,性能比标准思维链方法提升20%。"
date: 2026-02-23
tags: ["arxiv", "ai", "cs.cl", "cs.ir"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::en
**Paper**: [2602.18429](https://arxiv.org/abs/2602.18429)
**Authors**: Harshul Raj Surana, Arijit Maji, Aryan Vats, Akash Ghosh, Sriparna Saha, Amit Sheth
**Categories**: cs.CL, cs.IR

## Abstract

While Large Language Models excel at mathematical and coding reasoning, they struggle with tasks requiring deep socio-cultural knowledge, particularly in non-Western contexts like Indian culture. This paper introduces VIRAASAT, a semi-automated framework for generating multi-hop cultural reasoning questions. Built on a knowledge graph of 700+ expert-curated cultural artifacts spanning 13 attributes across all Indian states and union territories, VIRAASAT produces over 3,200 questions requiring chained reasoning. The authors identify that standard Chain-of-Thought fine-tuning fails to ground low-probability cultural facts, and propose Symbolic Chain-of-Manipulation (SCoM), which trains models to simulate atomic knowledge graph operations internally. SCoM achieves up to 20% improvement over CoT baselines in supervised fine-tuning experiments.

## Key Contributions

- **VIRAASAT Dataset**: A comprehensive multi-hop QA dataset with 3,200+ questions covering Indian cultural reasoning across 28 states and 8 union territories, spanning 13 cultural attributes including history, festivals, cuisine, and traditions
- **Knowledge Graph Foundation**: An expert-curated knowledge graph containing 700+ cultural artifacts that enables systematic generation of complex reasoning chains
- **Symbolic Chain-of-Manipulation (SCoM)**: A novel training paradigm that teaches models to perform atomic knowledge graph manipulations internally, improving their ability to traverse topological structures
- **Empirical Analysis**: Comprehensive evaluation of SOTA LLMs revealing specific failure modes in cultural reasoning, particularly in grounding and synthesizing low-probability facts

## The Cultural Reasoning Gap

Current LLM benchmarks predominantly focus on Western-centric knowledge and single-hop factual recall. The authors identify three critical limitations in existing cultural benchmarks: they are manually crafted (limiting scale), contain primarily single-hop questions (testing memorization rather than reasoning), and are prohibitively expensive to expand. This creates a significant blind spot in evaluating LLMs' ability to reason about diverse cultural contexts.

VIRAASAT addresses this gap by focusing on multi-hop reasoning that requires models to chain together multiple cultural facts. For example, a question might require understanding the historical context of a festival, its regional variations, and its connection to specific cultural practices—demanding genuine reasoning rather than simple recall.

The semi-automated generation approach leverages the structured knowledge graph to systematically create questions that traverse different reasoning paths, ensuring coverage across geographical regions and cultural dimensions while maintaining quality through expert curation of the underlying artifacts.

## Symbolic Chain-of-Manipulation Framework

The core innovation of SCoM lies in teaching models to internalize knowledge graph operations rather than generating free-form reasoning chains. Traditional Chain-of-Thought approaches struggle with cultural reasoning because they rely on the model's pre-training distribution, which often assigns low probability to specific cultural facts.

SCoM adapts the Chain-of-Manipulation paradigm by training models to simulate atomic operations like:
- **Node traversal**: Moving from one cultural entity to related entities
- **Attribute extraction**: Retrieving specific properties of cultural artifacts
- **Relation following**: Navigating typed relationships in the knowledge graph
- **Fact synthesis**: Combining information from multiple graph paths

This symbolic approach provides several advantages. First, it grounds reasoning in the explicit structure of the knowledge graph, reducing hallucination. Second, it makes the reasoning process more interpretable by exposing the specific graph operations performed. Third, it enables the model to reliably handle low-probability facts by treating them as discrete graph elements rather than continuous probability distributions.

The training process involves creating supervision data where each reasoning step corresponds to a specific graph manipulation. During inference, the model learns to generate these symbolic operations, which can then be executed against the knowledge graph to produce reliable answers.

## Experimental Results and Analysis

Evaluation on VIRAASAT reveals significant performance gaps in current SOTA LLMs. The authors test multiple model families and find that even the most capable models struggle with multi-hop cultural reasoning, often failing to maintain consistency across reasoning chains or incorrectly synthesizing cultural facts.

Standard CoT fine-tuning shows limited improvement, particularly on questions requiring three or more reasoning hops. The authors attribute this to CoT's reliance on the model's implicit knowledge representation, which poorly captures the long-tail distribution of cultural facts.

In contrast, SCoM demonstrates substantial gains:
- Up to 20% improvement in accuracy over CoT baselines
- Better performance on longer reasoning chains (3+ hops)
- Reduced hallucination rates when dealing with low-frequency cultural entities
- Improved consistency in multi-step reasoning

The results suggest that explicit symbolic manipulation provides a more robust foundation for cultural reasoning than implicit neural representations. The performance gap widens as question complexity increases, indicating that SCoM's structured approach scales better to challenging reasoning scenarios.

Error analysis reveals that remaining failures often stem from ambiguities in cultural knowledge itself (where multiple interpretations exist) or gaps in the knowledge graph coverage, pointing to directions for future work.

## Implications for Culturally-Aware AI

VIRAASAT represents a significant step toward building AI systems that can reason about diverse cultural contexts. The framework's semi-automated approach offers a scalable path to creating cultural reasoning benchmarks for other regions and cultures, addressing a critical gap in current AI evaluation.

The success of SCoM suggests that hybrid approaches combining symbolic reasoning with neural learning may be essential for handling knowledge domains with long-tail distributions. This has implications beyond cultural reasoning, potentially benefiting specialized domains like medicine, law, or regional history where facts don't follow the power-law distributions typical of general web text.

The release of the VIRAASAT dataset and findings provides the research community with tools to develop and evaluate culturally-aware models. This is particularly important as LLMs are increasingly deployed in diverse global contexts where cultural competence is essential for appropriate and effective interaction.

Future directions include expanding the knowledge graph to cover more cultural dimensions, developing methods to handle cultural knowledge that varies by perspective or interpretation, and exploring how symbolic reasoning approaches can be integrated with retrieval-augmented generation for even more robust cultural understanding.

## Takeaways

1. Current LLMs exhibit significant deficiencies in multi-hop cultural reasoning, particularly for non-Western contexts like Indian culture
2. VIRAASAT provides a scalable, semi-automated framework for generating complex cultural reasoning benchmarks using expert-curated knowledge graphs
3. Symbolic Chain-of-Manipulation (SCoM) outperforms standard Chain-of-Thought approaches by up to 20% by teaching models to simulate explicit knowledge graph operations
4. The structured symbolic approach proves more effective than implicit neural representations for handling low-probability cultural facts
5. The framework and dataset establish a foundation for developing culturally-aware AI systems that can reason across diverse global contexts
:::

:::zh
**论文**: [2602.18429](https://arxiv.org/abs/2602.18429)
**作者**: Harshul Raj Surana, Arijit Maji, Aryan Vats, Akash Ghosh, Sriparna Saha, Amit Sheth
**分类**: cs.CL, cs.IR

## 摘要

尽管大语言模型在数学和编程推理方面表现出色,但在需要深厚社会文化知识的任务中表现不佳,特别是在印度文化等非西方语境中。本文介绍了VIRAASAT,一个用于生成多跳文化推理问题的半自动化框架。该框架基于一个包含700多个专家策划的文化工件的知识图谱,涵盖印度所有邦和联邦属地的13个文化属性,生成了超过3200个需要链式推理的问题。作者发现标准的思维链微调无法有效处理低概率文化事实,因此提出了符号操作链(SCoM)方法,训练模型在内部模拟原子级知识图谱操作。在监督微调实验中,SCoM相比CoT基线实现了高达20%的性能提升。

## 主要贡献

- **VIRAASAT数据集**: 一个全面的多跳问答数据集,包含3200多个问题,覆盖印度28个邦和8个联邦属地的文化推理,涵盖历史、节日、美食和传统等13个文化属性
- **知识图谱基础**: 一个由专家策划的知识图谱,包含700多个文化工件,能够系统化地生成复杂的推理链
- **符号操作链(SCoM)**: 一种新颖的训练范式,教导模型在内部执行原子级知识图谱操作,提升其遍历拓扑结构的能力
- **实证分析**: 对最先进大语言模型的全面评估,揭示了文化推理中的特定失效模式,特别是在低概率事实的定位和综合方面

## 文化推理的差距

当前的大语言模型基准测试主要关注西方中心的知识和单跳事实回忆。作者指出现有文化基准测试存在三个关键局限:手工制作(限制规模)、主要包含单跳问题(测试记忆而非推理)、扩展成本过高。这在评估大语言模型对多元文化语境的推理能力方面造成了显著盲区。

VIRAASAT通过聚焦需要模型串联多个文化事实的多跳推理来解决这一差距。例如,一个问题可能需要理解节日的历史背景、地区变体及其与特定文化实践的联系——这要求真正的推理而非简单的记忆。

半自动化生成方法利用结构化知识图谱系统地创建遍历不同推理路径的问题,确保覆盖地理区域和文化维度,同时通过对底层工件的专家策划保持质量。

## 符号操作链框架

SCoM的核心创新在于教导模型内化知识图谱操作,而非生成自由形式的推理链。传统的思维链方法在文化推理中表现不佳,因为它们依赖模型的预训练分布,而该分布通常对特定文化事实赋予较低概率。

SCoM通过训练模型模拟原子操作来适应操作链范式,这些操作包括:
- **节点遍历**: 从一个文化实体移动到相关实体
- **属性提取**: 检索文化工件的特定属性
- **关系跟随**: 导航知识图谱中的类型化关系
- **事实综合**: 组合来自多个图谱路径的信息

这种符号化方法提供了多个优势。首先,它将推理建立在知识图谱的显式结构上,减少幻觉。其次,通过暴露执行的特定图谱操作,使推理过程更具可解释性。第三,它使模型能够可靠地处理低概率事实,将其视为离散图谱元素而非连续概率分布。

训练过程涉及创建监督数据,其中每个推理步骤对应特定的图谱操作。在推理过程中,模型学习生成这些符号操作,然后可以针对知识图谱执行以产生可靠答案。

## 实验结果与分析

在VIRAASAT上的评估揭示了当前最先进大语言模型的显著性能差距。作者测试了多个模型系列,发现即使是最强大的模型也在多跳文化推理中表现困难,经常无法在推理链中保持一致性或错误地综合文化事实。

标准CoT微调显示出有限的改进,特别是在需要三个或更多推理跳的问题上。作者将此归因于CoT依赖模型的隐式知识表示,而这种表示对文化事实的长尾分布捕获不佳。

相比之下,SCoM展现出显著提升:
- 相比CoT基线准确率提升高达20%
- 在更长推理链(3+跳)上表现更好
- 处理低频文化实体时幻觉率降低
- 多步推理的一致性提高

结果表明,显式符号操作为文化推理提供了比隐式神经表示更稳健的基础。随着问题复杂度增加,性能差距扩大,表明SCoM的结构化方法在具有挑战性的推理场景中扩展性更好。

错误分析显示,剩余的失败通常源于文化知识本身的歧义(存在多种解释)或知识图谱覆盖的空白,为未来工作指明了方向。

## 对文化感知AI的意义

VIRAASAT代表了构建能够对多元文化语境进行推理的AI系统的重要一步。该框架的半自动化方法为其他地区和文化创建文化推理基准提供了可扩展的路径,解决了当前AI评估中的关键差距。

SCoM的成功表明,结合符号推理与神经学习的混合方法对于处理具有长尾分布的知识领域可能至关重要。这不仅对文化推理有影响,还可能惠及医学、法律或地区历史等专业领域,这些领域的事实不遵循一般网络文本典型的幂律分布。

VIRAASAT数据集和研究发现的发布为研究社区提供了开发和评估文化感知模型的工具。随着大语言模型越来越多地部署在多元化的全球语境中,文化能力对于适当和有效的交互至关重要,这一点尤为重要。

未来方向包括扩展知识图谱以覆盖更多文化维度,开发处理因视角或解释而变化的文化知识的方法,以及探索如何将符号推理方法与检索增强生成集成以实现更稳健的文化理解。

## 要点总结

1. 当前大语言模型在多跳文化推理方面存在显著缺陷,特别是在印度文化等非西方语境中
2. VIRAASAT提供了一个可扩展的半自动化框架,使用专家策划的知识图谱生成复杂的文化推理基准
3. 符号操作链(SCoM)通过教导模型模拟显式知识图谱操作,性能比标准思维链方法提升高达20%
4. 结构化符号方法在处理低概率文化事实方面比隐式神经表示更有效
5. 该框架和数据集为开发能够跨多元全球语境进行推理的文化感知AI系统奠定了基础
:::
