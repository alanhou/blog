---
title:
  en: "Latent Reasoning with Supervised Thinking States"
  zh: "基于监督思维状态的潜在推理"
description:
  en: "Proposes Thinking States that enable LMs to reason during input processing with parallelizable teacher-forcing, approaching CoT quality with better latency"
  zh: "提出思维状态方法，使语言模型在输入处理过程中进行推理，通过可并行化的教师强制训练，在保持更低延迟的同时接近思维链质量"
date: 2026-02-10
tags: ["arxiv", "ai", "reasoning", "latent-reasoning", "chain-of-thought", "efficiency", "cs.CL", "cs.LG"]
image: "/arxiv-visuals/arxiv-latent-reasoning-thinking-states.png"
---

:::en
**Paper**: [2602.08332](https://arxiv.org/abs/2602.08332)
**Authors**: Ido Amos, Avi Caciularu, Mor Geva, Amir Globerson, Jonathan Herzig, Lior Shani, Idan Szpektor
**Categories**: cs.CL, cs.LG

## Abstract

This paper proposes "Thinking States" that enable language models to reason while processing input, generating thinking tokens at regular intervals and converting them back to embeddings. This approach mirrors iterative chain-of-thought but operates during input processing rather than output generation. The token-based thoughts can be learned from natural language supervision using parallelizable teacher-forcing. Experimental results show the method approaches CoT quality on math tasks, matches it on 2-Hop QA with better latency, and achieves superior performance on state-tracking with better generalization.

## Key Contributions

- **Thinking States architecture**: A novel mechanism for injecting reasoning steps during input processing
- **Parallelizable training**: Teacher-forcing enables efficient training unlike sequential CoT generation
- **Latency advantages**: Reasoning happens during input processing, reducing output generation time
- **Strong generalization**: Superior out-of-distribution performance on state-tracking tasks

## Motivation

Standard chain-of-thought reasoning has a fundamental efficiency problem: reasoning tokens are generated sequentially during output, adding significant latency. What if the model could "think" while reading the input instead?

Thinking States address this by inserting special thinking tokens at regular intervals during input processing. These tokens serve as computational "scratch space" where the model can perform intermediate reasoning steps.

## Architecture

### Thinking Token Insertion

Given an input sequence $x_1, x_2, \ldots, x_n$, Thinking States inserts thinking tokens at fixed intervals $k$:

$$x_1, \ldots, x_k, [\text{THINK}], x_{k+1}, \ldots, x_{2k}, [\text{THINK}], \ldots$$

Each $[\text{THINK}]$ token:
1. Is processed by the model to produce a hidden state
2. The hidden state is projected to a token prediction
3. The predicted token's embedding replaces the thinking token's representation
4. Processing continues with this updated representation

### The Think-Project-Replace Cycle

At each thinking position $t$, the model:

1. **Computes** hidden state $h_t$ from all previous tokens including prior thinking states
2. **Projects** $h_t$ through the language model head to get logits over the vocabulary
3. **Selects** the top token $w_t = \arg\max(\text{LM\_head}(h_t))$
4. **Replaces** the thinking token embedding with $\text{Embed}(w_t)$

This creates a discrete bottleneck that forces the model to compress its intermediate reasoning into interpretable tokens.

### Training with Teacher-Forcing

A key advantage is that thinking tokens can be supervised with natural language targets. Given a reasoning chain from a teacher model, the thinking tokens are trained to predict the corresponding reasoning words:

$$\mathcal{L} = \sum_{t \in \text{think\_positions}} -\log P(w_t^* | x_{<t}, \text{think}_{<t})$$

where $w_t^*$ is the target thinking word from the teacher. Because the targets are known during training, this can be parallelized via teacher-forcing, unlike autoregressive CoT generation.

## Experimental Results

### Math Reasoning

On mathematical reasoning benchmarks, Thinking States approaches the quality of full chain-of-thought:

- Closes the gap between direct answering and CoT by a significant margin
- The thinking tokens learn to perform intermediate calculations
- Performance scales with the number of thinking tokens inserted

### 2-Hop Question Answering

On 2-Hop QA tasks requiring compositional reasoning:

- **Matches CoT accuracy** while providing better laten model learns to resolve the first hop during input processing
- Thinking tokens capture bridge entity identification

### State Tracking

On state-tracking tasks (e.g., tracking object positions through a sequence of operations):

- **Outperforms CoT** with better generalization to longer sequences
- The iterative nature of thinking states naturally aligns with incremental state updates
- Superior out-of-distribution performance on sequences longer than training examples

## Analysis

### What Do Thinking Tokens Learn?

Inspection of the predicted thinking tokens reveals interpretable intermediate reasoning:

- On math: parutation results and carry operations
- On QA: bridge entities and intermediate facts
- On state tracking: current state representations after each operation

### Latency Benefits

The key efficiency advantage comes from the parallelization of reasoning:

| Method | Reasoning Phase | Output Phase | Total Latency |
|--------|----------------|--------------|---------------|
| Direct | None | Short | Low |
| CoT | None | Long (sequential) | High |
| Thinking States | During input (parallel) | Short | Medium |

Since input processing can leverage parallel computation (alns are known), thinking during input is more efficient than thinking during output.

### Scaling Behavior

The number of thinking tokens per interval affects performance:

- Too few: insufficient computational budget for reasoning
- Too many: diminishing returns and increased input processing time
- Optimal interval depends on task complexity

## Significance

Thinking States represent a compelling middle ground between direct answering and full chain-of-thought reasoning. By shifting reasoning computation from the sequential output phase to the parallelizable input phase, the method achieves strong reasoning performance with better latency characteristics. The ability to supervise thinking tokens with natural language makes training straightforward and the intermediate reasoning interpretable. This work opens a promising direction for efficient reasoning in language models.
:::

:::zh
**论文**: [2602.08332](https://arxiv.org/abs/2602.08332)
**作者**: Ido Amos, Avi Caciularu, Mor Geva, Amir Globerson, Jonathan Herzig, Lior Shani, Idan Szpektor
**分类**: cs.CL, cs.LG

## 摘要

本文提出了"思维状态"方法，使语言模型能够在处理输入时进行推理，在固定间隔生成思维token并将其转换回嵌入。这种方法模拟了迭代式思维链，但在输入处理阶段而非输出生成阶段运作。基于token的思维可以通过可并行化的教师强制从自然语言监督表明，该方法在数学任务上接近CoT质量，在2-Hop问答上匹配CoT且延迟更低，在状态追踪上表现优越且泛化能力更强。

## 主要贡献

- **思维状态架构**：在输入处理过程中注入推理步骤的新机制
- **可并行化训练**：教师强制实现高效训练，不同于顺序CoT生成
- **延迟优势**：推理在输入处理期间进行，减少输出生成时间
- **强泛化能力**：在状态追踪任务上优越的分布外性能

## 动机

标准思维链推理有一个根本的效率问题：推理token在输出期间顺序生成，增加了显著的延迟。如果模型可以在阅读输入时"思考"呢？

思维状态通过在输入处理期间以固定间隔插入特殊思维token来解决这个问题。这些token作为计算"草稿空间"，模型可以在其中执行中间推理步骤。

## 架构

### 思维Token插入

给定输入序列 $x_1, x_2, \ldots, x_n$，思维状态在固定间隔 $k$ 处插入思维token：

$$x_1, \ldots, x_k, [\text{THINK}], x_{k+1}, \ldots, x_{2k}, [\text{THINK}], \ldots$$

每个 $[\text{THINK}]$ token：
1. 由模型处理产生隐藏状态
2. 隐藏状态被投影为token预测
3. 预测token的嵌入替换思维token的表示
4. 处理继续使用更新后的表示

### 思考-投影-替换循环

在每个思维位置 $t$，模型：

1. **计算**隐藏状态 $h_t$，基于所有先前token包括之前的思维状态
2. **投影** $h_t$ 通过语言模型头获得词汇表上的logits
3. **选择**最高概率token $w_t = \arg\max(\text{LM\_head}(h_t))$
4. **替换**思维token嵌入为 $\text{Embed}(w_t)$

这创建了一个离散瓶颈，迫使模型将中间推理压缩为可解释的token。

### 教师强制训练

一个关键优势是思维token可以用自然语言目标进行监督。给定来自教师模型的推理链，思维token被训练来预测相应的推理词：

$$\mathcal{L} = \sum_{t \in \text{think\_positions}} -\log P(w_t^* | x_{<t}, \text{think}_{<t})$$

其中 $w_t^*$ 是来自教师的目标思维词。因为目标在训练期间是已知的，这可以通过教师强制并行化，不同于自回归CoT生成。

## 实验结果

### 数学推理

在数学推理基准上，思维状态接近完整思维链的质量：

- 显著缩小了直接回答和CoT之间的差距
- 思维token学会执行中间计算
- 性能随插入的思维token数量而扩展

### 2-Hop问答

在需要组合推理的2-Hop问答任务上：

- **匹配CoT准确率**同时提供更好的延迟
- 模型学会在输入处理期间解决第一跳
- 思维token捕获桥接实体识别

### 状态追踪

在状态追踪任务上（例如，追踪对象在一系列操作中的位置）：

- **优于CoT**，对更长序列有更好的泛化
- 思维状态的迭代性质自然与增量状态更新对齐
- 在比训练样本更长的序列上有优越的分布外性能

## 分析

### 思维Token学到了什么？

检查预测的思维token揭示了可解释的中间推理：

- 数学：部分计算结果和进位操作
- 问答：桥接实体和中间事实
- 状态追踪：每次操作后的当前状态表示

### 延迟优势

关键效率优势来自推理的并行化：

| 方法 | 推理阶段 | 输出阶段 | 总延迟 |
|------|---------|---------|--------|
| 直接回答 | 无 | 短 | 低 |
| CoT | 无 | 长（顺序） | 高 |
| 思维状态 | 输入期间（并行） | 短 | 中等 |

由于输入处理可以利用并行计算（所有输入token已知），在输入期间思考比在输出期间思考更高效。

### 扩展行为

每个间隔的思维token数量影响性能：

- 太少：推理计算预算不足
- 太多：收益递减且增加输入处理时间
- 最优间隔取决于任务复杂度

## 意义

思维状态代表了直接回答和完整思维链推理之间一个引人注目的中间方案。通过将推理计算从顺序输出阶段转移到可并行化的输入阶段，该方法以更好的延迟特性实现了强大的推理性能。用自然语言监督思维token的能力使训练简单直接，中间推理可解释。这项工作为语言模型中的高效推理开辟了一个有前景的方向。
:::
