---
title:
  en: "NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning"
  zh: "NovaPlan: 通过闭环视频语言规划实现零样本长时域机器人操作"
description:
  en: "A hierarchical framework combining vision-language models and video generation for zero-shot robot manipulation that achieves complex assembly tasks through closed-loop planning and geometric grounding."
  zh: "一个结合视觉语言模型和视频生成的层次化框架,通过闭环规划和几何基础实现零样本机器人操作,完成复杂装配任务。"
date: 2026-02-24
tags: ["arxiv", "ai", "cs.ro", "cs.ai", "cs.cv"]
image: "/arxiv-visuals/novaplan-zero-shot-long-horizon-manipulation/HeroScene.png"
---

![Hero diagram](/arxiv-visuals/novaplan-zero-shot-long-horizon-manipulation/HeroScene.png)



:::en
**Paper**: [2602.20119](https://arxiv.org/abs/2602.20119)
**Authors**: Jiahui Fu, Junyu Nan, Lingfeng Sun, Hongyu Li, Jianing Qian, Jennifer L. Barry, Kris Kitani, George Konidaris
**Categories**: cs.RO, cs.AI, cs.CV

## Abstract

NovaPlan addresses a fundamental challenge in robotics: enabling robots to perform complex, long-horizon manipulation tasks without prior demonstrations or training. The framework bridges the gap between high-level semantic reasoning provided by vision-language models (VLMs) and the physical grounding required for real-world robot execution. By combining closed-loop VLM planning with video generation models and geometric action extraction, NovaPlan decomposes tasks into sub-goals, generates visual predictions of outcomes, and translates these into precise robot actions. The system demonstrates autonomous error recovery through continuous monitoring and re-planning, achieving success on complex assembly tasks and the Functional Manipulation Benchmark (FMB) in a zero-shot setting.

## Key Contributions

- A hierarchical framework that unifies closed-loop VLM planning with video-based action generation for zero-shot long-horizon manipulation
- A dual kinematic prior extraction mechanism that leverages both object keypoints and human hand poses from generated videos, with intelligent switching based on execution context
- Closed-loop monitoring and autonomous re-planning capabilities that enable recovery from single-step failures without human intervention
- Demonstration of complex assembly tasks and dexterous manipulation on FMB without any prior demonstrations or task-specific training

## Technical Architecture

NovaPlan operates through a two-level hierarchy that separates semantic reasoning from physical execution. At the high level, a VLM planner receives natural language task descriptions and decomposes them into a sequence of sub-goals. For each sub-goal, the system generates a video prediction showing the expected outcome of the manipulation. This video serves as both a visual specification and a source of kinematic information.

The low-level execution layer extracts actionable information from the generated videos through two parallel pathways. The first pathway identifies task-relevant object keypoints and tracks their trajectories through the video frames. The second pathway detects and tracks human hand poses, which serve as natural demonstrations of manipulation strategies. A switching mechanism dynamically selects between these two kinematic priors based on factors such as occlusion levels and depth estimation confidence.

The closed-loop nature of the system is critical to its robustness. After each sub-goal execution, the VLM planner observes the actual robot state through camera feedback and compares it against the expected outcome. If discrepancies are detected, the system autonomously re-plans, either by adjusting the current sub-goal or by generating an entirely new action sequence. This feedback loop enables the system to recover from failures that would otherwise terminate execution.

## Geometric Grounding and Action Computation

A key innovation in NovaPlan is how it translates visual predictions into geometrically grounded robot actions. Rather than directly imitating pixel-level video content, the system extracts sparse geometric representations that are invariant to viewpoint changes and robust to visual noise.

For object-centric manipulation, the system identifies keypoints on target objects using foundation models and tracks their 3D trajectories across video frames. These trajectories are then transformed into end-effector waypoints through inverse kinematics, with the robot following the implied motion path. This approach works well for tasks where the object geometry is clearly visible and the manipulation primarily involves moving objects through space.

For contact-rich or dexterous manipulation, human hand poses provide more informative priors. The system detects hand keypoints in the generated video and maps them to robot end-effector poses through a learned correspondence. This is particularly effective for tasks requiring specific grasp configurations or fine manipulation, where the hand pose encodes important information about contact points and force application.

The switching mechanism between these two modes is governed by confidence metrics. When object keypoints are reliably detected and tracked with low reprojection error, the system uses object-centric control. When occlusion is heavy or depth estimates are uncertain, it falls back to hand pose guidance. This adaptive strategy maintains execution stability across diverse manipulation scenarios.

## Experimental Results and Analysis

NovaPlan was evaluated on three categories of long-horizon tasks: multi-step assembly, functional manipulation from the FMB benchmark, and tasks requiring error recovery. The results demonstrate significant advantages over baseline approaches that lack either closed-loop planning or geometric grounding.

On assembly tasks involving multiple objects and sequential dependencies, NovaPlan achieved success rates exceeding 75% in zero-shot settings. The system successfully completed tasks such as assembling furniture components, stacking blocks with specific ordering constraints, and constructing simple mechanical structures. Notably, these tasks required 5-8 sequential manipulation steps, with each step depending on the successful completion of previous ones.

The FMB evaluation tested the system's ability to perform functional manipulations where the goal is defined by achieving a specific functional state rather than a geometric configuration. Tasks included opening containers, operating mechanisms, and arranging objects for specific purposes. NovaPlan's closed-loop planning proved essential here, as the system could adapt its strategy based on observed functional outcomes rather than rigidly following a predetermined plan.

Error recovery experiments revealed the system's robustness to execution failures. When individual manipulation attempts failed due to grasp errors, object slippage, or environmental perturbations, the VLM planner detected the discrepancy and generated corrective actions. In 68% of cases where a single step failed, the system successfully recovered and completed the overall task. This is a substantial improvement over open-loop approaches, which typically fail completely after any single-step error.

## Implications for Robot Learning

NovaPlan represents a significant step toward robots that can perform complex manipulation tasks without extensive training data or task-specific programming. The zero-shot capability is particularly valuable for applications where collecting demonstrations is expensive or impractical, such as household robotics, disaster response, or space exploration.

The framework's reliance on foundation models (VLMs and video generation models) means it inherits both their capabilities and limitations. The system can generalize to novel objects and scenarios that appear in the training data of these foundation models, but may struggle with truly out-of-distribution situations. The geometric grounding layer partially mitigates this by ensuring physical plausibility, but the high-level planning still depends on the VLM's semantic understanding.

The closed-loop architecture suggests a path toward more autonomous robotic systems. Rather than requiring perfect execution of predetermined plans, robots can monitor their own performance and adapt in real-time. This is closer to how humans approach complex tasks—through iterative refinement rather than flawless execution. Future work could extend this approach to incorporate learning from failures, gradually improving performance through experience.

The dual kinematic prior mechanism highlights an important principle: different manipulation strategies are appropriate for different contexts. Object-centric control works well for gross motion and object transport, while hand pose guidance is better for contact-rich interaction. A mature robotic system needs multiple strategies and the intelligence to switch between them appropriately.

## Takeaways

1. NovaPlan demonstrates that zero-shot long-horizon manipulation is achievable by combining VLM planning, video generation, and geometric grounding in a closed-loop framework
2. Closed-loop monitoring and autonomous re-planning are essential for robust execution, enabling recovery from single-step failures without human intervention
3. Dual kinematic priors (object keypoints and hand poses) with intelligent switching provide robustness across diverse manipulation scenarios
4. The framework achieves 75%+ success rates on complex assembly tasks and performs well on functional manipulation benchmarks without any task-specific training
5. Foundation models can provide semantic reasoning and visual prediction capabilities, but geometric grounding is necessary to translate these into physically executable robot actions
:::

:::zh
**论文**: [2602.20119](https://arxiv.org/abs/2602.20119)
**作者**: Jiahui Fu, Junyu Nan, Lingfeng Sun, Hongyu Li, Jianing Qian, Jennifer L. Barry, Kris Kitani, George Konidaris
**分类**: cs.RO, cs.AI, cs.CV

## 摘要

NovaPlan解决了机器人领域的一个基本挑战:使机器人能够在没有先验演示或训练的情况下执行复杂的长时域操作任务。该框架弥合了视觉语言模型(VLM)提供的高级语义推理与真实世界机器人执行所需的物理基础之间的差距。通过将闭环VLM规划与视频生成模型和几何动作提取相结合,NovaPlan将任务分解为子目标,生成结果的视觉预测,并将其转换为精确的机器人动作。该系统通过持续监控和重新规划展示了自主错误恢复能力,在零样本设置下成功完成了复杂的装配任务和功能性操作基准测试(FMB)。

## 主要贡献

- 提出了一个层次化框架,将闭环VLM规划与基于视频的动作生成统一起来,实现零样本长时域操作
- 设计了双运动学先验提取机制,从生成的视频中同时利用物体关键点和人手姿态,并根据执行上下文智能切换
- 实现了闭环监控和自主重新规划能力,使系统能够在无需人工干预的情况下从单步失败中恢复
- 在没有任何先验演示或任务特定训练的情况下,展示了复杂装配任务和FMB上的灵巧操作能力

## 技术架构

NovaPlan通过两级层次结构运作,将语义推理与物理执行分离。在高层,VLM规划器接收自然语言任务描述并将其分解为一系列子目标。对于每个子目标,系统生成一个视频预测,显示操作的预期结果。该视频既作为视觉规范,也作为运动学信息的来源。

低层执行层通过两条并行路径从生成的视频中提取可操作信息。第一条路径识别任务相关的物体关键点并跟踪它们在视频帧中的轨迹。第二条路径检测并跟踪人手姿态,这些姿态作为操作策略的自然演示。切换机制根据遮挡程度和深度估计置信度等因素在这两种运动学先验之间动态选择。

系统的闭环特性对其鲁棒性至关重要。在每个子目标执行后,VLM规划器通过相机反馈观察实际的机器人状态,并将其与预期结果进行比较。如果检测到差异,系统会自主重新规划,要么调整当前子目标,要么生成全新的动作序列。这种反馈循环使系统能够从原本会终止执行的失败中恢复。

## 几何基础与动作计算

NovaPlan的一个关键创新是如何将视觉预测转换为几何基础的机器人动作。系统不是直接模仿像素级视频内容,而是提取对视角变化不变且对视觉噪声鲁棒的稀疏几何表示。

对于以物体为中心的操作,系统使用基础模型识别目标物体上的关键点,并跟踪它们在视频帧中的3D轨迹。然后通过逆运动学将这些轨迹转换为末端执行器路径点,机器人遵循隐含的运动路径。这种方法适用于物体几何形状清晰可见且操作主要涉及在空间中移动物体的任务。

对于接触丰富或灵巧的操作,人手姿态提供了更具信息量的先验。系统检测生成视频中的手部关键点,并通过学习的对应关系将它们映射到机器人末端执行器姿态。这对于需要特定抓取配置或精细操作的任务特别有效,其中手部姿态编码了关于接触点和力施加的重要信息。

这两种模式之间的切换机制由置信度指标控制。当物体关键点被可靠检测并以低重投影误差跟踪时,系统使用以物体为中心的控制。当遮挡严重或深度估计不确定时,它回退到手部姿态引导。这种自适应策略在各种操作场景中保持执行稳定性。

## 实验结果与分析

NovaPlan在三类长时域任务上进行了评估:多步骤装配、FMB基准测试中的功能性操作以及需要错误恢复的任务。结果表明,与缺乏闭环规划或几何基础的基线方法相比,该系统具有显著优势。

在涉及多个物体和顺序依赖关系的装配任务上,NovaPlan在零样本设置下实现了超过75%的成功率。系统成功完成了诸如组装家具部件、按特定顺序约束堆叠积木以及构建简单机械结构等任务。值得注意的是,这些任务需要5-8个连续的操作步骤,每个步骤都依赖于前面步骤的成功完成。

FMB评估测试了系统执行功能性操作的能力,其中目标由实现特定功能状态而非几何配置来定义。任务包括打开容器、操作机构以及为特定目的排列物体。NovaPlan的闭环规划在这里被证明是必不可少的,因为系统可以根据观察到的功能结果调整其策略,而不是僵化地遵循预定计划。

错误恢复实验揭示了系统对执行失败的鲁棒性。当由于抓取错误、物体滑动或环境扰动导致单个操作尝试失败时,VLM规划器检测到差异并生成纠正动作。在68%的单步失败案例中,系统成功恢复并完成了整体任务。这比开放环路方法有了实质性改进,后者通常在任何单步错误后完全失败。

## 对机器人学习的启示

NovaPlan代表了朝着能够在没有大量训练数据或任务特定编程的情况下执行复杂操作任务的机器人迈出的重要一步。零样本能力对于收集演示成本高昂或不切实际的应用特别有价值,例如家用机器人、灾难响应或太空探索。

该框架对基础模型(VLM和视频生成模型)的依赖意味着它继承了这些模型的能力和局限性。系统可以泛化到这些基础模型训练数据中出现的新物体和场景,但可能在真正的分布外情况下遇到困难。几何基础层通过确保物理合理性部分缓解了这一问题,但高层规划仍然依赖于VLM的语义理解。

闭环架构为更自主的机器人系统指明了道路。机器人不需要完美执行预定计划,而是可以监控自己的性能并实时适应。这更接近人类处理复杂任务的方式——通过迭代改进而非完美执行。未来的工作可以扩展这种方法,纳入从失败中学习,通过经验逐步提高性能。

双运动学先验机制突出了一个重要原则:不同的操作策略适用于不同的上下文。以物体为中心的控制适用于粗略运动和物体运输,而手部姿态引导更适合接触丰富的交互。成熟的机器人系统需要多种策略以及适当切换它们的智能。

## 要点总结

1. NovaPlan证明了通过在闭环框架中结合VLM规划、视频生成和几何基础,可以实现零样本长时域操作
2. 闭环监控和自主重新规划对于鲁棒执行至关重要,使系统能够在无需人工干预的情况下从单步失败中恢复
3. 具有智能切换的双运动学先验(物体关键点和手部姿态)在各种操作场景中提供了鲁棒性
4. 该框架在复杂装配任务上实现了75%以上的成功率,并在功能性操作基准测试上表现良好,无需任何任务特定训练
5. 基础模型可以提供语义推理和视觉预测能力,但几何基础对于将这些转换为物理可执行的机器人动作是必要的
:::
