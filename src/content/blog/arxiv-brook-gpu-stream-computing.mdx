---
title:
  en: "Brook for GPUs: Stream Computing on Graphics Hardware"
  zh: "Brook for GPUs: Stream Computing on Graphics Hardware"
description:
  en: "提出 Brook 流式编程模型，将 GPU 抽象为流处理器，为后来的 CUDA 奠定基础"
  zh: "提出 Brook 流式编程模型，将 GPU 抽象为流处理器，为后来的 CUDA 奠定基础"
date: 2004-01-01
tags: ["arxiv", "gpu-computing", "stream-processing", "cuda", "parallel-computing"]
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
---

:::zh
## 论文信息

- **标题**: Brook for GPUs: Stream Computing on Graphics Hardware
- **作者**: Ian Buck, Tim Foley, Daniel Horn, Jeremy Sugerman, Kayvon Fatahalian, Mike Houston, Pat Hanrahan
- **机构**: Stanford University
- **发表时间**: 2003-2004
- **论文链接**: [PDF](https://graphics.stanford.edu/papers/brookgpu/brookgpu.pdf)

## 核心贡献

Brook for GPUs 是一项开创性工作，它将 GPU 从专用图形处理器转变为通用并行计算平台。这项工作为后来 NVIDIA CUDA 的诞生奠定了重要基础。

### 主要创新

1. **流式编程模型**: 将数据组织为"流"(streams)，对流进行并行操作
2. **内核抽象**: 定义在流上执行的并行函数(kernels)
3. **GPU 抽象层**: 隐藏底层图形 API 的复杂性
4. **自动优化**: 编译器自动处理数据布局和内存管理

## 技术细节

### 流式计算模型

```c
// Brook 代码示例
kernel void saxpy(float a, float x<>, float y<>, out float result<>) {
    result = a * x + y;
}

// 主程序
float a = 2.0f;
float x<100>, y<100>, result<100>;
// ... 初始化数据 ...
saxpy(a, x, y, result);
```

### 核心概念

- **Streams**: 数据的并行集合
- **Kernels**: 在流元素上并行执行的函数
- **Reduction**: 将流归约为单个值的操作
- **Gather/Scatter**: 间接内存访问模式

## 历史意义

Brook for GPUs 的重要性在于：

1. **证明了 GPU 通用计算的可行性**: 在 CUDA 出现之前，展示了 GPU 可以用于非图形计算
2. **影响了 CUDA 设计**: NVIDIA 的 CUDA 架构借鉴了 Brook 的许多概念
3. **开启了 GPGPU 时代**: 为后来的深度学习 GPU 加速铺平了道路

## 对深度学习的影响

没有 Brook 和后续的 CUDA，现代深度学习的发展将大不相同：

- AlexNet (2012) 使用 GPU 训练成为可能
- 大规模语言模型的训练依赖 GPU 并行计算
- 当今 AI 基础设施建立在 GPU 计算之上

## 总结

Brook for GPUs 是计算历史上的里程碑，它开创了将 GPU 用于通用计算的先河，为整个深度学习革命奠定了硬件基础。
:::

:::en
## Paper Information

- **Title**: Brook for GPUs: Stream Computing on Graphics Hardware
- **Authors**: Ian Buck, Tim Foley, Daniel Horn, Jeremy Sugerman, Kayvon Fatahalian, Mike Houston, Pat Hanrahan
- **Institution**: Stanford University
- **Published**: 2003-2004
- **Paper Link**: [PDF](https://graphics.stanford.edu/papers/brookgpu/brookgpu.pdf)

## Core Contributions

Brook for GPUs was a pioneering work that transformed GPUs from specialized graphics processors into general-purpose parallel computing platforms. This work laid important groundwork for NVIDIA's CUDA.

### Key Innovations

1. **Stream Programming Model**: Organizing data as "streams" with parallel operations
2. **Kernel Abstraction**: Defining parallel functions that execute on streams
3. **GPU Abstraction Layer**: Hiding the complexity of underlying graphics APIs
4. **Automatic Optimization**: Compiler handles data layout and memory management

## Technical Details

### Stream Computing Model

The stream model treats computation as operations on collections of data elements, enabling massive parallelism on GPU hardware.

### Core Concepts

- **Streams**: Parallel collections of data
- **Kernels**: Functions executing in parallel on stream elements
- **Reduction**: Operations that reduce streams to single values
- **Gather/Scatter**: Indirect memory access patterns

## Historical Significance

Brook for GPUs is significant because:

1. **Proved GPU general computing feasibility**: Demonstrated GPUs could be used for non-graphics computation before CUDA
2. **Influenced CUDA design**: NVIDIA's CUDA architecture borrowed many concepts from Brook
3. **Launched the GPGPU era**: Paved the way for deep learning GPU acceleration

## Impact on Deep Learning

Without Brook and subsequent CUDA, modern deep learning would be vastly different:

- AlexNet (2012) GPU training became possible
- Large language model training relies on GPU parallel computing
- Today's AI infrastructure is built on GPU computing

## Summary

Brook for GPUs is a milestone in computing history, pioneering the use of GPUs for general-purpose computing and laying the hardware foundation for the entire deep learning revolution.
:::
